{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99370cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52cca81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hEn = pd.read_csv(\"./eval_metric_hEn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d43a03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4006, 19)\n"
     ]
    }
   ],
   "source": [
    "print(output_all_hEn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3843c0d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/Outputs/Human_Evaluation/hEN-DE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m eval_hEn \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/Outputs/Human_Evaluation/hEN-DE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/Outputs/Human_Evaluation/hEN-DE'"
     ]
    }
   ],
   "source": [
    "# human eval and correlation\n",
    "eval_hEn = pd.DataFrame()\n",
    "path = \"../dataset/Outputs/Human_Evaluation/hEN-DE\"\n",
    "for file in os.listdir(path):\n",
    "    if \"val\" in file:\n",
    "        print(file)\n",
    "        try:\n",
    "            e = pd.read_csv(path + \"/\" + file, sep = \";\")\n",
    "        except:\n",
    "            e = pd.read_csv(path + \"/\" + file,) \n",
    "            e.columns = ['Unnamed: 0', 'Model-Id', 'generated_summary', 'reference_summary',\n",
    "       'text', 'id', 'direction', 'coherence', 'consistency', 'fluency',\n",
    "       'relevance']\n",
    "            e = e[['Model-Id', 'id', 'coherence', 'consistency', 'fluency',\n",
    "       'relevance']] \n",
    "        e[\"annotator\"] = file[-5:-4]\n",
    "        eval_hEn = pd.concat([eval_hEn, e])\n",
    "        \n",
    "p1 = pd.read_csv(path + \"/\" + \"hEN-DE_Phase1_with_id.csv\", sep= \";\")\n",
    "p1['Phase'] = \"Phase-1\"\n",
    "p2 = pd.read_csv(path + \"/\" + \"hEN-DE_Phase2_with_id.csv\", sep= \";\")\n",
    "p2['Phase'] = \"Phase-2\"\n",
    "phase_id_hEn = p1.append(p2)\n",
    "\n",
    "eval_hEn = pd.merge(eval_hEn, phase_id_hEn, left_on = [\"Phase\", \"Text-id\"], right_on = [\"Phase\", \"text-id\"], how = \"outer\")\n",
    "\n",
    "eval_hEn[\"id\"] = [eval_hEn.id_y.iloc[idx] if pd.isna(eval_hEn.id_x.iloc[idx]) else eval_hEn.id_x.iloc[idx] for idx in range(len(eval_hEn))]\n",
    "eval_hEn[\"model_id\"] = [str(eval_hEn[\"Model-Id_x\"].iloc[idx]) if pd.isna(eval_hEn[\"Model-Id_y\"].iloc[idx]) else str(eval_hEn[\"Model-Id_y\"].iloc[idx]) for idx in range(len(eval_hEn))]\n",
    "\n",
    "for column in [\"coherence\", \"consistency\",  \"fluency\", \"relevance\"]:\n",
    "    eval_hEn[column] = [float(str(eval_hEn[column].iloc[idx]).replace(\",\", \".\")) for idx in range(len(eval_hEn)) ]\n",
    "eval_hEn.model_id = eval_hEn.model_id.replace({\"chatGPT_pp\": \"chatGPT_pipeline\", \"Memsum\":\"memsum_deepl\"})   \n",
    "\n",
    "chat_anno = pd.read_csv(path + \"/\" + \"de_chateval_6.csv\") \n",
    "chat_anno[\"annotator\"] = str(6)\n",
    "chat_anno = chat_anno.dropna()\n",
    "\n",
    "print(\"chatGPT:\", chat_anno.shape)\n",
    "column = [\"id\", \"model_id\", \"coherence\", \"consistency\", \"fluency\", \"relevance\", \"annotator\"]\n",
    "eval_hEn = pd.concat([eval_hEn[column], chat_anno[column]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940a4843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nan', 'chatGPT_title', 'chatGPT_pipeline', '5', '11', '2', '6',\n",
       "       '1', '3', '4', 'memsum_deepl', '10', 'B2', 'chatGPT_e2e',\n",
       "       'memsum_tr_chatgpt', 'memsum_pipegpt', 'English_25_False',\n",
       "       'English_25_True', 'English_100'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_hEn.model_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f93ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from menli normalization\n",
    "def min_max_normalize(scores):\n",
    "    if len(scores) > 1:\n",
    "        normalized_scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "    else:\n",
    "        normalized_scores = scores\n",
    "    return normalized_scores\n",
    "def compute_menli(df):\n",
    "    for nli_weight in [0.8, 0.2, 0.3]:   \n",
    "        norm_metric_scores = min_max_normalize(df.bertscore_F1)\n",
    "        norm_nli_scores = min_max_normalize(df.menli)\n",
    "        final_scores = [nli_weight*n + (1-nli_weight)*m for n, m in zip(norm_nli_scores, norm_metric_scores)]\n",
    "        df[\"MENLI_W\" + str(nli_weight)] = final_scores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae67bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hEn = compute_menli(output_all_hEn_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ce1f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>id</th>\n",
       "      <th>reference_summary</th>\n",
       "      <th>generated_summary</th>\n",
       "      <th>direction</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougel</th>\n",
       "      <th>bertscore_P</th>\n",
       "      <th>bertscore_R</th>\n",
       "      <th>bertscore_F1</th>\n",
       "      <th>bartscore</th>\n",
       "      <th>moverscore</th>\n",
       "      <th>menli</th>\n",
       "      <th>idx</th>\n",
       "      <th>DiscoScore_F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI_W0.8</th>\n",
       "      <th>MENLI_W0.2</th>\n",
       "      <th>MENLI_W0.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Die Geschichte spielt in der Zeit des amerikan...</td>\n",
       "      <td>Die Geschichte spielt in Kennesaw Mountain, Ge...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.170149</td>\n",
       "      <td>0.858479</td>\n",
       "      <td>0.847765</td>\n",
       "      <td>0.853088</td>\n",
       "      <td>-7.108416</td>\n",
       "      <td>0.826710</td>\n",
       "      <td>-0.954164</td>\n",
       "      <td>5-5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974544</td>\n",
       "      <td>0.140071</td>\n",
       "      <td>0.492802</td>\n",
       "      <td>0.434014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>Ein Mann namens Manton hat seine beiden Kinder...</td>\n",
       "      <td>Die Geschichte beginnt mit dem Anblick des alt...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>0.130879</td>\n",
       "      <td>0.848553</td>\n",
       "      <td>0.827102</td>\n",
       "      <td>0.837690</td>\n",
       "      <td>-5.524875</td>\n",
       "      <td>0.833683</td>\n",
       "      <td>-0.020967</td>\n",
       "      <td>12-5</td>\n",
       "      <td>3.760938</td>\n",
       "      <td>0.962296</td>\n",
       "      <td>0.492427</td>\n",
       "      <td>0.500621</td>\n",
       "      <td>0.499255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>Halpin Frayser, ein 32-j√§hriger Bewohner des N...</td>\n",
       "      <td>Halpin Frayser lebt in St. Helena, New York Ci...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.362393</td>\n",
       "      <td>0.147009</td>\n",
       "      <td>0.870212</td>\n",
       "      <td>0.842318</td>\n",
       "      <td>0.856038</td>\n",
       "      <td>-5.227464</td>\n",
       "      <td>0.815050</td>\n",
       "      <td>-0.994908</td>\n",
       "      <td>13-5</td>\n",
       "      <td>0.236795</td>\n",
       "      <td>0.961973</td>\n",
       "      <td>0.127853</td>\n",
       "      <td>0.505122</td>\n",
       "      <td>0.442244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>Der erste Teil wird von Joel Hetman Jr. erz√§hl...</td>\n",
       "      <td>Die Geschichte beginnt mit dem Tod eines schre...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.342400</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.861515</td>\n",
       "      <td>0.847997</td>\n",
       "      <td>0.854702</td>\n",
       "      <td>-4.223670</td>\n",
       "      <td>0.823316</td>\n",
       "      <td>-0.936292</td>\n",
       "      <td>19-5</td>\n",
       "      <td>0.199864</td>\n",
       "      <td>0.961006</td>\n",
       "      <td>0.149473</td>\n",
       "      <td>0.503568</td>\n",
       "      <td>0.444552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>Ein H√ºhnchen und ein H√§hnchen verreisen im Wag...</td>\n",
       "      <td>Ein Hund und eine Heule bauen ein sch√∂nes Wage...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.367893</td>\n",
       "      <td>0.200669</td>\n",
       "      <td>0.860734</td>\n",
       "      <td>0.872339</td>\n",
       "      <td>0.866497</td>\n",
       "      <td>-4.346346</td>\n",
       "      <td>0.864347</td>\n",
       "      <td>-0.940130</td>\n",
       "      <td>28-5</td>\n",
       "      <td>0.113075</td>\n",
       "      <td>0.946747</td>\n",
       "      <td>0.164333</td>\n",
       "      <td>0.568769</td>\n",
       "      <td>0.501363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>English_100</td>\n",
       "      <td>169</td>\n",
       "      <td>Nach dem Deutsch-Franz√∂sischen Krieg sind eini...</td>\n",
       "      <td>In a chateau in Normandy, during the Prussian ...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.861927</td>\n",
       "      <td>0.830362</td>\n",
       "      <td>0.845850</td>\n",
       "      <td>-4.086033</td>\n",
       "      <td>0.837850</td>\n",
       "      <td>-0.887630</td>\n",
       "      <td>169-English_100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830155</td>\n",
       "      <td>0.156658</td>\n",
       "      <td>0.459216</td>\n",
       "      <td>0.408790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>English_100</td>\n",
       "      <td>219</td>\n",
       "      <td>Die Erz√§hlung beginnt mit der Schilderung eine...</td>\n",
       "      <td>The story is about a group of adventurers who ...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.022756</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.813235</td>\n",
       "      <td>0.832468</td>\n",
       "      <td>-5.981541</td>\n",
       "      <td>0.794588</td>\n",
       "      <td>-0.996035</td>\n",
       "      <td>219-English_100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838499</td>\n",
       "      <td>0.094636</td>\n",
       "      <td>0.373947</td>\n",
       "      <td>0.327395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>English_100</td>\n",
       "      <td>288</td>\n",
       "      <td>Die beiden edlen Vettern ist eine Tragikom√∂die...</td>\n",
       "      <td>Das St√ºck \"The Two Noble Kinsmen\" wurde von Jo...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.185075</td>\n",
       "      <td>0.095522</td>\n",
       "      <td>0.852004</td>\n",
       "      <td>0.825930</td>\n",
       "      <td>0.838764</td>\n",
       "      <td>-5.793730</td>\n",
       "      <td>0.844478</td>\n",
       "      <td>-0.990916</td>\n",
       "      <td>288-English_100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882269</td>\n",
       "      <td>0.105439</td>\n",
       "      <td>0.409473</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>English_100</td>\n",
       "      <td>196</td>\n",
       "      <td>Spencer Brydon kehrt nach dreiunddrei√üig Jahre...</td>\n",
       "      <td>Der Protagonist des Textes, Spencer Brydon, is...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.221719</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.877558</td>\n",
       "      <td>0.825913</td>\n",
       "      <td>0.850952</td>\n",
       "      <td>-4.471878</td>\n",
       "      <td>0.792781</td>\n",
       "      <td>-0.300782</td>\n",
       "      <td>196-English_100</td>\n",
       "      <td>0.046351</td>\n",
       "      <td>0.852758</td>\n",
       "      <td>0.398793</td>\n",
       "      <td>0.546347</td>\n",
       "      <td>0.521755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>English_100</td>\n",
       "      <td>149</td>\n",
       "      <td>In der Stadt Rattleborough wird der wohlhabend...</td>\n",
       "      <td>The narrator tells the story of the disappeara...</td>\n",
       "      <td>hEN-DE</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.838078</td>\n",
       "      <td>0.822558</td>\n",
       "      <td>0.830246</td>\n",
       "      <td>-3.864340</td>\n",
       "      <td>0.793022</td>\n",
       "      <td>-0.982811</td>\n",
       "      <td>149-English_100</td>\n",
       "      <td>0.055921</td>\n",
       "      <td>0.857275</td>\n",
       "      <td>0.096843</td>\n",
       "      <td>0.362917</td>\n",
       "      <td>0.318571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4006 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_id   id                                  reference_summary  \\\n",
       "0               5    5  Die Geschichte spielt in der Zeit des amerikan...   \n",
       "1               5   12  Ein Mann namens Manton hat seine beiden Kinder...   \n",
       "2               5   13  Halpin Frayser, ein 32-j√§hriger Bewohner des N...   \n",
       "3               5   19  Der erste Teil wird von Joel Hetman Jr. erz√§hl...   \n",
       "4               5   28  Ein H√ºhnchen und ein H√§hnchen verreisen im Wag...   \n",
       "...           ...  ...                                                ...   \n",
       "4001  English_100  169  Nach dem Deutsch-Franz√∂sischen Krieg sind eini...   \n",
       "4002  English_100  219  Die Erz√§hlung beginnt mit der Schilderung eine...   \n",
       "4003  English_100  288  Die beiden edlen Vettern ist eine Tragikom√∂die...   \n",
       "4004  English_100  196  Spencer Brydon kehrt nach dreiunddrei√üig Jahre...   \n",
       "4005  English_100  149  In der Stadt Rattleborough wird der wohlhabend...   \n",
       "\n",
       "                                      generated_summary direction    rouge1  \\\n",
       "0     Die Geschichte spielt in Kennesaw Mountain, Ge...    hEN-DE  0.402985   \n",
       "1     Die Geschichte beginnt mit dem Anblick des alt...    hEN-DE  0.310838   \n",
       "2     Halpin Frayser lebt in St. Helena, New York Ci...    hEN-DE  0.362393   \n",
       "3     Die Geschichte beginnt mit dem Tod eines schre...    hEN-DE  0.342400   \n",
       "4     Ein Hund und eine Heule bauen ein sch√∂nes Wage...    hEN-DE  0.367893   \n",
       "...                                                 ...       ...       ...   \n",
       "4001  In a chateau in Normandy, during the Prussian ...    hEN-DE  0.025316   \n",
       "4002  The story is about a group of adventurers who ...    hEN-DE  0.022756   \n",
       "4003  Das St√ºck \"The Two Noble Kinsmen\" wurde von Jo...    hEN-DE  0.185075   \n",
       "4004  Der Protagonist des Textes, Spencer Brydon, is...    hEN-DE  0.221719   \n",
       "4005  The narrator tells the story of the disappeara...    hEN-DE  0.050420   \n",
       "\n",
       "        rougel  bertscore_P  bertscore_R  bertscore_F1  bartscore  moverscore  \\\n",
       "0     0.170149     0.858479     0.847765      0.853088  -7.108416    0.826710   \n",
       "1     0.130879     0.848553     0.827102      0.837690  -5.524875    0.833683   \n",
       "2     0.147009     0.870212     0.842318      0.856038  -5.227464    0.815050   \n",
       "3     0.156800     0.861515     0.847997      0.854702  -4.223670    0.823316   \n",
       "4     0.200669     0.860734     0.872339      0.866497  -4.346346    0.864347   \n",
       "...        ...          ...          ...           ...        ...         ...   \n",
       "4001  0.025316     0.861927     0.830362      0.845850  -4.086033    0.837850   \n",
       "4002  0.020228     0.852632     0.813235      0.832468  -5.981541    0.794588   \n",
       "4003  0.095522     0.852004     0.825930      0.838764  -5.793730    0.844478   \n",
       "4004  0.117647     0.877558     0.825913      0.850952  -4.471878    0.792781   \n",
       "4005  0.033613     0.838078     0.822558      0.830246  -3.864340    0.793022   \n",
       "\n",
       "         menli              idx  DiscoScore_F  DiscoScore_S  MENLI_W0.8  \\\n",
       "0    -0.954164              5-5      0.000000      0.974544    0.140071   \n",
       "1    -0.020967             12-5      3.760938      0.962296    0.492427   \n",
       "2    -0.994908             13-5      0.236795      0.961973    0.127853   \n",
       "3    -0.936292             19-5      0.199864      0.961006    0.149473   \n",
       "4    -0.940130             28-5      0.113075      0.946747    0.164333   \n",
       "...        ...              ...           ...           ...         ...   \n",
       "4001 -0.887630  169-English_100      0.000000      0.830155    0.156658   \n",
       "4002 -0.996035  219-English_100      0.000000      0.838499    0.094636   \n",
       "4003 -0.990916  288-English_100      0.000000      0.882269    0.105439   \n",
       "4004 -0.300782  196-English_100      0.046351      0.852758    0.398793   \n",
       "4005 -0.982811  149-English_100      0.055921      0.857275    0.096843   \n",
       "\n",
       "      MENLI_W0.2  MENLI_W0.3  \n",
       "0       0.492802    0.434014  \n",
       "1       0.500621    0.499255  \n",
       "2       0.505122    0.442244  \n",
       "3       0.503568    0.444552  \n",
       "4       0.568769    0.501363  \n",
       "...          ...         ...  \n",
       "4001    0.459216    0.408790  \n",
       "4002    0.373947    0.327395  \n",
       "4003    0.409473    0.358800  \n",
       "4004    0.546347    0.521755  \n",
       "4005    0.362917    0.318571  \n",
       "\n",
       "[4006 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all_hEn.drop(columns = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174b8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hEn.drop(columns = \"Unnamed: 0\").to_csv(\"eval_metric_hEn.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4445b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_metric = ['rouge1', 'rougel', 'bertscore_P',\n",
    "       'bertscore_R', 'bertscore_F1', \n",
    "                'bartscore', 'moverscore', 'menli','MENLI_W0.8', 'MENLI_W0.3', 'MENLI_W0.2', \"DiscoScore_F\", \"DiscoScore_S\"]\n",
    "\n",
    "columns_list = ['coherence', 'consistency', 'fluency', 'relevance', 'rouge1', 'rougel', 'bartscore', 'moverscore',\n",
    "       'bertscore_P', 'bertscore_R', 'bertscore_F1', 'menli', 'MENLI_W0.8',\n",
    "       'MENLI_W0.3','MENLI_W0.2', \"DiscoScore_F\", \"DiscoScore_S\"]\n",
    "\n",
    "model_order = ['English_25_False', 'English_25_True',\n",
    "       'English_100', \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"11\", 'chatGPT_title', \"chatGPT_e2e\",  \"chatGPT_pipeline\", \n",
    "                                            ]\n",
    "model_order_human = [                \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"11\",  'chatGPT_title', 'chatGPT_pipeline',\n",
    "       ]\n",
    "\n",
    "#columns_list = ['rouge1', 'rougel','bertscore', 'bartscore', 'moverscore',  'menli', 'supert',  'coherence', 'consistency', 'fluency', 'relevance',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b1a5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>reference_summary</th>\n",
       "      <th>generated_summary</th>\n",
       "      <th>direction</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougel</th>\n",
       "      <th>bertscore_P</th>\n",
       "      <th>bertscore_R</th>\n",
       "      <th>bertscore_F1</th>\n",
       "      <th>bartscore</th>\n",
       "      <th>moverscore</th>\n",
       "      <th>menli</th>\n",
       "      <th>idx</th>\n",
       "      <th>DiscoScore_F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI_W0.8</th>\n",
       "      <th>MENLI_W0.2</th>\n",
       "      <th>MENLI_W0.3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_100</th>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_25_False</th>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_25_True</th>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_e2e</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Unnamed: 0   id  reference_summary  generated_summary  \\\n",
       "model_id                                                                  \n",
       "1                        289  289                289                289   \n",
       "10                       289  289                289                289   \n",
       "11                       289  289                289                289   \n",
       "2                        289  289                289                289   \n",
       "3                        289  289                289                289   \n",
       "4                        289  289                289                289   \n",
       "5                        289  289                289                289   \n",
       "6                        289  289                289                289   \n",
       "English_100                0  275                275                275   \n",
       "English_25_False           0  276                276                276   \n",
       "English_25_True            0  276                276                276   \n",
       "chatGPT_e2e              289  289                289                289   \n",
       "chatGPT_pipeline         289  289                289                289   \n",
       "chatGPT_title            289  289                289                289   \n",
       "\n",
       "                  direction  rouge1  rougel  bertscore_P  bertscore_R  \\\n",
       "model_id                                                                \n",
       "1                       289     289     289          289          289   \n",
       "10                      289     289     289          289          289   \n",
       "11                      289     289     289          289          289   \n",
       "2                       289     289     289          289          289   \n",
       "3                       289     289     289          289          289   \n",
       "4                       289     289     289          289          289   \n",
       "5                       289     289     289          289          289   \n",
       "6                       289     289     289          289          289   \n",
       "English_100             275     275     275          275          275   \n",
       "English_25_False        276     276     276          276          276   \n",
       "English_25_True         276     276     276          276          276   \n",
       "chatGPT_e2e             289     289     289          289          289   \n",
       "chatGPT_pipeline        289     289     289          289          289   \n",
       "chatGPT_title           289     289     289          289          289   \n",
       "\n",
       "                  bertscore_F1  bartscore  moverscore  menli  idx  \\\n",
       "model_id                                                            \n",
       "1                          289        289         289    289  289   \n",
       "10                         289        289         289    289  289   \n",
       "11                         289        289         289    289  289   \n",
       "2                          289        289         289    289  289   \n",
       "3                          289        289         289    289  289   \n",
       "4                          289        289         289    289  289   \n",
       "5                          289        289         289    289  289   \n",
       "6                          289        289         289    289  289   \n",
       "English_100                275        275         275    275  275   \n",
       "English_25_False           276        276         276    276  276   \n",
       "English_25_True            276        276         276    276  276   \n",
       "chatGPT_e2e                289        289         289    289  289   \n",
       "chatGPT_pipeline           289        289         289    289  289   \n",
       "chatGPT_title              289        289         289    289  289   \n",
       "\n",
       "                  DiscoScore_F  DiscoScore_S  MENLI_W0.8  MENLI_W0.2  \\\n",
       "model_id                                                               \n",
       "1                          289           289         289         289   \n",
       "10                         289           289         289         289   \n",
       "11                         289           289         289         289   \n",
       "2                          289           289         289         289   \n",
       "3                          289           289         289         289   \n",
       "4                          289           289         289         289   \n",
       "5                          289           289         289         289   \n",
       "6                          289           289         289         289   \n",
       "English_100                275           275         275         275   \n",
       "English_25_False           276           276         276         276   \n",
       "English_25_True            276           276         276         276   \n",
       "chatGPT_e2e                289           289         289         289   \n",
       "chatGPT_pipeline           289           289         289         289   \n",
       "chatGPT_title              289           289         289         289   \n",
       "\n",
       "                  MENLI_W0.3  \n",
       "model_id                      \n",
       "1                        289  \n",
       "10                       289  \n",
       "11                       289  \n",
       "2                        289  \n",
       "3                        289  \n",
       "4                        289  \n",
       "5                        289  \n",
       "6                        289  \n",
       "English_100              275  \n",
       "English_25_False         276  \n",
       "English_25_True          276  \n",
       "chatGPT_e2e              289  \n",
       "chatGPT_pipeline         289  \n",
       "chatGPT_title            289  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all_hEn.groupby(\"model_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf7792f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id\n",
      "1                   275\n",
      "10                  275\n",
      "11                  275\n",
      "2                   275\n",
      "3                   275\n",
      "4                   275\n",
      "5                   275\n",
      "6                   275\n",
      "English_100         275\n",
      "English_25_False    275\n",
      "English_25_True     275\n",
      "chatGPT_e2e         275\n",
      "chatGPT_pipeline    275\n",
      "chatGPT_title       275\n",
      "Name: menli, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougel</th>\n",
       "      <th>bertscore_P</th>\n",
       "      <th>bertscore_R</th>\n",
       "      <th>bertscore_F1</th>\n",
       "      <th>bartscore</th>\n",
       "      <th>moverscore</th>\n",
       "      <th>menli</th>\n",
       "      <th>MENLI_W0.8</th>\n",
       "      <th>MENLI_W0.3</th>\n",
       "      <th>MENLI_W0.2</th>\n",
       "      <th>DiscoScore_F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>English_25_False</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-5.320</td>\n",
       "      <td>0.814</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_25_True</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.833</td>\n",
       "      <td>-5.350</td>\n",
       "      <td>0.814</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_100</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.858</td>\n",
       "      <td>-4.914</td>\n",
       "      <td>0.824</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.321</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.848</td>\n",
       "      <td>-5.275</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.499</td>\n",
       "      <td>1.653</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.328</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.849</td>\n",
       "      <td>-5.301</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.503</td>\n",
       "      <td>1.411</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.849</td>\n",
       "      <td>-5.276</td>\n",
       "      <td>0.824</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1.157</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.316</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.848</td>\n",
       "      <td>-5.253</td>\n",
       "      <td>0.826</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.498</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.321</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-5.311</td>\n",
       "      <td>0.825</td>\n",
       "      <td>-0.618</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.491</td>\n",
       "      <td>1.804</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.328</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.850</td>\n",
       "      <td>-5.250</td>\n",
       "      <td>0.826</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.510</td>\n",
       "      <td>1.050</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.341</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.850</td>\n",
       "      <td>-5.255</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>0.288</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.849</td>\n",
       "      <td>-5.009</td>\n",
       "      <td>0.822</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_e2e</th>\n",
       "      <td>0.282</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.859</td>\n",
       "      <td>-4.949</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>0.285</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.858</td>\n",
       "      <td>-4.933</td>\n",
       "      <td>0.824</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rouge1  rougel  bertscore_P  bertscore_R  bertscore_F1  \\\n",
       "model_id                                                                   \n",
       "English_25_False   0.315   0.131        0.830        0.839         0.834   \n",
       "English_25_True    0.311   0.130        0.829        0.838         0.833   \n",
       "English_100        0.269   0.143        0.874        0.843         0.858   \n",
       "1                  0.321   0.142        0.853        0.843         0.848   \n",
       "2                  0.328   0.143        0.853        0.845         0.849   \n",
       "3                  0.328   0.144        0.854        0.844         0.849   \n",
       "4                  0.316   0.141        0.855        0.841         0.848   \n",
       "5                  0.321   0.145        0.852        0.841         0.847   \n",
       "6                  0.328   0.147        0.855        0.844         0.850   \n",
       "11                 0.341   0.153        0.855        0.845         0.850   \n",
       "chatGPT_title      0.288   0.135        0.857        0.841         0.849   \n",
       "chatGPT_e2e        0.282   0.150        0.876        0.843         0.859   \n",
       "chatGPT_pipeline   0.285   0.147        0.874        0.843         0.858   \n",
       "\n",
       "                  bartscore  moverscore  menli  MENLI_W0.8  MENLI_W0.3  \\\n",
       "model_id                                                                 \n",
       "English_25_False     -5.320       0.814 -0.648       0.236       0.387   \n",
       "English_25_True      -5.350       0.814 -0.652       0.234       0.383   \n",
       "English_100          -4.914       0.824 -0.638       0.274       0.506   \n",
       "1                    -5.275       0.823 -0.605       0.273       0.462   \n",
       "2                    -5.301       0.823 -0.600       0.276       0.465   \n",
       "3                    -5.276       0.824 -0.601       0.276       0.467   \n",
       "4                    -5.253       0.826 -0.613       0.269       0.460   \n",
       "5                    -5.311       0.825 -0.618       0.266       0.453   \n",
       "6                    -5.250       0.826 -0.587       0.282       0.472   \n",
       "11                   -5.255       0.827 -0.624       0.268       0.468   \n",
       "chatGPT_title        -5.009       0.822 -0.745       0.218       0.444   \n",
       "chatGPT_e2e          -4.949       0.823 -0.655       0.269       0.509   \n",
       "chatGPT_pipeline     -4.933       0.824 -0.636       0.274       0.505   \n",
       "\n",
       "                  MENLI_W0.2  DiscoScore_F  DiscoScore_S  \n",
       "model_id                                                  \n",
       "English_25_False       0.417         0.301         0.956  \n",
       "English_25_True        0.413         0.291         0.955  \n",
       "English_100            0.552         0.605         0.936  \n",
       "1                      0.499         1.653         0.953  \n",
       "2                      0.503         1.411         0.958  \n",
       "3                      0.505         1.157         0.958  \n",
       "4                      0.498         1.500         0.950  \n",
       "5                      0.491         1.804         0.955  \n",
       "6                      0.510         1.050         0.957  \n",
       "11                     0.508         0.764         0.961  \n",
       "chatGPT_title          0.489         0.590         0.958  \n",
       "chatGPT_e2e            0.557         0.572         0.943  \n",
       "chatGPT_pipeline       0.551         0.797         0.946  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate table 1 eval_metrics\n",
    "filtered = output_all_hEn.set_index(\"id\").loc[output_all_hEn[output_all_hEn.model_id == \"English_100\"].id]\n",
    "latex = filtered.groupby(\"model_id\").mean().iloc[:, -14:].loc[model_order, order_metric].round(4)#.to_csv(\"tabular/hDe/metric_eval_mean.csv\", index = True)\n",
    "print(filtered.groupby(\"model_id\").menli.count())\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf6b3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_string(row):\n",
    "    lst = [\"{:.3f}\".format(i.round(3)) for i in row.values]\n",
    "    lst_ = [\"/\".join(lst[:2]), \"/\".join(lst[2:5]), lst[5], lst[6], \"/\".join(lst[7:])]\n",
    "    print(lst_)\n",
    "    return \"&\".join(lst_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0403f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.315/0.131', '0.830/0.839/0.834', '-5.320', '0.814', '-0.648/0.236/0.387/0.418/0.301/0.956']\n",
      "['0.311/0.130', '0.829/0.838/0.833', '-5.350', '0.814', '-0.652/0.234/0.383/0.413/0.291/0.955']\n",
      "['0.269/0.143', '0.874/0.843/0.858', '-4.914', '0.824', '-0.638/0.274/0.506/0.552/0.605/0.936']\n",
      "['0.321/0.142', '0.853/0.843/0.848', '-5.275', '0.823', '-0.604/0.273/0.462/0.500/1.653/0.953']\n",
      "['0.328/0.143', '0.853/0.845/0.848', '-5.301', '0.823', '-0.600/0.276/0.465/0.503/1.410/0.958']\n",
      "['0.328/0.144', '0.854/0.844/0.849', '-5.276', '0.824', '-0.600/0.276/0.467/0.505/1.158/0.958']\n",
      "['0.316/0.141', '0.855/0.841/0.848', '-5.253', '0.826', '-0.613/0.269/0.460/0.498/1.500/0.950']\n",
      "['0.321/0.146', '0.852/0.841/0.847', '-5.311', '0.825', '-0.618/0.266/0.453/0.491/1.804/0.955']\n",
      "['0.328/0.147', '0.855/0.844/0.850', '-5.250', '0.826', '-0.586/0.282/0.472/0.510/1.050/0.957']\n",
      "['0.341/0.153', '0.855/0.845/0.850', '-5.256', '0.827', '-0.624/0.268/0.468/0.508/0.764/0.961']\n",
      "['0.288/0.135', '0.857/0.840/0.849', '-5.009', '0.822', '-0.745/0.218/0.444/0.489/0.590/0.958']\n",
      "['0.282/0.150', '0.876/0.843/0.859', '-4.949', '0.823', '-0.655/0.268/0.509/0.557/0.572/0.943']\n",
      "['0.285/0.147', '0.874/0.843/0.858', '-4.933', '0.824', '-0.636/0.274/0.505/0.551/0.797/0.946']\n"
     ]
    }
   ],
   "source": [
    "#generate latex\n",
    "pd.DataFrame(latex.apply(lambda x: turn_string(x), axis = 1) + \"\\\\\" + \"\\\\\").to_csv(\"experiments/latex/hEn-latex_experiment-multilingual.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8abe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hEn = pd.merge(eval_hEn[[ 'coherence','consistency', 'fluency', 'relevance', 'id', \"model_id\", \"annotator\"]], filtered, on = [\"id\", \"model_id\"], how = \"left\")\n",
    "merged_hEn = merged_hEn.dropna(subset = [\"coherence\", \"menli\"])\n",
    "merged_hEn[\"sum\"] = merged_hEn['coherence'] + merged_hEn['consistency'] + merged_hEn['fluency'] + merged_hEn['relevance']\n",
    "merged_hEn = merged_hEn[merged_hEn[\"sum\"] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df7315f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/4742tn7s13l5fcnstlm_d7g40000gn/T/ipykernel_34000/1196222808.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  merged_hEn.annotator_orig = merged_hEn.annotator\n"
     ]
    }
   ],
   "source": [
    "# merge annotators \n",
    "merged_hEn.annotator_orig = merged_hEn.annotator\n",
    "merged_hEn.annotator = merged_hEn.annotator.replace({\"4\":\"1\", \"5\": \"3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "843332e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hEn[\"id_model\"] = merged_hEn.apply(lambda x: str(x[\"id\"]) + \"_\" + x[\"model_id\"], axis = 1)\n",
    "intersection_of_models = set(merged_hEn[(merged_hEn.annotator != \"6\" )].id_model.unique()).intersection(set(merged_hEn[(merged_hEn.annotator == \"6\" )].id_model.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cde1ed37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>consistency</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.660</td>\n",
       "      <td>1.310</td>\n",
       "      <td>1.760</td>\n",
       "      <td>1.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.625</td>\n",
       "      <td>1.521</td>\n",
       "      <td>1.781</td>\n",
       "      <td>1.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.516</td>\n",
       "      <td>1.344</td>\n",
       "      <td>1.422</td>\n",
       "      <td>1.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.716</td>\n",
       "      <td>1.568</td>\n",
       "      <td>1.943</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.583</td>\n",
       "      <td>1.486</td>\n",
       "      <td>1.597</td>\n",
       "      <td>1.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.500</td>\n",
       "      <td>1.402</td>\n",
       "      <td>1.728</td>\n",
       "      <td>1.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.446</td>\n",
       "      <td>1.337</td>\n",
       "      <td>1.620</td>\n",
       "      <td>1.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.620</td>\n",
       "      <td>1.370</td>\n",
       "      <td>1.848</td>\n",
       "      <td>1.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_100</th>\n",
       "      <td>3.444</td>\n",
       "      <td>3.556</td>\n",
       "      <td>3.556</td>\n",
       "      <td>3.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_25_False</th>\n",
       "      <td>1.750</td>\n",
       "      <td>1.429</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_25_True</th>\n",
       "      <td>1.679</td>\n",
       "      <td>1.393</td>\n",
       "      <td>1.571</td>\n",
       "      <td>1.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_e2e</th>\n",
       "      <td>3.212</td>\n",
       "      <td>3.182</td>\n",
       "      <td>3.364</td>\n",
       "      <td>2.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>3.365</td>\n",
       "      <td>3.568</td>\n",
       "      <td>3.419</td>\n",
       "      <td>3.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>2.651</td>\n",
       "      <td>2.395</td>\n",
       "      <td>3.151</td>\n",
       "      <td>2.209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coherence  consistency  fluency  relevance\n",
       "model_id                                                    \n",
       "1                     1.660        1.310    1.760      1.310\n",
       "10                    1.625        1.521    1.781      1.344\n",
       "11                    1.516        1.344    1.422      1.188\n",
       "2                     1.716        1.568    1.943      1.500\n",
       "3                     1.583        1.486    1.597      1.236\n",
       "4                     1.500        1.402    1.728      1.359\n",
       "5                     1.446        1.337    1.620      1.250\n",
       "6                     1.620        1.370    1.848      1.435\n",
       "English_100           3.444        3.556    3.556      3.296\n",
       "English_25_False      1.750        1.429    1.750      1.107\n",
       "English_25_True       1.679        1.393    1.571      1.071\n",
       "chatGPT_e2e           3.212        3.182    3.364      2.848\n",
       "chatGPT_pipeline      3.365        3.568    3.419      3.135\n",
       "chatGPT_title         2.651        2.395    3.151      2.209"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_hEn.groupby('model_id').mean().iloc[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fca3447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human annotaiton All\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>consistency</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.012</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2.298</td>\n",
       "      <td>1.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.889</td>\n",
       "      <td>1.792</td>\n",
       "      <td>2.819</td>\n",
       "      <td>1.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.986</td>\n",
       "      <td>1.792</td>\n",
       "      <td>2.403</td>\n",
       "      <td>1.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.881</td>\n",
       "      <td>1.798</td>\n",
       "      <td>2.381</td>\n",
       "      <td>1.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.764</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.375</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>3.125</td>\n",
       "      <td>2.125</td>\n",
       "      <td>2.812</td>\n",
       "      <td>2.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>3.062</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.062</td>\n",
       "      <td>3.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coherence  consistency  fluency  relevance\n",
       "model_id                                                    \n",
       "1                     2.012        1.500    2.298      1.595\n",
       "2                     1.889        1.792    2.819      1.792\n",
       "3                     2.000        1.625    1.625      1.625\n",
       "4                     1.986        1.792    2.403      1.958\n",
       "5                     1.881        1.798    2.381      1.750\n",
       "6                     1.764        1.667    2.375      1.972\n",
       "11                    2.375        2.000    1.875      1.750\n",
       "chatGPT_title         3.125        2.125    2.812      2.125\n",
       "chatGPT_pipeline      3.062        3.375    3.062      3.375"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# human annotation result avg. \n",
    "print(\"human annotaiton All\")\n",
    "summary_level = pd.DataFrame(merged_hEn[(merged_hEn.annotator != \"6\")].set_index(\"id_model\").loc[intersection_of_models].groupby([\"model_id\", \"id\"]).mean()).reset_index() #.iloc[:,:4].loc[model_order_human]\n",
    "human_mean = summary_level.groupby(\"model_id\").mean().iloc[:,1:5].loc[model_order_human]\n",
    "human_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e56c9b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>consistency</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.286</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.571</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.667</td>\n",
       "      <td>1.167</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.500</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.286</td>\n",
       "      <td>1.071</td>\n",
       "      <td>1.286</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.333</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>2.500</td>\n",
       "      <td>2.250</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>3.250</td>\n",
       "      <td>3.250</td>\n",
       "      <td>3.500</td>\n",
       "      <td>3.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coherence  consistency  fluency  relevance\n",
       "model_id                                                    \n",
       "1                     1.286        1.000    1.571      1.000\n",
       "2                     1.667        1.167    1.667      1.000\n",
       "3                     1.000        1.000    1.000      1.000\n",
       "4                     1.500        1.333    1.500      1.167\n",
       "5                     1.286        1.071    1.286      1.000\n",
       "6                     1.333        1.333    1.500      1.000\n",
       "11                    1.500        1.000    1.500      1.000\n",
       "chatGPT_title         2.500        2.250    3.000      2.000\n",
       "chatGPT_pipeline      3.250        3.250    3.500      3.250"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average ChatGPT annotation results\n",
    "summary_level = pd.DataFrame(merged_hEn[merged_hEn.annotator == \"6\"].set_index(\"id_model\").loc[intersection_of_models].groupby([\"model_id\", \"id\"]).mean()).reset_index() #.iloc[:,:4].loc[model_order_human]\n",
    "chatGPT_mean = summary_level.groupby(\"model_id\").mean().iloc[:,1:5].loc[model_order_human]\n",
    "chatGPT_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a32a29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen plots\n",
    "order_anno =[\"coherence_human\",\"coherence_chatGPT\", \"consistency_human\", \"consistency_chatGPT\",\n",
    "             \"fluency_human\", \"fluency_chatGPT\", \"relevance_human\",   'relevance_chatGPT']\n",
    "annotation_human_chatty = pd.merge(human_mean.reset_index(), chatGPT_mean.reset_index(), on = \"model_id\", \n",
    "         suffixes = [\"_human\", \"_chatGPT\"], how = \"outer\").set_index(\"model_id\").loc[model_order_human, order_anno].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "522dab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.01/1.29', '1.50/1.00', '2.30/1.57', '1.60/1.00']\n",
      "['1.89/1.67', '1.79/1.17', '2.82/1.67', '1.79/1.00']\n",
      "['2.00/1.00', '1.62/1.00', '1.62/1.00', '1.62/1.00']\n",
      "['1.99/1.50', '1.79/1.33', '2.40/1.50', '1.96/1.17']\n",
      "['1.88/1.29', '1.80/1.07', '2.38/1.29', '1.75/1.00']\n",
      "['1.76/1.33', '1.67/1.33', '2.38/1.50', '1.97/1.00']\n",
      "['2.38/1.50', '2.00/1.00', '1.88/1.50', '1.75/1.00']\n",
      "['3.12/2.50', '2.12/2.25', '2.81/3.00', '2.12/2.00']\n",
      "['3.06/3.25', '3.38/3.25', '3.06/3.50', '3.38/3.25']\n"
     ]
    }
   ],
   "source": [
    "def turn_string(row):\n",
    "    lst = [\"{:.2f}\".format(i.round(3)) for i in row.values]\n",
    "    lst_ = [\"/\".join(lst[:2]), \"/\".join(lst[2:4]), \"/\".join(lst[4:6]), \"/\".join(lst[6:])]\n",
    "    print(lst_)\n",
    "    return \"&\".join(lst_)\n",
    "#generate latex\n",
    "pd.DataFrame(annotation_human_chatty.apply(lambda x: turn_string(x) + \"\\\\\" + \"\\\\\", axis = 1)).to_csv(\"experiments/latex/hEn_latex_human_chatty_anno.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "297b3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hEn[\"overlap_count\"] = merged_hEn.groupby([\"model_id\", \"id\"]).generated_summary.transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd9823da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only compare with more than 3 annotators \n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "from sklearn.metrics import cohen_kappa_score \n",
    "import scipy\n",
    "def agreement_return(dim, annotator_lst_hEn, merged_hEnidlst, df, exclude = True):\n",
    "    tmp = agreement(dim, annotator_lst_hEn, merged_hEnidlst, df)\n",
    "    cor_lst = []\n",
    "    for a1 in tmp.index:\n",
    "        if exclude:\n",
    "            if dim == \"fluency\":\n",
    "                a1 = int(a1)+1 # exclude fluency from annotator 1\n",
    "                #print(a1, dim)\n",
    "        for a2 in  tmp.index:\n",
    "            if int(a2)>int(a1):\n",
    "                agree = tmp.loc[[str(a1),str(a2)]].dropna(axis='columns')\n",
    "                if len(agree.loc[str(a1)]) > 0:\n",
    "                    cor = spearmanr(agree.loc[str(a1)], agree.loc[str(a2)]).correlation\n",
    "                    #print(cor, agree, \"\\n\\n\\n\\n\")\n",
    "                    k1 = [int(val) for val in agree.loc[str(a1)]]\n",
    "                    k2 = [int(val) for val in agree.loc[str(a2)]]\n",
    "                    kappa = cohen_kappa_score(k1, k2)\n",
    "                    cor_lst.append((a1, a2, cor, kappa, len(agree.loc[str(a1)]), agree.columns.tolist())) # kappa,\n",
    "                else: print(\"length problem\", agree)\n",
    "    return cor_lst\n",
    "\n",
    "def agreement(dim, annotator_lst,idlst, df = merged_hEn, ):\n",
    "    collection = {}\n",
    "    for id_ in idlst:\n",
    "        annotation_lst = []\n",
    "        for annotator in annotator_lst:\n",
    "            sub = df[(df.id == id_) & (df.annotator == annotator)]\n",
    "            if len(sub)>0:\n",
    "                annotation_lst.append(sub[dim].values[0])\n",
    "            else:\n",
    "                annotation_lst.append(np.nan)\n",
    "            collection[id_] = annotation_lst\n",
    "    return pd.DataFrame(collection, index = annotator_lst)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8deafc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anno_res(df, exclude):\n",
    "    merged_hEnidlst = df.id.unique()\n",
    "    annotator_lst_hEn = df.annotator.unique()\n",
    "    df_anno = pd.DataFrame()\n",
    "    for dim in ['coherence', 'consistency', 'fluency', 'relevance']:\n",
    "        #print(\"!!!!!\", dim)\n",
    "        cor_lst = agreement_return(dim, annotator_lst_hEn,merged_hEnidlst, df = df, exclude = exclude)\n",
    "        df_anno_ = pd.DataFrame(cor_lst, columns = [\"annotator1\", \"annotator2\", \"spearman\", \"kappa\",\"annotation_count\", \"id_list\"]) #\"kappa\",\n",
    "        df_anno_[\"dimension\"] = dim\n",
    "        #print(df_anno_)\n",
    "        df_anno = pd.concat([df_anno, df_anno_])\n",
    "        #print(dim, \"agreement: \", cor_lst)\n",
    "    return df_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4027e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence</th>\n",
       "      <td>0.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluency</th>\n",
       "      <td>0.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance</th>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             spearman\n",
       "dimension            \n",
       "coherence       0.353\n",
       "consistency     0.493\n",
       "fluency         0.433\n",
       "relevance       0.605"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = merged_hEn[(merged_hEn[\"sum\"] >0) ] \n",
    "df_anno = anno_res(df, exclude = False)\n",
    "df_anno[(df_anno.annotation_count > 10) & (df_anno.annotator2 != \"6\") & (df_anno.annotator2 != \"6\")].groupby(\"dimension\").mean().iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21fce5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.DataFrame(df.set_index(\"annotator\").loc[[\"1\", \"2\", \"3\"]].groupby([\"model_id\", 'id']).mean()).reset_index()\n",
    "chatty = df[df.annotator == \"6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59d83740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human chatty corr\n",
    "human_chatty = pd.merge(human[['model_id', 'id', 'coherence', 'consistency', 'fluency', 'relevance',]], chatty[['model_id', 'id', 'coherence', 'consistency', 'fluency', 'relevance',]], on = [\"id\", \"model_id\"], how = \"left\", suffixes = [\"_human\", \"_chatty\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa9e76df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence_chatty</th>\n",
       "      <th>consistency_chatty</th>\n",
       "      <th>fluency_chatty</th>\n",
       "      <th>relevance_chatty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence_human</th>\n",
       "      <td>0.320</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency_human</th>\n",
       "      <td>0.342</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluency_human</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance_human</th>\n",
       "      <td>0.389</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   coherence_chatty  consistency_chatty  fluency_chatty  \\\n",
       "coherence_human               0.320               0.293           0.462   \n",
       "consistency_human             0.342               0.377           0.380   \n",
       "fluency_human                 0.305               0.147           0.392   \n",
       "relevance_human               0.389               0.457           0.495   \n",
       "\n",
       "                   relevance_chatty  \n",
       "coherence_human               0.311  \n",
       "consistency_human             0.372  \n",
       "fluency_human                 0.245  \n",
       "relevance_human               0.455  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_chatty.corr(\"spearman\").loc[[\"coherence_human\", \"consistency_human\", \"fluency_human\", \"relevance_human\"], [\"coherence_chatty\", \"consistency_chatty\", \"fluency_chatty\", \"relevance_chatty\"]].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58ebc80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ['coherence', 'consistency', 'fluency', 'relevance'] + order_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "382a5f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_level_coorr(df_):\n",
    "    df = df_.groupby([\"id\", \"model_id\"])[columns_list].mean() # summary level aggregation\n",
    "    dct = {}\n",
    "    for dim in ['coherence', 'consistency', 'fluency', 'relevance']:\n",
    "        lst_tau = []\n",
    "        lst_spearmanr = []\n",
    "        lst_pr = []\n",
    "        lst_ptau = []\n",
    "        for metric in order_metric:\n",
    "            if dim == \"fluency\":\n",
    "                df = df_[df_.annotator != \"1\"].groupby([\"id\", \"model_id\"])[columns_list].mean()\n",
    "               # except:pass\n",
    "            #else: \n",
    "             #   tmp = df\n",
    "            lst_tau.append(kendalltau(y=df[dim], x=df[metric]).correlation) #scipy.stats.weightedtau \n",
    "            lst_ptau.append(kendalltau(y=df[dim], x=df[metric]).pvalue)\n",
    "            lst_spearmanr.append(spearmanr(df[dim], df[metric]).correlation)\n",
    "            lst_pr.append(spearmanr(df[dim],df[metric]).pvalue)\n",
    "        dct[dim] = lst_spearmanr\n",
    "        dct[dim+\"_pvalue\"] = lst_pr\n",
    "        #dct[dim+\"_tau\"] = lst_tau\n",
    "        #dct[dim+\"_pvalue_tau\"] = lst_ptau\n",
    "\n",
    "    return pd.DataFrame(dct, index = order_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c704e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hEn = merged_hEn.rename(columns = {\"rouge1\": \"ROUGE-1\", \"rougel\":\"ROUGE-L\", 'bertscore_P': \"BERTScore-P\", 'bertscore_R':\"BERTScore-R\", \n",
    "                      'bertscore_F1': \"BERTScore-F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI-W1',\n",
    "                                    'MENLI_W0.8': 'MENLI-W.8', 'MENLI_W0.3':'MENLI-W.3', 'MENLI_W0.2':'MENLI-W.2', \"DiscoScore_F\":\"DiscoScore-F\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a415732a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_diff = ['ROUGE-1', 'ROUGE-L', 'BERTScore-P', 'BERTScore-R', 'BERTScore-F1',\n",
    "       'BARTScore', 'MoverScore', 'MENLI-W1','MENLI-W.8',  'MENLI-W.3', 'MENLI-W.2', 'DiscoScore-F', \n",
    "               \n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9bc1fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ = merged_hEn[(merged_hEn.annotator != \"6\" )].set_index(\"id_model\").loc[intersection_of_models]#.set_index(\"annotator\").loc[[\"1\",\"2\",\"3\"]].reset_index()#.loc[[\"4\",\"5\"]].reset_index()# \n",
    "inter1 = df_.groupby(\"id_model\").mean()\n",
    "#segment_human = segment_level_coorr(df_)\n",
    "#segment_human.round(3)\n",
    "caseALL = inter1.corr(\"spearman\").iloc[:4, 6:19]\n",
    "from scipy.stats import pearsonr\n",
    "pval = inter1.corr(method=lambda x, y: pearsonr(x, y)[1]).iloc[:4, 6:19] #- np.eye(*caseF.shape)\n",
    "p = pval.applymap(lambda x: \"\\n\\n\" + ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "label = caseALL.round(2).astype(str) + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "691e074a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (8,3))\n",
    "X = caseALL.loc[:,metric_diff].round(2)\n",
    "sns.heatmap(caseALL.loc[:,metric_diff].round(2),\n",
    "            #mask= (p.loc[:,metric_diff] != \"*\"),\n",
    "            # Use annot key with np.array as value containing strings of data + latex \n",
    "            # prefixes/suffices making the bold/italic/underline formatting\n",
    "            #annot_kws={\"style\": \"italic\", \"weight\": \"bold\"},\n",
    "            annot=label.loc[:,metric_diff],\n",
    "            # fmt key must be empty, formatting error otherwise\n",
    "            fmt=\"\",#'0.2f',,\n",
    "            cbar=False,\n",
    "            linewidth=0.5,\n",
    "            cmap=\"coolwarm_r\")\n",
    "plt.savefig('hEn-mul-segment_cor.pdf',bbox_inches='tight', pad_inches=0 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0efcc35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore-P</th>\n",
       "      <th>BERTScore-R</th>\n",
       "      <th>BERTScore-F1</th>\n",
       "      <th>BARTScore</th>\n",
       "      <th>MoverScore</th>\n",
       "      <th>MENLI-W1</th>\n",
       "      <th>DiscoScore-F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI-W.8</th>\n",
       "      <th>MENLI-W.2</th>\n",
       "      <th>MENLI-W.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence</th>\n",
       "      <td>0.3*</td>\n",
       "      <td>0.32*</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.29*</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.63***</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.54***</td>\n",
       "      <td>0.41**</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.45**</td>\n",
       "      <td>0.4*</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.34*</td>\n",
       "      <td>0.42**</td>\n",
       "      <td>0.4**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluency</th>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.42*</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.17*</td>\n",
       "      <td>-0.47*</td>\n",
       "      <td>-0.45*</td>\n",
       "      <td>-0.47*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance</th>\n",
       "      <td>0.2*</td>\n",
       "      <td>0.32**</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26*</td>\n",
       "      <td>0.28*</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28**</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ROUGE-1  ROUGE-L BERTScore-P BERTScore-R BERTScore-F1 BARTScore  \\\n",
       "coherence      0.3*    0.32*       -0.03        0.21         0.19     -0.13   \n",
       "consistency    0.42  0.63***        0.11     0.54***       0.41**      0.07   \n",
       "fluency       -0.28    -0.22       -0.18       -0.35         -0.3      0.22   \n",
       "relevance      0.2*   0.32**        0.17       0.26*        0.28*      0.14   \n",
       "\n",
       "            MoverScore MENLI-W1 DiscoScore-F DiscoScore_S MENLI-W.8 MENLI-W.2  \\\n",
       "coherence        0.29*      0.3         0.05         0.25      0.23       0.2   \n",
       "consistency     0.45**     0.4*          0.1         0.29     0.34*    0.42**   \n",
       "fluency          -0.27   -0.42*        -0.34       -0.17*    -0.47*    -0.45*   \n",
       "relevance       0.28**     0.14        -0.02         0.16      0.11      0.21   \n",
       "\n",
       "            MENLI-W.3  \n",
       "coherence        0.22  \n",
       "consistency     0.4**  \n",
       "fluency        -0.47*  \n",
       "relevance        0.17  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = merged_hEn[(merged_hEn.annotator != \"6\" )].set_index(\"id_model\").loc[intersection_of_models]#.set_index(\"annotator\").loc[[\"1\",\"2\",\"3\"]].reset_index()#.loc[[\"4\",\"5\"]].reset_index()# \n",
    "inter2 = df_[(df_.model_id != 'chatGPT_title') & (df_.model_id != 'chatGPT_pipeline')].groupby(\"id_model\").mean()\n",
    "#segment_human = segment_level_coorr(df_)\n",
    "#segment_human.round(3)\n",
    "caseF = inter2.corr(\"spearman\").iloc[:4, 6:19]\n",
    "from scipy.stats import pearsonr\n",
    "pval = inter2.corr(method=lambda x, y: pearsonr(x, y)[1]).iloc[:4, 6:19] #- np.eye(*caseF.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "caseF.round(2).astype(str) + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dab48fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatGPT outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore-P</th>\n",
       "      <th>BERTScore-R</th>\n",
       "      <th>BERTScore-F1</th>\n",
       "      <th>BARTScore</th>\n",
       "      <th>MoverScore</th>\n",
       "      <th>MENLI-W1</th>\n",
       "      <th>DiscoScore-F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI-W.8</th>\n",
       "      <th>MENLI-W.2</th>\n",
       "      <th>MENLI-W.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence</th>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.87*</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluency</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.87*</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ROUGE-1 ROUGE-L BERTScore-P BERTScore-R BERTScore-F1 BARTScore  \\\n",
       "coherence      0.14   -0.11        0.37       -0.19        -0.01     -0.23   \n",
       "consistency    0.63    0.54       0.87*        0.22          0.5       0.3   \n",
       "fluency       -0.14   -0.14        0.36       -0.14        -0.23     -0.14   \n",
       "relevance      0.63    0.54       0.87*        0.22          0.5       0.3   \n",
       "\n",
       "            MoverScore MENLI-W1 DiscoScore-F DiscoScore_S MENLI-W.8 MENLI-W.2  \\\n",
       "coherence        -0.23     0.31         0.24         0.76      0.31      0.12   \n",
       "consistency        0.3     0.26         0.63         0.38      0.44      0.44   \n",
       "fluency          -0.14     0.02         0.79         0.49     -0.04     -0.18   \n",
       "relevance          0.3     0.26         0.63         0.38      0.44      0.44   \n",
       "\n",
       "            MENLI-W.3  \n",
       "coherence        0.12  \n",
       "consistency      0.44  \n",
       "fluency         -0.18  \n",
       "relevance        0.44  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"chatGPT outputs\")\n",
    "df_ = merged_hEn[(merged_hEn.annotator != \"6\" )].set_index(\"id_model\").loc[intersection_of_models]#.set_index(\"annotator\").loc[[\"1\",\"2\",\"3\"]].reset_index()#.loc[[\"4\",\"5\"]].reset_index()# \n",
    "inter2 = df_[(df_.model_id == 'chatGPT_title') | (df_.model_id == 'chatGPT_pipeline')].groupby(\"id_model\").mean()\n",
    "#segment_human = segment_level_coorr(df_)\n",
    "#segment_human.round(3)\n",
    "caseF = inter2.corr(\"spearman\").iloc[:4, 6:19]\n",
    "from scipy.stats import pearsonr\n",
    "pval = inter2.corr(method=lambda x, y: pearsonr(x, y)[1]).iloc[:4, 6:19] #- np.eye(*caseF.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "caseF.round(2).astype(str) + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef485d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17474299",
   "metadata": {},
   "outputs": [],
   "source": [
    "boostrap = []\n",
    "for i in range(20000):\n",
    "    diff = inter2.sample(20).corr(\"spearman\").iloc[:4, 6:19] - inter1.sample(20).corr(\"spearman\").iloc[:4, 6:19] \n",
    "    boostrap.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import statsmodels.stats.api as sms\n",
    "diff = pd.DataFrame(columns = caseF.columns, index = caseF.index)\n",
    "for dim in caseF.index:\n",
    "    for metric in caseF.columns:\n",
    "        lst = []\n",
    "        for df in boostrap:\n",
    "            lst.append(df.loc[dim, metric])\n",
    "        conf = sms.DescrStatsW(lst).tconfint_mean()\n",
    "        diff.loc[dim, metric] = [round(con, 1) for con in conf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba011b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = caseF-caseALL\n",
    "p = diff.applymap(lambda x: '' if 0 in x else \"*\")\n",
    "var.round(3).astype(str) + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "var.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d3236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = var.rename(columns = {\"rouge1\": \"ROUGE_1\", \"rougel\":\"ROUGE_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'}) \n",
    "p = p.rename(columns = {\"rouge1\": \"ROUGE_1\", \"rougel\":\"ROUGE_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6848d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(var.loc[:,metric_diff].round(2),\n",
    "            mask= (p.loc[:,metric_diff] != \"*\"),\n",
    "            # Use annot key with np.array as value containing strings of data + latex \n",
    "            # prefixes/suffices making the bold/italic/underline formatting\n",
    "            #annot_kws={\"style\": \"italic\", \"weight\": \"bold\"},\n",
    "            annot=True,\n",
    "            # fmt key must be empty, formatting error otherwise\n",
    "            fmt='0.2f',\n",
    "            cbar=False,\n",
    "            linewidth=0.5,\n",
    "            cmap=\"coolwarm_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796a2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_dem(df_):\n",
    "    df = pd.DataFrame()\n",
    "    case = df_[(df_.model_id != 'chatGPT_title') & (df_.model_id != 'chatGPT_pipeline')].groupby(\"id_model\").mean()\n",
    "    print(\"finetuned models: \",case.shape)\n",
    "    case = case.corr(\"spearman\").iloc[:4, 6:17]\n",
    "    dfm = case.reset_index().melt(id_vars=['index'])\n",
    "    dfm[\"model_group\"] = \"Finetuned\"\n",
    "    df = df.append(dfm)\n",
    "    \n",
    "    case = df_[(df_.model_id == 'chatGPT_title') | (df_.model_id == 'chatGPT_pipeline')].groupby(\"id_model\").mean()\n",
    "    print(\"GPT models: \", case.shape)\n",
    "    case = case.corr(\"spearman\").iloc[:4, 6:17]\n",
    "    dfm = case.reset_index().melt(id_vars=['index'])\n",
    "    dfm[\"model_group\"] = \"GPT\"\n",
    "    df = df.append(dfm)\n",
    "    \n",
    "    case = df_.groupby(\"id_model\").mean()\n",
    "    print(\"ALL models: \", case.shape)\n",
    "    case = case.corr(\"spearman\").iloc[:4, 6:17]\n",
    "    dfm = case.reset_index().melt(id_vars=['index'])\n",
    "    dfm[\"model_group\"] = \"Combined\"\n",
    "    df = df.append(dfm)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_df = sep_dem(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d379d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_df[\"variable\"] =sep_df[\"variable\"].replace({\"rouge1\": \"Rouge_1\", \"rougel\":\"Rouge_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'})\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(8, 3)})\n",
    "g = sns.catplot(kind='bar', data=sep_df, col='index', x='variable', y='value', order=[\"Rouge_1\", \"Rouge_L\", \"BERTScore_P\",\n",
    "                                                                             \"BERTScore_R\", \"BERTScore_F1\", \n",
    "                                                                              \"BARTScore\", \"MoverScore\",\"MENLI_W1\",\n",
    "                                                                             \"MENLI_W.8\", \"MENLI_W.3\", \"MENLI_W.2\", \"DiscoScore_F\", \"DiscoScore_S\"],\n",
    "                hue = \"model_group\", height = 4.5)\n",
    "g.set_titles(\"{col_name} \")\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set(ylabel=None, xlabel = None, ylim = (-0.5, 1))\n",
    "sns.set_style(\"dark\")\n",
    "g.tight_layout()\n",
    "plt.savefig('hEn-mul-segment_cor_by_group.pdf',bbox_inches='tight', pad_inches=0 )  \n",
    "            #col_order=sorted(df.Code.unique()), estimator=sum, ci=None, height=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f645609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a68d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836c0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7fa82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = merged_hEn[(merged_hEn.annotator == \"6\" ) ].set_index(\"id_model\").loc[intersection_of_models]#.set_index(\"annotator\").loc[[\"1\",\"2\",\"3\", \"4\",\"5\",]].reset_index() \n",
    "segment_GPT = segment_level_coorr(df_)\n",
    "segment_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_seg =[\"coherence_human\",\"coherence_chatGPT\", \"consistency_human\", \"consistency_chatGPT\",\n",
    "             \"fluency_human\", \"fluency_chatGPT\", \"relevance_human\",   'relevance_chatGPT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c745614",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_cor = pd.merge(segment_human.reset_index(), segment_GPT.reset_index(), on = \"index\", \n",
    "         suffixes = [\"_human\", \"_chatGPT\"], how = \"outer\").set_index(\"index\").loc[order_metric, order_seg].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b103776",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = seg_cor.reset_index().melt(id_vars=['index'])\n",
    "dfm[\"annotator\"] = [var.split(\"_\")[1] for var in dfm.variable]\n",
    "dfm[\"dimension\"] = [var.split(\"_\")[0] for var in dfm.variable]\n",
    "dfm[\"index\"] = dfm[\"index\"].replace({\"rouge1\": \"Rouge_1\", \"rougel\":\"Rouge_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'})\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(8, 3)})\n",
    "g = sns.catplot(kind='bar', data=dfm, col='dimension', x='index', y='value', order=[\"Rouge_1\", \"Rouge_L\", \"BERTScore_P\",\n",
    "                                                                             \"BERTScore_R\", \"BERTScore_F1\", \n",
    "                                                                              \"BARTScore\", \"MoverScore\",\"MENLI_W1\",\n",
    "                                                                             \"MENLI_W.8\", \"MENLI_W.3\", \"MENLI_W.2\"],\n",
    "                row='annotator', \n",
    "            margin_titles=True, height = 2.5)\n",
    "g.set_titles(\"{col_name} \")\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set(ylabel=None, xlabel = None, ylim = (-0.6, 0.6))\n",
    "sns.set_style(\"dark\")\n",
    "g.tight_layout()\n",
    "plt.savefig('hEn-mul-segment_cor.pdf',bbox_inches='tight', pad_inches=0 )  \n",
    "            #col_order=sorted(df.Code.unique()), estimator=sum, ci=None, height=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63538e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_string(row):\n",
    "    lst = [\"{:.3f}\".format(i.round(3)) for i in row.values]\n",
    "    lst_ = [\"/\".join(lst[:2]), \"/\".join(lst[2:4]), \"/\".join(lst[4:6]), \"/\".join(lst[6:])]\n",
    "    print(lst_)\n",
    "    return \"&\".join(lst_)\n",
    "#generate latex\n",
    "pd.DataFrame(seg_cor.apply(lambda x: turn_string(x) + \"\\\\\" + \"\\\\\", axis = 1)).to_csv(\"experiments/latex/hEn_latex_seg_cor.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c857bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244076e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_corr(df_):\n",
    "    seg = df_.groupby([\"id\", \"model_id\"])[columns_list].mean()\n",
    "    df = seg.reset_index().groupby(\"model_id\").mean()\n",
    "    dct = {}\n",
    "    for dim in ['coherence', 'consistency', 'fluency', 'relevance']:\n",
    "        lst_tau = []\n",
    "        lst_spearmanr = []\n",
    "        lst_pr = []\n",
    "        lst_ptau = []\n",
    "        for metric in order_metric:\n",
    "            #lst_tau.append(kendalltau(y=df[dim], x=df[metric]).correlation) #scipy.stats.weightedtau \n",
    "            #lst_ptau.append(kendalltau(y=df[dim], x=df[metric]).pvalue)\n",
    "            lst_spearmanr.append(spearmanr(df[dim], df[metric]).correlation)\n",
    "            #lst_pr.append(pearsonr(x=df[dim], y=df[metric])[1])\n",
    "        dct[dim] = lst_spearmanr\n",
    "        #dct[dim+\"_pvalue\"] = lst_pr\n",
    "        #dct[dim+\"_tau\"] = lst_tau\n",
    "        #dct[dim+\"_pvalue_tau\"] = lst_ptau\n",
    "\n",
    "    return pd.DataFrame(dct, index = order_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f84dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ = merged_hEn[(merged_hEn.annotator != \"6\" )].set_index(\"id_model\").loc[intersection_of_models].set_index(\"annotator\").loc[[\"1\",\"2\",\"3\"]].reset_index()\n",
    "system_human = system_corr(df_)\n",
    "system_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6caa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ecad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.groupby(\"model_id\").mean().loc[['1',\n",
    " '2',\n",
    " '3',\n",
    " '4',\n",
    " '5',\n",
    " '6',\n",
    " '11',]].corr(\"spearman\").iloc[6:-2,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.groupby(\"model_id\").mean().corr(\"spearman\").iloc[6:-2,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bcd96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b72813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d01bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = merged_hEn[(merged_hEn.annotator == \"6\" )].set_index(\"id_model\").loc[intersection_of_models]\n",
    "system_gpt = system_corr(df_)\n",
    "system_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_cor = pd.merge(system_human.reset_index(), system_gpt.reset_index(), on = \"index\", \n",
    "         suffixes = [\"_human\", \"_chatGPT\"], how = \"outer\").set_index(\"index\").loc[order_metric, order_seg].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = sys_cor - seg_cor\n",
    "dfm = diff.reset_index().melt(id_vars=['index'])\n",
    "dfm[\"annotator\"] = [var.split(\"_\")[1] for var in dfm.variable]\n",
    "dfm[\"dimension\"] = [var.split(\"_\")[0] for var in dfm.variable]\n",
    "dfm[\"index\"] = dfm[\"index\"].replace({\"rouge1\": \"Rouge_1\", \"rougel\":\"Rouge_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'})\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(8, 3)})\n",
    "g = sns.catplot(kind='bar', data=dfm, col='dimension', x='index', y='value', order=[\"Rouge_1\", \"Rouge_L\", \"BERTScore_P\",\n",
    "                                                                             \"BERTScore_R\", \"BERTScore_F1\", \n",
    "                                                                              \"BARTScore\", \"MoverScore\",\"MENLI_W1\",\n",
    "                                                                             \"MENLI_W.8\", \"MENLI_W.3\", \"MENLI_W.2\"],\n",
    "                row='annotator', \n",
    "            margin_titles=True, height = 2.5)\n",
    "g.set_titles(\"{col_name} \")\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set(ylabel=None, xlabel = None, ylim = (-0.6, 0.6))\n",
    "sns.set_style(\"dark\")\n",
    "g.tight_layout()\n",
    "\n",
    "            #col_order=sorted(df.Code.unique()), estimator=sum, ci=None, height=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be353516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "sns.set_style(\"dark\")\n",
    "pyplot.subplots(figsize=(8, 8))\n",
    "# calculate the correlation matrix\n",
    "corr = output_all_hEn.iloc[:,2:].corr().loc[order_metric, order_metric]\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(corr, cmap=\"Blues\", annot=True, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)\n",
    "#pyplot.savefig('tabular/hEn/corr_plot.pdf',bbox_inches='tight', pad_inches=0 )  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e79988f",
   "metadata": {},
   "source": [
    "Jihed_metric = pd.read_csv(\"../dataset/Outputs/Human_Evaluation/hEN-DE/de_metrics_res.csv\", sep = \";\")\n",
    "merged_hEn = pd.merge(Jihed_metric, eval_hEn, on = [\"Phase\", \"text-id\"], how = \"outer\")\n",
    "merged_hEn[\"id\"] = merged_hEn[\"id_y\"]\n",
    "df=merged_hEn[merged_hEn['Model-Id'] !=\"B2\"]#[(merged_hEn.overlap_count >0) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41e3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d537df",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_de = pd.read_csv(\"./experiments/Metrics/052023/de_de_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7205f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combi = pd.merge(score_de, score_mul, on = \"idx\", suffixes =[\"_base_de\", \"_base_mul\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "combi.corr(\"spearman\").iloc[2:8, 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5da7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14858a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4c360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ece67e52",
   "metadata": {},
   "source": [
    "df = merged_hEn[[\"id\", \"model_id\"]].drop_duplicates().sort_values([\"id\",\"model_id\"])\n",
    "df[\"value\"] = 1\n",
    "df.pivot(index=\"model_id\", columns=[\"id\"], values=\"value\").fillna(0).to_csv(\"pivot_hEn_humanEval_phase3.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5df934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
