{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99370cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52cca81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hDe = pd.read_csv(\"./eval_metric_hDe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072aa34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>id</th>\n",
       "      <th>reference_summary</th>\n",
       "      <th>generated_summary</th>\n",
       "      <th>direction</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougel</th>\n",
       "      <th>bertscore_P</th>\n",
       "      <th>bertscore_R</th>\n",
       "      <th>bertscore_F1</th>\n",
       "      <th>bartscore</th>\n",
       "      <th>moverscore</th>\n",
       "      <th>menli</th>\n",
       "      <th>idx</th>\n",
       "      <th>DiscoScore_F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI_W0.8</th>\n",
       "      <th>MENLI_W0.2</th>\n",
       "      <th>MENLI_W0.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>In the tale, a spoiled princess reluctantly be...</td>\n",
       "      <td>A queen-in-law finds a golden ball and throws ...</td>\n",
       "      <td>hDE-EN</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>0.182292</td>\n",
       "      <td>0.526474</td>\n",
       "      <td>0.513492</td>\n",
       "      <td>0.519902</td>\n",
       "      <td>-3.460109</td>\n",
       "      <td>0.545190</td>\n",
       "      <td>-0.428836</td>\n",
       "      <td>1-10</td>\n",
       "      <td>1.249658</td>\n",
       "      <td>0.931723</td>\n",
       "      <td>0.317515</td>\n",
       "      <td>0.412750</td>\n",
       "      <td>0.396878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>A cat and a mouse, contrary to the custom of t...</td>\n",
       "      <td>A cat and a mouse want to live together and be...</td>\n",
       "      <td>hDE-EN</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.264925</td>\n",
       "      <td>0.528035</td>\n",
       "      <td>0.499843</td>\n",
       "      <td>0.513553</td>\n",
       "      <td>-3.294651</td>\n",
       "      <td>0.575665</td>\n",
       "      <td>-0.195034</td>\n",
       "      <td>2-10</td>\n",
       "      <td>4.671926</td>\n",
       "      <td>0.966070</td>\n",
       "      <td>0.409246</td>\n",
       "      <td>0.426065</td>\n",
       "      <td>0.423262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>A poor woodcutter and his wife had a three-yea...</td>\n",
       "      <td>A woodcutter and his only child, a girl, are s...</td>\n",
       "      <td>hDE-EN</td>\n",
       "      <td>0.499139</td>\n",
       "      <td>0.271945</td>\n",
       "      <td>0.589919</td>\n",
       "      <td>0.579816</td>\n",
       "      <td>0.584824</td>\n",
       "      <td>-3.167333</td>\n",
       "      <td>0.583184</td>\n",
       "      <td>-0.409021</td>\n",
       "      <td>3-10</td>\n",
       "      <td>0.799250</td>\n",
       "      <td>0.970019</td>\n",
       "      <td>0.351731</td>\n",
       "      <td>0.519645</td>\n",
       "      <td>0.491659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>A father had two sons. The dimwitted younger s...</td>\n",
       "      <td>A king had a daughter, the beautifulst princes...</td>\n",
       "      <td>hDE-EN</td>\n",
       "      <td>0.289345</td>\n",
       "      <td>0.132942</td>\n",
       "      <td>0.571323</td>\n",
       "      <td>0.525512</td>\n",
       "      <td>0.547461</td>\n",
       "      <td>-3.837389</td>\n",
       "      <td>0.567684</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>4-10</td>\n",
       "      <td>0.283574</td>\n",
       "      <td>0.940372</td>\n",
       "      <td>0.315107</td>\n",
       "      <td>0.453893</td>\n",
       "      <td>0.430762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>A mother goat leaves her seven children at hom...</td>\n",
       "      <td>A Geis has seven little children whom she love...</td>\n",
       "      <td>hDE-EN</td>\n",
       "      <td>0.393491</td>\n",
       "      <td>0.201183</td>\n",
       "      <td>0.541044</td>\n",
       "      <td>0.503911</td>\n",
       "      <td>0.521818</td>\n",
       "      <td>-2.991108</td>\n",
       "      <td>0.573224</td>\n",
       "      <td>-0.142887</td>\n",
       "      <td>5-10</td>\n",
       "      <td>1.913062</td>\n",
       "      <td>0.936069</td>\n",
       "      <td>0.433616</td>\n",
       "      <td>0.444678</td>\n",
       "      <td>0.442834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id  id                                  reference_summary  \\\n",
       "0       10   1  In the tale, a spoiled princess reluctantly be...   \n",
       "1       10   2  A cat and a mouse, contrary to the custom of t...   \n",
       "2       10   3  A poor woodcutter and his wife had a three-yea...   \n",
       "3       10   4  A father had two sons. The dimwitted younger s...   \n",
       "4       10   5  A mother goat leaves her seven children at hom...   \n",
       "\n",
       "                                   generated_summary direction    rouge1  \\\n",
       "0  A queen-in-law finds a golden ball and throws ...    hDE-EN  0.369792   \n",
       "1  A cat and a mouse want to live together and be...    hDE-EN  0.511194   \n",
       "2  A woodcutter and his only child, a girl, are s...    hDE-EN  0.499139   \n",
       "3  A king had a daughter, the beautifulst princes...    hDE-EN  0.289345   \n",
       "4  A Geis has seven little children whom she love...    hDE-EN  0.393491   \n",
       "\n",
       "     rougel  bertscore_P  bertscore_R  bertscore_F1  bartscore  moverscore  \\\n",
       "0  0.182292     0.526474     0.513492      0.519902  -3.460109    0.545190   \n",
       "1  0.264925     0.528035     0.499843      0.513553  -3.294651    0.575665   \n",
       "2  0.271945     0.589919     0.579816      0.584824  -3.167333    0.583184   \n",
       "3  0.132942     0.571323     0.525512      0.547461  -3.837389    0.567684   \n",
       "4  0.201183     0.541044     0.503911      0.521818  -2.991108    0.573224   \n",
       "\n",
       "      menli   idx  DiscoScore_F  DiscoScore_S  MENLI_W0.8  MENLI_W0.2  \\\n",
       "0 -0.428836  1-10      1.249658      0.931723    0.317515    0.412750   \n",
       "1 -0.195034  2-10      4.671926      0.966070    0.409246    0.426065   \n",
       "2 -0.409021  3-10      0.799250      0.970019    0.351731    0.519645   \n",
       "3 -0.462407  4-10      0.283574      0.940372    0.315107    0.453893   \n",
       "4 -0.142887  5-10      1.913062      0.936069    0.433616    0.444678   \n",
       "\n",
       "   MENLI_W0.3  \n",
       "0    0.396878  \n",
       "1    0.423262  \n",
       "2    0.491659  \n",
       "3    0.430762  \n",
       "4    0.442834  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all_hDe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d43a03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5519, 19)\n"
     ]
    }
   ],
   "source": [
    "print(output_all_hDe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a43ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Text   id_x    Phase             Model Model-Id  coherence  consistency  \\\n",
      "0  Text-1  199.0  Phase-1  mLED hDE-EN only        1        1.5          2.0   \n",
      "1  Text-1  199.0  Phase-1  mLED hDE-EN only        1        2.0          1.0   \n",
      "2  Text-1  199.0  Phase-1  mLED hDE-EN only        1        1.5          2.0   \n",
      "3  Text-1  199.0  Phase-1  mLED hDE-EN only        1        1.5          1.5   \n",
      "4  Text-1  199.0  Phase-1  mLED hDE-EN only        1        2.5          1.5   \n",
      "\n",
      "   fluency  relevance annotator  id_y     id model_id  \n",
      "0      3.0        2.5         2   NaN  199.0        1  \n",
      "1      3.0        1.5         3   NaN  199.0        1  \n",
      "2      3.0        2.0         1   NaN  199.0        1  \n",
      "3      2.5        1.5         4   NaN  199.0        1  \n",
      "4      3.0        1.5         5   NaN  199.0        1  \n",
      "chatGPT: (607, 15)\n"
     ]
    }
   ],
   "source": [
    "eval_ = pd.DataFrame()\n",
    "path = \"../dataset/Outputs/Human_Evaluation/hDE-EN\"\n",
    "for file in os.listdir(path):\n",
    "    if \"val\" in file:\n",
    "        try:\n",
    "            e = pd.read_csv(path + \"/\" + file, sep = \";\")\n",
    "        except:\n",
    "            e = pd.read_csv(path + \"/\" + file,) \n",
    "            e.columns = ['Unnamed: 0', 'Model-Id', 'generated_summary', 'id', 'direction',\n",
    "       'reference_summary', 'text', 'coherence', 'consistency', 'fluency',\n",
    "       'relevance']\n",
    "            e = e[['Model-Id', 'id', 'coherence', 'consistency', 'fluency',\n",
    "       'relevance']]\n",
    "        e[\"annotator\"] = file[-5:-4]\n",
    "       # if (file[-5:-4] != \"7\"): #& (file[-5:-4] != \"1\") :\n",
    "        eval_ = pd.concat([eval_, e])\n",
    "phase1_hDe=pd.read_csv(\"../dataset/Outputs/Human_Evaluation/hDE-EN-p1_id.csv\")[[\"Text\", \"id\"]]\n",
    "phase1_hDe[\"id\"] = [int(id_.split(\":\")[1].replace(\"\\r\", \"\")) for id_ in phase1_hDe.id]\n",
    "phase1_hDe[\"Phase\"] = \"Phase-1\"\n",
    "phase2_hDe=pd.read_csv(\"../dataset/Outputs/Human_Evaluation/hDE-EN-p2_id.csv\")[[\"Text\", \"id\"]]\n",
    "phase2_hDe[\"id\"] = [int(id_.split(\":\")[1].replace(\"\\r\", \"\")) for id_ in phase2_hDe.id]\n",
    "phase2_hDe[\"Phase\"] = \"Phase-2\"\n",
    "phase_id = phase1_hDe.append(phase2_hDe)\n",
    "\n",
    "# merge with id\n",
    "eval_ = pd.merge(phase_id, eval_, on = [\"Phase\", \"Text\"], how = 'outer')\n",
    "eval_[\"id\"] = [eval_.id_y.iloc[idx] if pd.isna(eval_.id_x.iloc[idx]) else eval_.id_x.iloc[idx] for idx in range(len(eval_))]\n",
    "for column in [\"coherence\", \"consistency\",  \"fluency\", \"relevance\"]:\n",
    "    eval_[column] = [float(str(eval_[column].iloc[idx]).replace(\",\", \".\")) for idx in range(len(eval_)) ]\n",
    "eval_[\"model_id\"] = eval_[\"Model-Id\"]\n",
    "eval_[\"model_id\"] = eval_[\"model_id\"].replace({\"101\":'10'})\n",
    "print(eval_.head())\n",
    "\n",
    "chat_anno = pd.read_csv(path + \"/\" + \"en_chat_8.csv\") \n",
    "chat_anno[\"annotator\"] = str(8)\n",
    "chat_anno = chat_anno.dropna()\n",
    "print(\"chatGPT:\", chat_anno.shape)\n",
    "\n",
    "eval_.model_id = eval_.model_id.replace({\"chatGPT_pp\": \"chatGPT_pipeline\", \"Memsum\":\"memsum_deepl\"})\n",
    "column = [\"id\", \"model_id\", \"coherence\", \"consistency\", \"fluency\", \"relevance\", \"annotator\"]\n",
    "eval_ = pd.concat([eval_[column], chat_anno[column]])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d52e030",
   "metadata": {},
   "source": [
    "df = merged_hDe[[\"id\", \"model_id\"]].drop_duplicates().sort_values([\"id\",\"model_id\"])\n",
    "df[\"value\"] = 1\n",
    "df.pivot(index=\"model_id\", columns=[\"id\"], values=\"value\").fillna(0).to_csv(\"pivot_hEN_humanEval_phase3.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c6048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hDe_en = pd.concat([output_all_hDe, score_en], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a05504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from menli normalization\n",
    "def min_max_normalize(scores):\n",
    "    if len(scores) > 1:\n",
    "        normalized_scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "    else:\n",
    "        normalized_scores = scores\n",
    "    return normalized_scores\n",
    "def compute_menli(df):\n",
    "    for nli_weight in [0.8, 0.2, 0.3]:   \n",
    "        norm_metric_scores = min_max_normalize(df.bertscore_F1)\n",
    "        norm_nli_scores = min_max_normalize(df.menli)\n",
    "        final_scores = [nli_weight*n + (1-nli_weight)*m for n, m in zip(norm_nli_scores, norm_metric_scores)]\n",
    "        df[\"MENLI_W\" + str(nli_weight)] = final_scores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67453f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hDe = compute_menli(output_all_hDe_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e63f1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hDe = output_all_hDe.drop(columns = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14edc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hDe.to_csv(\"eval_metric_hDe.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a66500",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_metric = ['rouge1', 'rougel', 'bertscore_P',\n",
    "       'bertscore_R', 'bertscore_F1',  'bartscore','moverscore','menli',  'MENLI_W0.8', 'MENLI_W0.3', 'MENLI_W0.2', \"DiscoScore_F\", \"DiscoScore_S\"]\n",
    "\n",
    "model_order = ['German_25_False', 'German_25_True',\n",
    "       'German_100',  \n",
    "                '1','3', '2', '4','9_2', '9_1',  '10',  'chatGPT_title',\n",
    "       'chatGPT_e2e', 'chatGPT_pipeline',\n",
    "       ]\n",
    "\n",
    "model_order_human = [\n",
    "                '1','3', '2', '4','9_2', '9_1',  '10',  'chatGPT_title', 'chatGPT_pipeline',\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a7f21f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_id', 'id', 'Unnamed: 0', 'reference_summary',\n",
       "       'generated_summary', 'direction', 'rouge1', 'rougel', 'bertscore_P',\n",
       "       'bertscore_R', 'bertscore_F1', 'bartscore', 'moverscore', 'menli',\n",
       "       'idx', 'DiscoScore_F', 'DiscoScore_S', 'MENLI_W0.8', 'MENLI_W0.2',\n",
       "       'MENLI_W0.3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all_hDe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ab79fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id\n",
      "1                   324\n",
      "10                  324\n",
      "2                   324\n",
      "3                   324\n",
      "4                   324\n",
      "5                   324\n",
      "6                   324\n",
      "7                   324\n",
      "8                   324\n",
      "9_1                 324\n",
      "9_2                 324\n",
      "German_100          324\n",
      "German_25_False     324\n",
      "German_25_True      324\n",
      "chatGPT_e2e         323\n",
      "chatGPT_pipeline    324\n",
      "chatGPT_title       324\n",
      "Name: menli, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougel</th>\n",
       "      <th>bertscore_P</th>\n",
       "      <th>bertscore_R</th>\n",
       "      <th>bertscore_F1</th>\n",
       "      <th>bartscore</th>\n",
       "      <th>moverscore</th>\n",
       "      <th>menli</th>\n",
       "      <th>MENLI_W0.8</th>\n",
       "      <th>MENLI_W0.3</th>\n",
       "      <th>MENLI_W0.2</th>\n",
       "      <th>DiscoScore_F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>German_25_False</th>\n",
       "      <td>0.320</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.545</td>\n",
       "      <td>-3.311</td>\n",
       "      <td>0.552</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_25_True</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-3.360</td>\n",
       "      <td>0.551</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_100</th>\n",
       "      <td>0.382</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-3.421</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.391</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.547</td>\n",
       "      <td>-3.524</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.479</td>\n",
       "      <td>1.838</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.393</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.551</td>\n",
       "      <td>-3.492</td>\n",
       "      <td>0.569</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.485</td>\n",
       "      <td>1.725</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.547</td>\n",
       "      <td>-3.534</td>\n",
       "      <td>0.567</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.477</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.389</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.547</td>\n",
       "      <td>-3.567</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.426</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_2</th>\n",
       "      <td>0.386</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-3.593</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.464</td>\n",
       "      <td>1.595</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_1</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-3.615</td>\n",
       "      <td>0.567</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.458</td>\n",
       "      <td>1.685</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.386</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.539</td>\n",
       "      <td>-3.590</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.462</td>\n",
       "      <td>1.635</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.528</td>\n",
       "      <td>-3.857</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_e2e</th>\n",
       "      <td>0.399</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.624</td>\n",
       "      <td>-3.363</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>0.382</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-3.422</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rouge1  rougel  bertscore_P  bertscore_R  bertscore_F1  \\\n",
       "model_id                                                                   \n",
       "German_25_False    0.320   0.175        0.521        0.574         0.545   \n",
       "German_25_True     0.315   0.171        0.514        0.567         0.538   \n",
       "German_100         0.382   0.234        0.639        0.597         0.615   \n",
       "1                  0.391   0.201        0.537        0.561         0.547   \n",
       "3                  0.393   0.200        0.539        0.566         0.551   \n",
       "2                  0.388   0.198        0.537        0.561         0.547   \n",
       "4                  0.389   0.198        0.540        0.556         0.547   \n",
       "9_2                0.386   0.201        0.536        0.547         0.540   \n",
       "9_1                0.380   0.198        0.530        0.544         0.536   \n",
       "10                 0.386   0.202        0.532        0.548         0.539   \n",
       "chatGPT_title      0.304   0.164        0.527        0.530         0.528   \n",
       "chatGPT_e2e        0.399   0.244        0.646        0.607         0.624   \n",
       "chatGPT_pipeline   0.382   0.232        0.637        0.597         0.615   \n",
       "\n",
       "                  bartscore  moverscore  menli  MENLI_W0.8  MENLI_W0.3  \\\n",
       "model_id                                                                 \n",
       "German_25_False      -3.311       0.552 -0.232       0.407       0.463   \n",
       "German_25_True       -3.360       0.551 -0.248       0.398       0.450   \n",
       "German_100           -3.421       0.571 -0.206       0.446       0.566   \n",
       "1                    -3.524       0.568 -0.206       0.418       0.469   \n",
       "3                    -3.492       0.569 -0.216       0.416       0.473   \n",
       "2                    -3.534       0.567 -0.231       0.408       0.465   \n",
       "4                    -3.567       0.568 -0.255       0.398       0.461   \n",
       "9_2                  -3.593       0.568 -0.252       0.397       0.453   \n",
       "9_1                  -3.615       0.567 -0.241       0.400       0.448   \n",
       "10                   -3.590       0.568 -0.246       0.399       0.451   \n",
       "chatGPT_title        -3.857       0.542 -0.700       0.211       0.367   \n",
       "chatGPT_e2e          -3.363       0.575 -0.194       0.455       0.580   \n",
       "chatGPT_pipeline     -3.422       0.571 -0.282       0.415       0.554   \n",
       "\n",
       "                  MENLI_W0.2  DiscoScore_F  DiscoScore_S  \n",
       "model_id                                                  \n",
       "German_25_False        0.474         0.551         0.928  \n",
       "German_25_True         0.461         0.536         0.926  \n",
       "German_100             0.589         0.883         0.925  \n",
       "1                      0.479         1.838         0.936  \n",
       "3                      0.485         1.725         0.935  \n",
       "2                      0.477         1.142         0.936  \n",
       "4                      0.473         1.426         0.936  \n",
       "9_2                    0.464         1.595         0.934  \n",
       "9_1                    0.458         1.685         0.934  \n",
       "10                     0.462         1.635         0.934  \n",
       "chatGPT_title          0.398         0.788         0.928  \n",
       "chatGPT_e2e            0.605         0.982         0.945  \n",
       "chatGPT_pipeline       0.581         0.907         0.937  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate table 1 eval_metrics\n",
    "filtered = output_all_hDe.set_index(\"id\").loc[output_all_hDe[output_all_hDe.model_id == \"1\"].id]\n",
    "latex = filtered.groupby(\"model_id\").mean().iloc[:, -14:].loc[model_order, order_metric]#.to_csv(\"tabular/hDe/metric_eval_mean.csv\", index = True)\n",
    "print(filtered.groupby(\"model_id\").menli.count())\n",
    "latex.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73826d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_string(row):\n",
    "    lst = [\"{:.3f}\".format(i.round(3)) for i in row.values]\n",
    "    lst_ = [\"/\".join(lst[:2]), \"/\".join(lst[2:5]), lst[5], lst[6], \"/\".join(lst[7:])]\n",
    "    print(lst_)\n",
    "    return \"&\".join(lst_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e4eeee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.320/0.175', '0.521/0.574/0.545', '-3.311', '0.552', '-0.232/0.407/0.463/0.474/0.551/0.928']\n",
      "['0.315/0.171', '0.514/0.567/0.538', '-3.360', '0.551', '-0.248/0.398/0.450/0.461/0.536/0.926']\n",
      "['0.382/0.234', '0.639/0.597/0.615', '-3.421', '0.571', '-0.206/0.446/0.566/0.589/0.883/0.925']\n",
      "['0.391/0.201', '0.537/0.561/0.547', '-3.524', '0.568', '-0.206/0.418/0.469/0.479/1.838/0.936']\n",
      "['0.393/0.200', '0.539/0.566/0.551', '-3.492', '0.569', '-0.216/0.416/0.473/0.485/1.725/0.935']\n",
      "['0.388/0.198', '0.537/0.561/0.547', '-3.534', '0.567', '-0.231/0.408/0.465/0.477/1.142/0.936']\n",
      "['0.389/0.198', '0.540/0.556/0.547', '-3.567', '0.568', '-0.255/0.398/0.461/0.473/1.426/0.936']\n",
      "['0.386/0.201', '0.536/0.547/0.540', '-3.593', '0.568', '-0.252/0.397/0.453/0.464/1.595/0.934']\n",
      "['0.380/0.198', '0.530/0.544/0.536', '-3.615', '0.567', '-0.241/0.400/0.448/0.458/1.685/0.934']\n",
      "['0.386/0.202', '0.532/0.548/0.539', '-3.590', '0.568', '-0.246/0.399/0.451/0.462/1.635/0.934']\n",
      "['0.304/0.164', '0.527/0.530/0.528', '-3.857', '0.542', '-0.700/0.211/0.367/0.398/0.788/0.928']\n",
      "['0.399/0.244', '0.646/0.607/0.624', '-3.363', '0.575', '-0.194/0.455/0.580/0.605/0.982/0.945']\n",
      "['0.382/0.232', '0.637/0.597/0.615', '-3.422', '0.571', '-0.282/0.415/0.554/0.581/0.907/0.937']\n"
     ]
    }
   ],
   "source": [
    "#generate latex\n",
    "pd.DataFrame(latex.apply(lambda x: turn_string(x), axis = 1)).to_csv(\"experiments/latex/latex_experiment_hDe-monolingual.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e793b2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>consistency</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "      <th>id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reference_summary</th>\n",
       "      <th>generated_summary</th>\n",
       "      <th>...</th>\n",
       "      <th>MENLI-W1</th>\n",
       "      <th>idx</th>\n",
       "      <th>DiscoScore-F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI-W.8</th>\n",
       "      <th>MENLI-W.2</th>\n",
       "      <th>MENLI-W.3</th>\n",
       "      <th>overlap_count</th>\n",
       "      <th>sum</th>\n",
       "      <th>id_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>199.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2,274.00</td>\n",
       "      <td>A poor boy, called \"Golden\" because of his hai...</td>\n",
       "      <td>A poor shepherd and his six children live in a...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>199-1</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>199.0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>199.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2,274.00</td>\n",
       "      <td>A poor boy, called \"Golden\" because of his hai...</td>\n",
       "      <td>A poor shepherd and his six children live in a...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>199-1</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>7.50</td>\n",
       "      <td>199.0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2,274.00</td>\n",
       "      <td>A poor boy, called \"Golden\" because of his hai...</td>\n",
       "      <td>A poor shepherd and his six children live in a...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>199-1</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>8.50</td>\n",
       "      <td>199.0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>199.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2,274.00</td>\n",
       "      <td>A poor boy, called \"Golden\" because of his hai...</td>\n",
       "      <td>A poor shepherd and his six children live in a...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>199-1</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>7.00</td>\n",
       "      <td>199.0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>199.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2,274.00</td>\n",
       "      <td>A poor boy, called \"Golden\" because of his hai...</td>\n",
       "      <td>A poor shepherd and his six children live in a...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>199-1</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>8.50</td>\n",
       "      <td>199.0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>268.00</td>\n",
       "      <td>German_100</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One fine morning, the hare makes fun of the he...</td>\n",
       "      <td>The story tells of a pig who challenges a hare...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>268-German_100</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>16.00</td>\n",
       "      <td>268.0_German_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>272.00</td>\n",
       "      <td>German_100</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A huntsman gave an old woman alms. She told hi...</td>\n",
       "      <td>gab ihr das gute Salathaupt, das sie mit Freud...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>272-German_100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>272.0_German_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>277.00</td>\n",
       "      <td>German_100</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Four boys from a country without a moon, where...</td>\n",
       "      <td>In a land where there was no moon or stars, fo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>277-German_100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>18.00</td>\n",
       "      <td>277.0_German_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>288.00</td>\n",
       "      <td>German_100</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The wolf is the stronger of the two and domina...</td>\n",
       "      <td>The wolf had the fox with him, and the fox had...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>288-German_100</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>18.00</td>\n",
       "      <td>288.0_German_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>314.00</td>\n",
       "      <td>German_100</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A peasant has seven sons and no daughter. Fina...</td>\n",
       "      <td>A man had seven sons but no daughters. His wif...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>314-German_100</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1</td>\n",
       "      <td>18.00</td>\n",
       "      <td>314.0_German_100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coherence  consistency  fluency  relevance     id    model_id annotator  \\\n",
       "0         1.50         2.00     3.00       2.50 199.00           1         2   \n",
       "1         2.00         1.00     3.00       1.50 199.00           1         3   \n",
       "2         1.50         2.00     3.00       2.00 199.00           1         1   \n",
       "3         1.50         1.50     2.50       1.50 199.00           1         4   \n",
       "4         2.50         1.50     3.00       1.50 199.00           1         5   \n",
       "..         ...          ...      ...        ...    ...         ...       ...   \n",
       "883       4.00         5.00     4.00       3.00 268.00  German_100         8   \n",
       "884       1.00         1.00     1.00       1.00 272.00  German_100         8   \n",
       "885       4.00         5.00     4.00       5.00 277.00  German_100         8   \n",
       "886       4.00         5.00     4.00       5.00 288.00  German_100         8   \n",
       "887       4.00         5.00     4.00       5.00 314.00  German_100         8   \n",
       "\n",
       "     Unnamed: 0                                  reference_summary  \\\n",
       "0      2,274.00  A poor boy, called \"Golden\" because of his hai...   \n",
       "1      2,274.00  A poor boy, called \"Golden\" because of his hai...   \n",
       "2      2,274.00  A poor boy, called \"Golden\" because of his hai...   \n",
       "3      2,274.00  A poor boy, called \"Golden\" because of his hai...   \n",
       "4      2,274.00  A poor boy, called \"Golden\" because of his hai...   \n",
       "..          ...                                                ...   \n",
       "883         NaN  One fine morning, the hare makes fun of the he...   \n",
       "884         NaN  A huntsman gave an old woman alms. She told hi...   \n",
       "885         NaN  Four boys from a country without a moon, where...   \n",
       "886         NaN  The wolf is the stronger of the two and domina...   \n",
       "887         NaN  A peasant has seven sons and no daughter. Fina...   \n",
       "\n",
       "                                     generated_summary  ... MENLI-W1  \\\n",
       "0    A poor shepherd and his six children live in a...  ...    -0.23   \n",
       "1    A poor shepherd and his six children live in a...  ...    -0.23   \n",
       "2    A poor shepherd and his six children live in a...  ...    -0.23   \n",
       "3    A poor shepherd and his six children live in a...  ...    -0.23   \n",
       "4    A poor shepherd and his six children live in a...  ...    -0.23   \n",
       "..                                                 ...  ...      ...   \n",
       "883  The story tells of a pig who challenges a hare...  ...    -0.90   \n",
       "884  gab ihr das gute Salathaupt, das sie mit Freud...  ...    -0.12   \n",
       "885  In a land where there was no moon or stars, fo...  ...     0.34   \n",
       "886  The wolf had the fox with him, and the fox had...  ...     0.59   \n",
       "887  A man had seven sons but no daughters. His wif...  ...    -0.43   \n",
       "\n",
       "                idx  DiscoScore-F  DiscoScore_S  MENLI-W.8  MENLI-W.2  \\\n",
       "0             199-1          1.06          0.98       0.42       0.51   \n",
       "1             199-1          1.06          0.98       0.42       0.51   \n",
       "2             199-1          1.06          0.98       0.42       0.51   \n",
       "3             199-1          1.06          0.98       0.42       0.51   \n",
       "4             199-1          1.06          0.98       0.42       0.51   \n",
       "..              ...           ...           ...        ...        ...   \n",
       "883  268-German_100          0.61          0.90       0.14       0.43   \n",
       "884  272-German_100          0.00          0.50       0.40       0.27   \n",
       "885  277-German_100          0.50          0.94       0.68       0.72   \n",
       "886  288-German_100          2.28          0.95       0.78       0.71   \n",
       "887  314-German_100          0.17          0.94       0.37       0.61   \n",
       "\n",
       "     MENLI-W.3  overlap_count   sum          id_model  \n",
       "0         0.50              5  9.00           199.0_1  \n",
       "1         0.50              5  7.50           199.0_1  \n",
       "2         0.50              5  8.50           199.0_1  \n",
       "3         0.50              5  7.00           199.0_1  \n",
       "4         0.50              5  8.50           199.0_1  \n",
       "..         ...            ...   ...               ...  \n",
       "883       0.38              1 16.00  268.0_German_100  \n",
       "884       0.29              1  4.00  272.0_German_100  \n",
       "885       0.72              1 18.00  277.0_German_100  \n",
       "886       0.72              1 18.00  288.0_German_100  \n",
       "887       0.57              1 18.00  314.0_German_100  \n",
       "\n",
       "[681 rows x 28 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_hDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0698384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human annotation\n",
    "merged_hDe = pd.merge(eval_[['coherence',\n",
    "       'consistency', 'fluency', 'relevance', 'id', \"model_id\", \"annotator\"]], output_all_hDe, on = [\"id\", \"model_id\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "880b6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess \n",
    "# exclude nans\n",
    "merged_hDe = merged_hDe.dropna(subset = [\"coherence\", \"menli\"])\n",
    "# count overlap of annotations for generated summary\n",
    "merged_hDe[\"overlap_count\"] = merged_hDe.groupby([\"model_id\", \"id\"]).generated_summary.transform(\"count\")\n",
    "# sum of scores in 4 dimension, remove 1111s, or 0000s\n",
    "merged_hDe[\"sum\"] = merged_hDe['coherence'] + merged_hDe['consistency'] + merged_hDe['fluency'] + merged_hDe['relevance']\n",
    "merged_hDe = merged_hDe[merged_hDe[\"sum\"] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a7b817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/4742tn7s13l5fcnstlm_d7g40000gn/T/ipykernel_25351/1259815561.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  merged_hDe.annotator_orig = merged_hDe.annotator\n"
     ]
    }
   ],
   "source": [
    "# merge annotators \n",
    "merged_hDe.annotator_orig = merged_hDe.annotator\n",
    "merged_hDe.annotator = merged_hDe.annotator.replace({\"6\":\"3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27b4c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hDe[\"id_model\"] = merged_hDe.apply(lambda x: str(x[\"id\"]) + \"_\" + x[\"model_id\"], axis = 1)\n",
    "intersection_of_models = set(merged_hDe[(merged_hDe.annotator != \"8\" )].id_model.unique()).intersection(set(merged_hDe[(merged_hDe.annotator == \"8\" )].id_model.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b512e10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>consistency</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "      <th>id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougel</th>\n",
       "      <th>bertscore_P</th>\n",
       "      <th>bertscore_R</th>\n",
       "      <th>...</th>\n",
       "      <th>bartscore</th>\n",
       "      <th>moverscore</th>\n",
       "      <th>menli</th>\n",
       "      <th>DiscoScore_F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI_W0.8</th>\n",
       "      <th>MENLI_W0.2</th>\n",
       "      <th>MENLI_W0.3</th>\n",
       "      <th>overlap_count</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.853659</td>\n",
       "      <td>1.835366</td>\n",
       "      <td>2.280488</td>\n",
       "      <td>1.823171</td>\n",
       "      <td>158.914634</td>\n",
       "      <td>2125.939024</td>\n",
       "      <td>0.372924</td>\n",
       "      <td>0.194778</td>\n",
       "      <td>0.529634</td>\n",
       "      <td>0.555788</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.524514</td>\n",
       "      <td>0.564809</td>\n",
       "      <td>-0.250539</td>\n",
       "      <td>2.066134</td>\n",
       "      <td>0.943860</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>0.464629</td>\n",
       "      <td>0.453507</td>\n",
       "      <td>4.170732</td>\n",
       "      <td>7.792683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.822581</td>\n",
       "      <td>1.604839</td>\n",
       "      <td>1.927419</td>\n",
       "      <td>1.596774</td>\n",
       "      <td>142.806452</td>\n",
       "      <td>160.064516</td>\n",
       "      <td>0.401842</td>\n",
       "      <td>0.203868</td>\n",
       "      <td>0.543960</td>\n",
       "      <td>0.542666</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.512942</td>\n",
       "      <td>0.572620</td>\n",
       "      <td>-0.323597</td>\n",
       "      <td>1.430239</td>\n",
       "      <td>0.947991</td>\n",
       "      <td>0.369032</td>\n",
       "      <td>0.459653</td>\n",
       "      <td>0.444550</td>\n",
       "      <td>3.209677</td>\n",
       "      <td>6.951613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.903226</td>\n",
       "      <td>1.766129</td>\n",
       "      <td>1.991935</td>\n",
       "      <td>1.669355</td>\n",
       "      <td>144.919355</td>\n",
       "      <td>2792.016129</td>\n",
       "      <td>0.380527</td>\n",
       "      <td>0.202439</td>\n",
       "      <td>0.535075</td>\n",
       "      <td>0.557082</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.457672</td>\n",
       "      <td>0.567418</td>\n",
       "      <td>-0.230478</td>\n",
       "      <td>0.817795</td>\n",
       "      <td>0.942002</td>\n",
       "      <td>0.407483</td>\n",
       "      <td>0.472621</td>\n",
       "      <td>0.461765</td>\n",
       "      <td>3.193548</td>\n",
       "      <td>7.330645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.094828</td>\n",
       "      <td>1.948276</td>\n",
       "      <td>2.129310</td>\n",
       "      <td>1.887931</td>\n",
       "      <td>142.034483</td>\n",
       "      <td>1808.482759</td>\n",
       "      <td>0.413992</td>\n",
       "      <td>0.210625</td>\n",
       "      <td>0.543524</td>\n",
       "      <td>0.570547</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.437542</td>\n",
       "      <td>0.572572</td>\n",
       "      <td>-0.260093</td>\n",
       "      <td>1.185901</td>\n",
       "      <td>0.945355</td>\n",
       "      <td>0.400082</td>\n",
       "      <td>0.487807</td>\n",
       "      <td>0.473186</td>\n",
       "      <td>3.241379</td>\n",
       "      <td>8.060345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.681818</td>\n",
       "      <td>1.522727</td>\n",
       "      <td>1.784091</td>\n",
       "      <td>1.522727</td>\n",
       "      <td>146.159091</td>\n",
       "      <td>1149.090909</td>\n",
       "      <td>0.385257</td>\n",
       "      <td>0.189332</td>\n",
       "      <td>0.538308</td>\n",
       "      <td>0.549011</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.579024</td>\n",
       "      <td>0.568629</td>\n",
       "      <td>-0.313955</td>\n",
       "      <td>1.303712</td>\n",
       "      <td>0.945065</td>\n",
       "      <td>0.373071</td>\n",
       "      <td>0.461225</td>\n",
       "      <td>0.446533</td>\n",
       "      <td>1.318182</td>\n",
       "      <td>6.511364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.595238</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>2.595238</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>100.476190</td>\n",
       "      <td>2447.142857</td>\n",
       "      <td>0.389906</td>\n",
       "      <td>0.196525</td>\n",
       "      <td>0.543192</td>\n",
       "      <td>0.542991</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.691951</td>\n",
       "      <td>0.570999</td>\n",
       "      <td>-0.462280</td>\n",
       "      <td>1.059008</td>\n",
       "      <td>0.956332</td>\n",
       "      <td>0.313217</td>\n",
       "      <td>0.446140</td>\n",
       "      <td>0.423986</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.095238</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.880952</td>\n",
       "      <td>161.142857</td>\n",
       "      <td>498.904762</td>\n",
       "      <td>0.392206</td>\n",
       "      <td>0.190915</td>\n",
       "      <td>0.548322</td>\n",
       "      <td>0.564667</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.417577</td>\n",
       "      <td>0.569898</td>\n",
       "      <td>-0.410667</td>\n",
       "      <td>1.979621</td>\n",
       "      <td>0.953207</td>\n",
       "      <td>0.339417</td>\n",
       "      <td>0.472877</td>\n",
       "      <td>0.450634</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_1</th>\n",
       "      <td>1.433333</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.255556</td>\n",
       "      <td>146.377778</td>\n",
       "      <td>818.800000</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>0.201696</td>\n",
       "      <td>0.534163</td>\n",
       "      <td>0.540508</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.583005</td>\n",
       "      <td>0.569589</td>\n",
       "      <td>-0.205569</td>\n",
       "      <td>1.658892</td>\n",
       "      <td>0.939936</td>\n",
       "      <td>0.414239</td>\n",
       "      <td>0.461968</td>\n",
       "      <td>0.454013</td>\n",
       "      <td>1.355556</td>\n",
       "      <td>5.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_2</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.579545</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>147.886364</td>\n",
       "      <td>1473.590909</td>\n",
       "      <td>0.383781</td>\n",
       "      <td>0.197036</td>\n",
       "      <td>0.530773</td>\n",
       "      <td>0.539702</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.529144</td>\n",
       "      <td>0.567425</td>\n",
       "      <td>-0.278311</td>\n",
       "      <td>1.345965</td>\n",
       "      <td>0.938577</td>\n",
       "      <td>0.384015</td>\n",
       "      <td>0.451090</td>\n",
       "      <td>0.439911</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>5.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_100</th>\n",
       "      <td>3.810811</td>\n",
       "      <td>4.135135</td>\n",
       "      <td>3.837838</td>\n",
       "      <td>3.972973</td>\n",
       "      <td>141.081081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.392146</td>\n",
       "      <td>0.241838</td>\n",
       "      <td>0.640687</td>\n",
       "      <td>0.602221</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.408327</td>\n",
       "      <td>0.571886</td>\n",
       "      <td>-0.239390</td>\n",
       "      <td>1.152250</td>\n",
       "      <td>0.921370</td>\n",
       "      <td>0.434262</td>\n",
       "      <td>0.593213</td>\n",
       "      <td>0.566721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_25_False</th>\n",
       "      <td>1.769231</td>\n",
       "      <td>1.743590</td>\n",
       "      <td>1.615385</td>\n",
       "      <td>1.461538</td>\n",
       "      <td>146.743590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339585</td>\n",
       "      <td>0.182997</td>\n",
       "      <td>0.531017</td>\n",
       "      <td>0.578221</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.237109</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>-0.230807</td>\n",
       "      <td>0.642544</td>\n",
       "      <td>0.934807</td>\n",
       "      <td>0.410614</td>\n",
       "      <td>0.485641</td>\n",
       "      <td>0.473137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_25_True</th>\n",
       "      <td>1.710526</td>\n",
       "      <td>1.394737</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334671</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>0.521575</td>\n",
       "      <td>0.569477</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.280749</td>\n",
       "      <td>0.554598</td>\n",
       "      <td>-0.212838</td>\n",
       "      <td>0.610887</td>\n",
       "      <td>0.922986</td>\n",
       "      <td>0.414140</td>\n",
       "      <td>0.472567</td>\n",
       "      <td>0.462829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_e2e</th>\n",
       "      <td>3.794872</td>\n",
       "      <td>4.230769</td>\n",
       "      <td>3.871795</td>\n",
       "      <td>4.076923</td>\n",
       "      <td>146.743590</td>\n",
       "      <td>853.717949</td>\n",
       "      <td>0.397486</td>\n",
       "      <td>0.249901</td>\n",
       "      <td>0.650876</td>\n",
       "      <td>0.609510</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.326445</td>\n",
       "      <td>0.576954</td>\n",
       "      <td>-0.156303</td>\n",
       "      <td>0.993383</td>\n",
       "      <td>0.947427</td>\n",
       "      <td>0.471359</td>\n",
       "      <td>0.615941</td>\n",
       "      <td>0.591844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>4.011364</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>4.056818</td>\n",
       "      <td>151.272727</td>\n",
       "      <td>881.045455</td>\n",
       "      <td>0.365215</td>\n",
       "      <td>0.219588</td>\n",
       "      <td>0.639793</td>\n",
       "      <td>0.592032</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.406731</td>\n",
       "      <td>0.570985</td>\n",
       "      <td>-0.359126</td>\n",
       "      <td>0.894081</td>\n",
       "      <td>0.940020</td>\n",
       "      <td>0.383516</td>\n",
       "      <td>0.571323</td>\n",
       "      <td>0.540022</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>16.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>2.611111</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>1.966667</td>\n",
       "      <td>147.066667</td>\n",
       "      <td>857.288889</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.164480</td>\n",
       "      <td>0.535734</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.773227</td>\n",
       "      <td>0.543901</td>\n",
       "      <td>-0.730676</td>\n",
       "      <td>0.571184</td>\n",
       "      <td>0.927967</td>\n",
       "      <td>0.200954</td>\n",
       "      <td>0.403018</td>\n",
       "      <td>0.369341</td>\n",
       "      <td>1.355556</td>\n",
       "      <td>10.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coherence  consistency   fluency  relevance          id  \\\n",
       "model_id                                                                    \n",
       "1                  1.853659     1.835366  2.280488   1.823171  158.914634   \n",
       "10                 1.822581     1.604839  1.927419   1.596774  142.806452   \n",
       "2                  1.903226     1.766129  1.991935   1.669355  144.919355   \n",
       "3                  2.094828     1.948276  2.129310   1.887931  142.034483   \n",
       "4                  1.681818     1.522727  1.784091   1.522727  146.159091   \n",
       "6                  2.595238     2.071429  2.595238   2.071429  100.476190   \n",
       "7                  2.571429     2.095238  2.500000   1.880952  161.142857   \n",
       "9_1                1.433333     1.277778  1.566667   1.255556  146.377778   \n",
       "9_2                1.500000     1.375000  1.579545   1.272727  147.886364   \n",
       "German_100         3.810811     4.135135  3.837838   3.972973  141.081081   \n",
       "German_25_False    1.769231     1.743590  1.615385   1.461538  146.743590   \n",
       "German_25_True     1.710526     1.394737  1.631579   1.184211  149.000000   \n",
       "chatGPT_e2e        3.794872     4.230769  3.871795   4.076923  146.743590   \n",
       "chatGPT_pipeline   4.011364     4.090909  4.090909   4.056818  151.272727   \n",
       "chatGPT_title      2.611111     2.100000  3.555556   1.966667  147.066667   \n",
       "\n",
       "                   Unnamed: 0    rouge1    rougel  bertscore_P  bertscore_R  \\\n",
       "model_id                                                                      \n",
       "1                 2125.939024  0.372924  0.194778     0.529634     0.555788   \n",
       "10                 160.064516  0.401842  0.203868     0.543960     0.542666   \n",
       "2                 2792.016129  0.380527  0.202439     0.535075     0.557082   \n",
       "3                 1808.482759  0.413992  0.210625     0.543524     0.570547   \n",
       "4                 1149.090909  0.385257  0.189332     0.538308     0.549011   \n",
       "6                 2447.142857  0.389906  0.196525     0.543192     0.542991   \n",
       "7                  498.904762  0.392206  0.190915     0.548322     0.564667   \n",
       "9_1                818.800000  0.384505  0.201696     0.534163     0.540508   \n",
       "9_2               1473.590909  0.383781  0.197036     0.530773     0.539702   \n",
       "German_100                NaN  0.392146  0.241838     0.640687     0.602221   \n",
       "German_25_False           NaN  0.339585  0.182997     0.531017     0.578221   \n",
       "German_25_True            NaN  0.334671  0.178711     0.521575     0.569477   \n",
       "chatGPT_e2e        853.717949  0.397486  0.249901     0.650876     0.609510   \n",
       "chatGPT_pipeline   881.045455  0.365215  0.219588     0.639793     0.592032   \n",
       "chatGPT_title      857.288889  0.301700  0.164480     0.535734     0.531251   \n",
       "\n",
       "                  ...  bartscore  moverscore     menli  DiscoScore_F  \\\n",
       "model_id          ...                                                  \n",
       "1                 ...  -3.524514    0.564809 -0.250539      2.066134   \n",
       "10                ...  -3.512942    0.572620 -0.323597      1.430239   \n",
       "2                 ...  -3.457672    0.567418 -0.230478      0.817795   \n",
       "3                 ...  -3.437542    0.572572 -0.260093      1.185901   \n",
       "4                 ...  -3.579024    0.568629 -0.313955      1.303712   \n",
       "6                 ...  -3.691951    0.570999 -0.462280      1.059008   \n",
       "7                 ...  -3.417577    0.569898 -0.410667      1.979621   \n",
       "9_1               ...  -3.583005    0.569589 -0.205569      1.658892   \n",
       "9_2               ...  -3.529144    0.567425 -0.278311      1.345965   \n",
       "German_100        ...  -3.408327    0.571886 -0.239390      1.152250   \n",
       "German_25_False   ...  -3.237109    0.555205 -0.230807      0.642544   \n",
       "German_25_True    ...  -3.280749    0.554598 -0.212838      0.610887   \n",
       "chatGPT_e2e       ...  -3.326445    0.576954 -0.156303      0.993383   \n",
       "chatGPT_pipeline  ...  -3.406731    0.570985 -0.359126      0.894081   \n",
       "chatGPT_title     ...  -3.773227    0.543901 -0.730676      0.571184   \n",
       "\n",
       "                  DiscoScore_S  MENLI_W0.8  MENLI_W0.2  MENLI_W0.3  \\\n",
       "model_id                                                             \n",
       "1                     0.943860    0.397900    0.464629    0.453507   \n",
       "10                    0.947991    0.369032    0.459653    0.444550   \n",
       "2                     0.942002    0.407483    0.472621    0.461765   \n",
       "3                     0.945355    0.400082    0.487807    0.473186   \n",
       "4                     0.945065    0.373071    0.461225    0.446533   \n",
       "6                     0.956332    0.313217    0.446140    0.423986   \n",
       "7                     0.953207    0.339417    0.472877    0.450634   \n",
       "9_1                   0.939936    0.414239    0.461968    0.454013   \n",
       "9_2                   0.938577    0.384015    0.451090    0.439911   \n",
       "German_100            0.921370    0.434262    0.593213    0.566721   \n",
       "German_25_False       0.934807    0.410614    0.485641    0.473137   \n",
       "German_25_True        0.922986    0.414140    0.472567    0.462829   \n",
       "chatGPT_e2e           0.947427    0.471359    0.615941    0.591844   \n",
       "chatGPT_pipeline      0.940020    0.383516    0.571323    0.540022   \n",
       "chatGPT_title         0.927967    0.200954    0.403018    0.369341   \n",
       "\n",
       "                  overlap_count        sum  \n",
       "model_id                                    \n",
       "1                      4.170732   7.792683  \n",
       "10                     3.209677   6.951613  \n",
       "2                      3.193548   7.330645  \n",
       "3                      3.241379   8.060345  \n",
       "4                      1.318182   6.511364  \n",
       "6                      5.000000   9.333333  \n",
       "7                      5.000000   9.047619  \n",
       "9_1                    1.355556   5.533333  \n",
       "9_2                    1.363636   5.727273  \n",
       "German_100             1.000000  15.756757  \n",
       "German_25_False        1.000000   6.589744  \n",
       "German_25_True         1.000000   5.921053  \n",
       "chatGPT_e2e            1.000000  15.974359  \n",
       "chatGPT_pipeline       1.363636  16.250000  \n",
       "chatGPT_title          1.355556  10.233333  \n",
       "\n",
       "[15 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_hDe.groupby(\"model_id\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "282bd635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human annotaiton All\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>consistency</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>2.775000</td>\n",
       "      <td>2.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.755000</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>2.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.383333</td>\n",
       "      <td>2.212500</td>\n",
       "      <td>2.487500</td>\n",
       "      <td>2.304167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.416667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_2</th>\n",
       "      <td>1.937500</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>2.687500</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_1</th>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>2.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.089286</td>\n",
       "      <td>1.892857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>2.875000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>2.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coherence  consistency   fluency  relevance\n",
       "model_id                                                     \n",
       "1                  2.100000     2.075000  2.775000   2.225000\n",
       "3                  2.755000     2.440000  2.710000   2.540000\n",
       "2                  2.383333     2.212500  2.487500   2.304167\n",
       "4                  2.416667     2.000000  2.916667   2.666667\n",
       "9_2                1.937500     1.875000  2.687500   2.250000\n",
       "9_1                1.875000     1.500000  2.812500   2.062500\n",
       "10                 2.089286     1.892857  2.428571   2.035714\n",
       "chatGPT_title      2.875000     3.250000  4.750000   2.312500\n",
       "chatGPT_pipeline   4.500000     4.375000  5.000000   4.250000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# human annotation result avg. \n",
    "print(\"human annotaiton All\")\n",
    "summary_level = pd.DataFrame(merged_hDe[(merged_hDe.annotator != \"8\")].set_index(\"id_model\").loc[intersection_of_models].groupby([\"model_id\", \"id\"]).mean()).reset_index() #.iloc[:,:4].loc[model_order_human]\n",
    "human_mean = summary_level.groupby(\"model_id\").mean().iloc[:,1:5].loc[model_order_human]\n",
    "human_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65283d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>consistency</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_2</th>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_1</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coherence  consistency   fluency  relevance\n",
       "model_id                                                     \n",
       "1                  1.875000     1.875000  2.000000   1.625000\n",
       "3                  2.000000     1.800000  2.000000   1.800000\n",
       "2                  1.500000     1.166667  1.833333   1.166667\n",
       "4                  2.000000     2.000000  2.000000   1.333333\n",
       "9_2                1.250000     1.750000  1.250000   1.250000\n",
       "9_1                1.500000     1.250000  1.250000   1.000000\n",
       "10                 1.714286     1.285714  1.714286   1.142857\n",
       "chatGPT_title      2.750000     2.250000  3.250000   2.250000\n",
       "chatGPT_pipeline   4.250000     4.500000  4.000000   4.250000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average ChatGPT annotation results\n",
    "summary_level = pd.DataFrame(merged_hDe[merged_hDe.annotator == \"8\"].set_index(\"id_model\").loc[intersection_of_models].groupby([\"model_id\", \"id\"]).mean()).reset_index() #.iloc[:,:4].loc[model_order_human]\n",
    "chatGPT_mean = summary_level.groupby(\"model_id\").mean().iloc[:,1:5].loc[model_order_human]\n",
    "chatGPT_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5c26cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"chatGPT annotaiton mean, exclude 1s, >5\")\n",
    "#chatGPT_meanmerged_hDe[(merged_hDe.annotator == \"8\") & (merged_hDe[\"sum\"] >4)].groupby(\"model_id\").mean().iloc[:,:4].loc[model_order]#.to_csv(\"tabular/hEn/annotation_mean_GPT.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afd64733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen plots\n",
    "order_anno =[\"coherence_human\",\"coherence_chatGPT\", \"consistency_human\", \"consistency_chatGPT\",\n",
    "             \"fluency_human\", \"fluency_chatGPT\", \"relevance_human\",   'relevance_chatGPT']\n",
    "annotation_human_chatty = pd.merge(human_mean.reset_index(), chatGPT_mean.reset_index(), on = \"model_id\", \n",
    "         suffixes = [\"_human\", \"_chatGPT\"], how = \"outer\").set_index(\"model_id\").loc[model_order_human, order_anno].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f268127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence_human</th>\n",
       "      <th>coherence_chatGPT</th>\n",
       "      <th>consistency_human</th>\n",
       "      <th>consistency_chatGPT</th>\n",
       "      <th>fluency_human</th>\n",
       "      <th>fluency_chatGPT</th>\n",
       "      <th>relevance_human</th>\n",
       "      <th>relevance_chatGPT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.10</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.76</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.38</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.49</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.42</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_2</th>\n",
       "      <td>1.94</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_1</th>\n",
       "      <td>1.88</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.09</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>2.88</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>4.50</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coherence_human  coherence_chatGPT  consistency_human  \\\n",
       "model_id                                                                  \n",
       "1                            2.10               1.88               2.08   \n",
       "3                            2.76               2.00               2.44   \n",
       "2                            2.38               1.50               2.21   \n",
       "4                            2.42               2.00               2.00   \n",
       "9_2                          1.94               1.25               1.88   \n",
       "9_1                          1.88               1.50               1.50   \n",
       "10                           2.09               1.71               1.89   \n",
       "chatGPT_title                2.88               2.75               3.25   \n",
       "chatGPT_pipeline             4.50               4.25               4.38   \n",
       "\n",
       "                  consistency_chatGPT  fluency_human  fluency_chatGPT  \\\n",
       "model_id                                                                \n",
       "1                                1.88           2.78             2.00   \n",
       "3                                1.80           2.71             2.00   \n",
       "2                                1.17           2.49             1.83   \n",
       "4                                2.00           2.92             2.00   \n",
       "9_2                              1.75           2.69             1.25   \n",
       "9_1                              1.25           2.81             1.25   \n",
       "10                               1.29           2.43             1.71   \n",
       "chatGPT_title                    2.25           4.75             3.25   \n",
       "chatGPT_pipeline                 4.50           5.00             4.00   \n",
       "\n",
       "                  relevance_human  relevance_chatGPT  \n",
       "model_id                                              \n",
       "1                            2.22               1.62  \n",
       "3                            2.54               1.80  \n",
       "2                            2.30               1.17  \n",
       "4                            2.67               1.33  \n",
       "9_2                          2.25               1.25  \n",
       "9_1                          2.06               1.00  \n",
       "10                           2.04               1.14  \n",
       "chatGPT_title                2.31               2.25  \n",
       "chatGPT_pipeline             4.25               4.25  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_human_chatty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9d8ec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.10/1.88', '2.08/1.88', '2.78/2.00', '2.22/1.62']\n",
      "['2.76/2.00', '2.44/1.80', '2.71/2.00', '2.54/1.80']\n",
      "['2.38/1.50', '2.21/1.17', '2.49/1.83', '2.30/1.17']\n",
      "['2.42/2.00', '2.00/2.00', '2.92/2.00', '2.67/1.33']\n",
      "['1.94/1.25', '1.88/1.75', '2.69/1.25', '2.25/1.25']\n",
      "['1.88/1.50', '1.50/1.25', '2.81/1.25', '2.06/1.00']\n",
      "['2.09/1.71', '1.89/1.29', '2.43/1.71', '2.04/1.14']\n",
      "['2.88/2.75', '3.25/2.25', '4.75/3.25', '2.31/2.25']\n",
      "['4.50/4.25', '4.38/4.50', '5.00/4.00', '4.25/4.25']\n"
     ]
    }
   ],
   "source": [
    "def turn_string(row):\n",
    "    lst = [\"{:.2f}\".format(i.round(3)) for i in row.values]\n",
    "    lst_ = [\"/\".join(lst[:2]), \"/\".join(lst[2:4]), \"/\".join(lst[4:6]), \"/\".join(lst[6:])]\n",
    "    print(lst_)\n",
    "    return \"&\".join(lst_)\n",
    "#generate latex\n",
    "pd.DataFrame(annotation_human_chatty.apply(lambda x: turn_string(x) + \"\\\\\" + \"\\\\\", axis = 1)).to_csv(\"experiments/latex/hDe_latex_human_chatty_anno.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63789b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau, spearmanr\n",
    "from sklearn.metrics import cohen_kappa_score \n",
    "import scipy\n",
    "def agreement_return(dim, annotator_lst_hEn, merged_hEnidlst, df, exclude = True):\n",
    "    tmp = agreement(dim, annotator_lst_hEn, merged_hEnidlst, df)\n",
    "    cor_lst = []\n",
    "    for a1 in tmp.index:\n",
    "        if exclude:\n",
    "            if dim == \"fluency\":\n",
    "                a1 = int(a1)+1 # exclude fluency from annotator 1\n",
    "                print(a1, dim)\n",
    "        for a2 in  tmp.index:\n",
    "            if int(a2)>int(a1):\n",
    "                agree = tmp.loc[[str(a1),str(a2)]].dropna(axis='columns')\n",
    "                if len(agree.loc[str(a1)]) > 0:\n",
    "                    cor = spearmanr(agree.loc[str(a1)], agree.loc[str(a2)]).correlation\n",
    "                    print(cor, agree, \"\\n\\n\\n\\n\")\n",
    "                    k1 = [int(val) for val in agree.loc[str(a1)]]\n",
    "                    k2 = [int(val) for val in agree.loc[str(a2)]]\n",
    "                    kappa = cohen_kappa_score(k1, k2)\n",
    "                    if a2 == 8:\n",
    "                        print(agree)\n",
    "                    cor_lst.append((a1, a2, cor, kappa, len(agree.loc[str(a1)]), agree.columns.tolist())) # kappa,\n",
    "                else: print(\"length problem\", agree)\n",
    "    return cor_lst\n",
    "\n",
    "def agreement(dim, annotator_lst,idlst, df = merged_hDe, ):\n",
    "    collection = {}\n",
    "    for id_ in idlst:\n",
    "        annotation_lst = []\n",
    "        for annotator in annotator_lst:\n",
    "            sub = df[(df.id == id_) & (df.annotator == annotator)]\n",
    "            if len(sub)>0:\n",
    "                annotation_lst.append(sub[dim].values[0])\n",
    "            else:\n",
    "                annotation_lst.append(np.nan)\n",
    "            collection[id_] = annotation_lst\n",
    "    return pd.DataFrame(collection, index = annotator_lst)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a40801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anno_res(df, exclude):\n",
    "    merged_hEnidlst = df.id.unique()\n",
    "    annotator_lst_hEn = df.annotator.unique()\n",
    "    df_anno = pd.DataFrame()\n",
    "    for dim in ['coherence', 'consistency', 'fluency', 'relevance']:\n",
    "        #print(\"!!!!!\", dim)\n",
    "        cor_lst = agreement_return(dim, annotator_lst_hEn,merged_hEnidlst, df = df, exclude = exclude)\n",
    "        df_anno_ = pd.DataFrame(cor_lst, columns = [\"annotator1\", \"annotator2\", \"spearmanr\", \"kappa\",\"annotation_count\", \"id_list\"]) #\"kappa\",\n",
    "        df_anno_[\"dimension\"] = dim\n",
    "        #print(df_anno_)\n",
    "        df_anno = pd.concat([df_anno, df_anno_])\n",
    "        #print(dim, \"agreement: \", cor_lst)\n",
    "    return df_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9ded310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute interannotation agreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "292d611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47771122896001367    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    1.5    2.0    1.5    1.5    1.5    2.0    1.5    2.0    3.0    2.0  ...   \n",
      "3    2.0    1.0    1.0    1.0    1.0    2.0    4.0    2.0    3.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    3.0    2.0    3.0    3.0    3.0    2.0    3.0    2.0    2.0    2.5  \n",
      "3    3.0    1.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6314401245125855    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "2    1.5    2.0    1.5    1.5    1.5    2.0    1.5    2.0    3.0    2.0   \n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    2.0    2.0    2.0    2.5   \n",
      "\n",
      "   122.0  288.0  \n",
      "2    2.5    2.0  \n",
      "4    3.0    2.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.33841858170650735    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    1.5    2.0    1.5    1.5    1.5    2.0    1.5    2.0    3.0    2.0  ...   \n",
      "5    2.5    3.0    2.5    2.5    2.5    2.5    3.0    3.0    3.0    3.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    3.0    2.0    3.0    3.0    3.0    2.0    3.0    2.0    2.0    2.5  \n",
      "5    3.0    3.0    3.0    3.5    3.0    3.0    3.5    3.0    3.0    3.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.5000000000000001    208.0  21.0   272.0\n",
      "2    2.0    1.5    2.0\n",
      "7    1.0    1.5    1.5 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.029600680637607475    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    1.5    2.0    1.5    1.5    1.5    2.0    1.5    2.0    3.0    2.0  ...   \n",
      "8    2.0    2.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    3.0    2.0    3.0    3.0    3.0    2.0    3.0    2.0    2.0    2.5  \n",
      "8    1.0    2.0    2.0    2.0    1.0    5.0    1.0    2.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.7553112697424857    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "3    2.0    1.0    1.0    1.0    1.0    2.0    4.0    2.0    3.0    3.0   \n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    2.0    2.0    2.0    2.5   \n",
      "\n",
      "   122.0  288.0  \n",
      "3    3.0    1.0  \n",
      "4    3.0    2.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.4120682989008948    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "3    2.0    1.0    1.0    1.0    1.0    2.0    4.0    2.0    3.0    1.0  ...   \n",
      "5    2.5    3.0    2.5    2.5    2.5    2.5    3.0    3.0    3.0    3.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "3    3.0    1.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0  \n",
      "5    3.0    3.0    3.0    3.5    3.0    3.0    3.5    3.0    3.0    3.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "3    1.0    1.0    1.0\n",
      "7    1.0    1.5    1.5 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.15601992435969878    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "3    2.0    1.0    1.0    1.0    1.0    2.0    4.0    2.0    3.0    1.0  ...   \n",
      "8    2.0    2.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "3    3.0    1.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0  \n",
      "8    1.0    2.0    2.0    2.0    1.0    5.0    1.0    2.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.5184281421870574    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    1.5    1.0    2.0    1.5    2.5    2.5    3.5    3.0    3.5    2.0  ...   \n",
      "2    1.5    2.0    1.5    1.5    1.5    2.0    1.5    2.0    3.0    2.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    3.0    3.0    3.0    2.5    3.0    3.0    3.0    3.0    3.0    3.0  \n",
      "2    3.0    2.0    3.0    3.0    3.0    2.0    3.0    2.0    2.0    2.5  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6288734758791662    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    1.5    1.0    2.0    1.5    2.5    2.5    3.5    3.0    3.5    2.0  ...   \n",
      "3    2.0    1.0    1.0    1.0    1.0    2.0    4.0    2.0    3.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    3.0    3.0    3.0    2.5    3.0    3.0    3.0    3.0    3.0    3.0  \n",
      "3    3.0    1.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6799673725567167    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "1    1.5    1.0    2.0    1.5    2.5    2.5    3.5    3.0    3.5    2.5   \n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    2.0    2.0    2.0    2.5   \n",
      "\n",
      "   122.0  288.0  \n",
      "1    3.0    3.0  \n",
      "4    3.0    2.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.2868938758618911    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    1.5    1.0    2.0    1.5    2.5    2.5    3.5    3.0    3.5    2.0  ...   \n",
      "5    2.5    3.0    2.5    2.5    2.5    2.5    3.0    3.0    3.0    3.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    3.0    3.0    3.0    2.5    3.0    3.0    3.0    3.0    3.0    3.0  \n",
      "5    3.0    3.0    3.0    3.5    3.0    3.0    3.5    3.0    3.0    3.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8660254037844387    208.0  21.0   272.0\n",
      "1    1.0    1.5    2.0\n",
      "7    1.0    1.5    1.5 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.06347671366642246    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    1.5    1.0    2.0    1.5    2.5    2.5    3.5    3.0    3.5    2.0  ...   \n",
      "8    2.0    2.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    3.0    3.0    3.0    2.5    3.0    3.0    3.0    3.0    3.0    3.0  \n",
      "8    1.0    2.0    2.0    2.0    1.0    5.0    1.0    2.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6434737624985188    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    2.0    2.0    2.0    2.5   \n",
      "5    2.5    3.0    2.5    2.5    2.5    2.5    3.0    3.0    3.0    4.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "4    3.0    2.0  \n",
      "5    3.0    3.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0 \n",
      "4    1.0    1.0\n",
      "7    1.0    1.5 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.3359419867484068    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    2.0    2.0    2.0    2.5   \n",
      "8    2.0    2.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "4    3.0    2.0  \n",
      "8    1.0    2.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.5000000000000001    208.0  21.0   272.0\n",
      "5    3.0    2.5    3.0\n",
      "7    1.0    1.5    1.5 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.06525568224334392    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "5    2.5    3.0    2.5    2.5    2.5    2.5    3.0    3.0    3.0    3.0  ...   \n",
      "8    2.0    2.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "5    3.0    3.0    3.0    3.5    3.0    3.0    3.5    3.0    3.0    3.0  \n",
      "8    1.0    2.0    2.0    2.0    1.0    5.0    1.0    2.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.5000000000000001    208.0  21.0   272.0\n",
      "7    1.0    1.5    1.5\n",
      "8    2.0    2.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.7467503500423677    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    2.0    2.0    2.0    2.0    1.5    3.0    3.5    3.0    3.0    2.0  ...   \n",
      "3    1.0    1.0    1.0    2.0    1.0    2.0    3.0    2.0    2.5    2.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    2.0    2.5    2.5    2.0    2.5    1.0    2.0    3.0    2.5    2.0  \n",
      "3    2.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0    1.0    2.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8916077244164782    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "2    2.0    2.0    2.0    2.0    1.5    3.0    3.5    3.0    3.0    3.0   \n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    3.0    2.0    2.5    3.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "2    3.0    2.5  \n",
      "4    3.5    1.5   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.2939697258003445    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    2.0    2.0    2.0    2.0    1.5    3.0    3.5    3.0    3.0    2.0  ...   \n",
      "5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    2.0    1.5  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    2.0    2.5    2.5    2.0    2.5    1.0    2.0    3.0    2.5    2.0  \n",
      "5    2.0    2.0    2.5    3.0    1.5    1.5    2.0    1.5    2.0    2.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "2    2.0    2.0    2.0\n",
      "7    1.0    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.09481428726817134    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    2.0    2.0    2.0    2.0    1.5    3.0    3.5    3.0    3.0    2.0  ...   \n",
      "8    2.0    1.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    2.0    2.5    2.5    2.0    2.5    1.0    2.0    3.0    2.5    2.0  \n",
      "8    1.0    1.0    1.0    2.0    1.0    5.0    1.0    1.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8553082268105884    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "3    1.0    1.0    1.0    2.0    1.0    2.0    3.0    2.0    2.5    3.0   \n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    3.0    2.0    2.5    3.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "3    3.0    2.0  \n",
      "4    3.5    1.5   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.4370666466289446    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "3    1.0    1.0    1.0    2.0    1.0    2.0    3.0    2.0    2.5    2.0  ...   \n",
      "5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    2.0    1.5  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "3    2.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0    1.0    2.0  \n",
      "5    2.0    2.0    2.5    3.0    1.5    1.5    2.0    1.5    2.0    2.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "3    1.0    2.0    2.0\n",
      "7    1.0    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.07462451496387155    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "3    1.0    1.0    1.0    2.0    1.0    2.0    3.0    2.0    2.5    2.0  ...   \n",
      "8    2.0    1.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "3    2.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0    1.0    2.0  \n",
      "8    1.0    1.0    1.0    2.0    1.0    5.0    1.0    1.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6441228335172803    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    2.0    2.5    2.0    2.5    2.0    2.5    3.5    3.0    4.0    2.5  ...   \n",
      "2    2.0    2.0    2.0    2.0    1.5    3.0    3.5    3.0    3.0    2.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.0    2.0    3.0    2.0    2.0    2.5    2.0    2.5    2.5    3.0  \n",
      "2    2.0    2.5    2.5    2.0    2.5    1.0    2.0    3.0    2.5    2.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6413173316915852    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    2.0    2.5    2.0    2.5    2.0    2.5    3.5    3.0    4.0    2.5  ...   \n",
      "3    1.0    1.0    1.0    2.0    1.0    2.0    3.0    2.0    2.5    2.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.0    2.0    3.0    2.0    2.0    2.5    2.0    2.5    2.5    3.0  \n",
      "3    2.0    2.0    2.0    2.0    2.0    2.0    2.0    2.0    1.0    2.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.7619507692573538    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "1    2.0    2.5    2.0    2.5    2.0    2.5    3.5    3.0    4.0    3.0   \n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    3.0    2.0    2.5    3.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "1    4.0    2.0  \n",
      "4    3.5    1.5   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.2397521541596815    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    2.0    2.5    2.0    2.5    2.0    2.5    3.5    3.0    4.0    2.5  ...   \n",
      "5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    2.0    1.5  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.0    2.0    3.0    2.0    2.0    2.5    2.0    2.5    2.5    3.0  \n",
      "5    2.0    2.0    2.5    3.0    1.5    1.5    2.0    1.5    2.0    2.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "1    2.5    2.5    2.5\n",
      "7    1.0    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.12329674886724826    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    2.0    2.5    2.0    2.5    2.0    2.5    3.5    3.0    4.0    2.5  ...   \n",
      "8    2.0    1.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.0    2.0    3.0    2.0    2.0    2.5    2.0    2.5    2.5    3.0  \n",
      "8    1.0    1.0    1.0    2.0    1.0    5.0    1.0    1.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6086484194925051    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    3.0    2.0    2.5    3.0   \n",
      "5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    2.0    2.5   \n",
      "\n",
      "   122.0  288.0  \n",
      "4    3.5    1.5  \n",
      "5    2.5    2.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0 \n",
      "4    1.0    1.0\n",
      "7    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.1452664022548461    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "4    1.5    1.0    1.5    1.0    1.0    2.0    3.0    2.0    2.5    3.0   \n",
      "8    2.0    1.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "4    3.5    1.5  \n",
      "8    1.0    1.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "5    1.5    1.5    1.5\n",
      "7    1.0    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.07814508102336445    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    1.5    2.0    1.5  ...   \n",
      "8    2.0    1.0    1.0    2.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "5    2.0    2.0    2.5    3.0    1.5    1.5    2.0    1.5    2.0    2.0  \n",
      "8    1.0    1.0    1.0    2.0    1.0    5.0    1.0    1.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "7    1.0    1.0    1.0\n",
      "8    1.0    2.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.14252586783914237    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    3.0    3.0    2.5    2.5    2.5    3.0    3.0    2.5    3.5    3.0  ...   \n",
      "3    3.0    2.0    3.0    3.0    3.0    2.0    4.0    2.0    3.0    2.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    2.5    2.0    3.0    3.0    3.0    2.0    3.0    2.0    2.5    2.5  \n",
      "3    3.0    2.0    2.0    3.0    2.0    3.0    3.0    3.0    2.0    3.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.24672857543871607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "2    3.0    3.0    2.5    2.5    2.5    3.0    3.0    2.5    3.5    2.5   \n",
      "4    2.5    2.5    2.5    1.5    1.0    2.5    2.5    2.5    2.5    3.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "2    3.0    2.0  \n",
      "4    4.0    2.5   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.37425114427183365    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    3.0    3.0    2.5    2.5    2.5    3.0    3.0    2.5    3.5    3.0  ...   \n",
      "5    3.0    3.5    3.0    3.0    2.0    3.0    3.0    2.5    3.0    3.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    2.5    2.0    3.0    3.0    3.0    2.0    3.0    2.0    2.5    2.5  \n",
      "5    2.5    2.0    2.0    4.0    3.0    2.5    3.0    2.0    2.0    3.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "2    3.0    2.5    3.0\n",
      "7    2.0    2.0    2.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.0297912987241933    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    3.0    3.0    2.5    2.5    2.5    3.0    3.0    2.5    3.5    3.0  ...   \n",
      "8    2.0    2.0    1.0    2.0    1.0    2.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    2.5    2.0    3.0    3.0    3.0    2.0    3.0    2.0    2.5    2.5  \n",
      "8    2.0    2.0    2.0    2.0    1.0    4.0    1.0    2.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.19983491536600892    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "3    3.0    2.0    3.0    3.0    3.0    2.0    4.0    2.0    3.0    3.0   \n",
      "4    2.5    2.5    2.5    1.5    1.0    2.5    2.5    2.5    2.5    3.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "3    4.0    2.0  \n",
      "4    4.0    2.5   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.2926618514264255    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "3    3.0    2.0    3.0    3.0    3.0    2.0    4.0    2.0    3.0    2.0  ...   \n",
      "5    3.0    3.5    3.0    3.0    2.0    3.0    3.0    2.5    3.0    3.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "3    3.0    2.0    2.0    3.0    2.0    3.0    3.0    3.0    2.0    3.0  \n",
      "5    2.5    2.0    2.0    4.0    3.0    2.5    3.0    2.0    2.0    3.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "3    2.0    3.0    2.0\n",
      "7    2.0    2.0    2.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.05094704850504814    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "3    3.0    2.0    3.0    3.0    3.0    2.0    4.0    2.0    3.0    2.0  ...   \n",
      "8    2.0    2.0    1.0    2.0    1.0    2.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "3    3.0    2.0    2.0    3.0    2.0    3.0    3.0    3.0    2.0    3.0  \n",
      "8    2.0    2.0    2.0    2.0    1.0    4.0    1.0    2.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.2589189109735236    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    3.0    3.5    3.0    3.5    2.5    3.0    3.5    3.5    3.5    2.5  ...   \n",
      "2    3.0    3.0    2.5    2.5    2.5    3.0    3.0    2.5    3.5    3.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.5    3.0    1.5    1.5    2.5    3.0    3.0    2.0    2.0    2.5  \n",
      "2    2.5    2.0    3.0    3.0    3.0    2.0    3.0    2.0    2.5    2.5  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.07676468925431788    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    3.0    3.5    3.0    3.5    2.5    3.0    3.5    3.5    3.5    2.5  ...   \n",
      "3    3.0    2.0    3.0    3.0    3.0    2.0    4.0    2.0    3.0    2.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.5    3.0    1.5    1.5    2.5    3.0    3.0    2.0    2.0    2.5  \n",
      "3    3.0    2.0    2.0    3.0    2.0    3.0    3.0    3.0    2.0    3.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.4045685882199178    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "1    3.0    3.5    3.0    3.5    2.5    3.0    3.5    3.5    3.5    1.5   \n",
      "4    2.5    2.5    2.5    1.5    1.0    2.5    2.5    2.5    2.5    3.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "1    2.0    3.0  \n",
      "4    4.0    2.5   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.09181712498700557    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    3.0    3.5    3.0    3.5    2.5    3.0    3.5    3.5    3.5    2.5  ...   \n",
      "5    3.0    3.5    3.0    3.0    2.0    3.0    3.0    2.5    3.0    3.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.5    3.0    1.5    1.5    2.5    3.0    3.0    2.0    2.0    2.5  \n",
      "5    2.5    2.0    2.0    4.0    3.0    2.5    3.0    2.0    2.0    3.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "1    3.5    3.5    2.5\n",
      "7    2.0    2.0    2.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.24483628112102004    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    3.0    3.5    3.0    3.5    2.5    3.0    3.5    3.5    3.5    2.5  ...   \n",
      "8    2.0    2.0    1.0    2.0    1.0    2.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.5    3.0    1.5    1.5    2.5    3.0    3.0    2.0    2.0    2.5  \n",
      "8    2.0    2.0    2.0    2.0    1.0    4.0    1.0    2.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6621419376570247    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "4    2.5    2.5    2.5    1.5    1.0    2.5    2.5    2.5    2.5    3.0   \n",
      "5    3.0    3.5    3.0    3.0    2.0    3.0    3.0    2.5    3.0    4.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "4    4.0    2.5  \n",
      "5    3.5    2.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0 \n",
      "4    2.5    1.5\n",
      "7    2.0    2.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.22915193257678956    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "4    2.5    2.5    2.5    1.5    1.0    2.5    2.5    2.5    2.5    3.0   \n",
      "8    2.0    2.0    1.0    2.0    1.0    2.0    1.0    1.0    5.0    1.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "4    4.0    2.5  \n",
      "8    1.0    2.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "5    3.5    3.0    3.0\n",
      "7    2.0    2.0    2.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.12596054939367266    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "5    3.0    3.5    3.0    3.0    2.0    3.0    3.0    2.5    3.0    3.0  ...   \n",
      "8    2.0    2.0    1.0    2.0    1.0    2.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "5    2.5    2.0    2.0    4.0    3.0    2.5    3.0    2.0    2.0    3.0  \n",
      "8    2.0    2.0    2.0    2.0    1.0    4.0    1.0    2.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "7    2.0    2.0    2.0\n",
      "8    2.0    2.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8141190611084582    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    2.5    1.5    2.0    2.0    1.5    1.5    4.0    2.0    3.0    2.0  ...   \n",
      "3    1.5    1.0    1.0    1.5    1.0    2.0    4.0    2.0    3.0    1.5  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    2.5    1.5    2.5    3.0    2.0    1.5    2.5    1.5    2.0    2.5  \n",
      "3    3.0    1.0    3.0    2.5    1.0    1.0    3.0    1.0    2.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6673468449559495    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "2    2.5    1.5    2.0    2.0    1.5    1.5    4.0    2.0    3.0    3.0   \n",
      "4    1.5    1.5    1.5    1.0    1.0    2.5    3.0    1.5    2.5    3.5   \n",
      "\n",
      "   122.0  288.0  \n",
      "2    3.5    1.5  \n",
      "4    4.0    1.5   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.412721630134    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    2.5    1.5    2.0    2.0    1.5    1.5    4.0    2.0    3.0    2.0  ...   \n",
      "5    1.5    1.5    1.5    2.5    3.5    2.0    3.5    2.5    2.0    1.5  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    2.5    1.5    2.5    3.0    2.0    1.5    2.5    1.5    2.0    2.5  \n",
      "5    1.0    1.0    2.0    3.0    1.0    1.0    1.5    1.0    1.5    1.5  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "2    1.5    2.0    2.0\n",
      "7    1.0    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.16940824686469574    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "2    2.5    1.5    2.0    2.0    1.5    1.5    4.0    2.0    3.0    2.0  ...   \n",
      "8    2.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "2    2.5    1.5    2.5    3.0    2.0    1.5    2.5    1.5    2.0    2.5  \n",
      "8    1.0    1.0    1.0    2.0    1.0    5.0    1.0    1.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8172552128238159    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "3    1.5    1.0    1.0    1.5    1.0    2.0    4.0    2.0    3.0    3.0   \n",
      "4    1.5    1.5    1.5    1.0    1.0    2.5    3.0    1.5    2.5    3.5   \n",
      "\n",
      "   122.0  288.0  \n",
      "3    4.0    1.0  \n",
      "4    4.0    1.5   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.44897216086468356    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "3    1.5    1.0    1.0    1.5    1.0    2.0    4.0    2.0    3.0    1.5  ...   \n",
      "5    1.5    1.5    1.5    2.5    3.5    2.0    3.5    2.5    2.0    1.5  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "3    3.0    1.0    3.0    2.5    1.0    1.0    3.0    1.0    2.0    1.0  \n",
      "5    1.0    1.0    2.0    3.0    1.0    1.0    1.5    1.0    1.5    1.5  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "3    1.0    1.5    1.5\n",
      "7    1.0    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.0991540278199479    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "3    1.5    1.0    1.0    1.5    1.0    2.0    4.0    2.0    3.0    1.5  ...   \n",
      "8    2.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "3    3.0    1.0    3.0    2.5    1.0    1.0    3.0    1.0    2.0    1.0  \n",
      "8    1.0    1.0    1.0    2.0    1.0    5.0    1.0    1.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6435582282385324    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    2.0    2.0    2.5    2.0    1.5    3.0    4.0    3.5    4.0    2.0  ...   \n",
      "2    2.5    1.5    2.0    2.0    1.5    1.5    4.0    2.0    3.0    2.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.0    1.0    3.5    2.5    1.5    2.5    2.0    2.5    2.5    3.0  \n",
      "2    2.5    1.5    2.5    3.0    2.0    1.5    2.5    1.5    2.0    2.5  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6758510112741278    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    2.0    2.0    2.5    2.0    1.5    3.0    4.0    3.5    4.0    2.0  ...   \n",
      "3    1.5    1.0    1.0    1.5    1.0    2.0    4.0    2.0    3.0    1.5  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.0    1.0    3.5    2.5    1.5    2.5    2.0    2.5    2.5    3.0  \n",
      "3    3.0    1.0    3.0    2.5    1.0    1.0    3.0    1.0    2.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.7673195317185016    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "1    2.0    2.0    2.5    2.0    1.5    3.0    4.0    3.5    4.0    3.0   \n",
      "4    1.5    1.5    1.5    1.0    1.0    2.5    3.0    1.5    2.5    3.5   \n",
      "\n",
      "   122.0  288.0  \n",
      "1    4.0    1.0  \n",
      "4    4.0    1.5   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.4363144927763341    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    2.0    2.0    2.5    2.0    1.5    3.0    4.0    3.5    4.0    2.0  ...   \n",
      "5    1.5    1.5    1.5    2.5    3.5    2.0    3.5    2.5    2.0    1.5  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.0    1.0    3.5    2.5    1.5    2.5    2.0    2.5    2.5    3.0  \n",
      "5    1.0    1.0    2.0    3.0    1.0    1.0    1.5    1.0    1.5    1.5  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "1    2.0    2.0    2.0\n",
      "7    1.0    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.1927537134000787    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "1    2.0    2.0    2.5    2.0    1.5    3.0    4.0    3.5    4.0    2.0  ...   \n",
      "8    2.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "1    2.0    1.0    3.5    2.5    1.5    2.5    2.0    2.5    2.5    3.0  \n",
      "8    1.0    1.0    1.0    2.0    1.0    5.0    1.0    1.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.30192641078885457    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "4    1.5    1.5    1.5    1.0    1.0    2.5    3.0    1.5    2.5    3.5   \n",
      "5    1.5    1.5    1.5    2.5    3.5    2.0    3.5    2.5    2.0    3.5   \n",
      "\n",
      "   122.0  288.0  \n",
      "4    4.0    1.5  \n",
      "5    3.0    1.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0 \n",
      "4    1.5    1.0\n",
      "7    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.05315314383198459    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   156.0  \\\n",
      "4    1.5    1.5    1.5    1.0    1.0    2.5    3.0    1.5    2.5    3.5   \n",
      "8    2.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    5.0    1.0   \n",
      "\n",
      "   122.0  288.0  \n",
      "4    4.0    1.5  \n",
      "8    1.0    1.0   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "5    1.5    2.5    1.5\n",
      "7    1.0    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.04616442407999539    199.0  208.0  261.0  21.0   268.0  59.0   179.0  314.0  38.0   272.0  ...  \\\n",
      "5    1.5    1.5    1.5    2.5    3.5    2.0    3.5    2.5    2.0    1.5  ...   \n",
      "8    2.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    5.0    1.0  ...   \n",
      "\n",
      "   23.0   288.0  52.0   169.0  37.0   228.0  35.0   275.0  61.0   4.0    \n",
      "5    1.0    1.0    2.0    3.0    1.0    1.0    1.5    1.0    1.5    1.5  \n",
      "8    1.0    1.0    1.0    2.0    1.0    5.0    1.0    1.0    1.0    1.0  \n",
      "\n",
      "[2 rows x 31 columns] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan    208.0  21.0   272.0\n",
      "7    1.0    1.0    1.0\n",
      "8    1.0    1.0    1.0 \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    }
   ],
   "source": [
    "df = merged_hDe[(merged_hDe[\"sum\"] >0) ] \n",
    "df_anno = anno_res(df, exclude = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4c7bae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spearmanr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence</th>\n",
       "      <td>0.537259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.612049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluency</th>\n",
       "      <td>0.175744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance</th>\n",
       "      <td>0.598538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             spearmanr\n",
       "dimension             \n",
       "coherence     0.537259\n",
       "consistency   0.612049\n",
       "fluency       0.175744\n",
       "relevance     0.598538"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anno[(df_anno.annotation_count > 10) & (df_anno.annotator2 != \"8\") & (df_anno.annotator2 != \"7\")].groupby(\"dimension\").mean().iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16cea588",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.DataFrame(df[(df.annotator != \"8\") & (df.annotator != \"7\")].groupby([\"model_id\", 'id']).mean()).reset_index()\n",
    "chatty = df[df.annotator == \"8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "660d0f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>consistency</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "      <th>id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougel</th>\n",
       "      <th>bertscore_P</th>\n",
       "      <th>bertscore_R</th>\n",
       "      <th>...</th>\n",
       "      <th>bartscore</th>\n",
       "      <th>moverscore</th>\n",
       "      <th>menli</th>\n",
       "      <th>DiscoScore_F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI_W0.8</th>\n",
       "      <th>MENLI_W0.2</th>\n",
       "      <th>MENLI_W0.3</th>\n",
       "      <th>overlap_count</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.58</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.39</td>\n",
       "      <td>140.17</td>\n",
       "      <td>2116.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.11</td>\n",
       "      <td>6.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.58</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>144.53</td>\n",
       "      <td>167.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.76</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.56</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.23</td>\n",
       "      <td>146.74</td>\n",
       "      <td>2792.72</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.69</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.72</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.50</td>\n",
       "      <td>144.06</td>\n",
       "      <td>1814.72</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.42</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.69</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.53</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.32</td>\n",
       "      <td>149.05</td>\n",
       "      <td>1151.76</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.13</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_1</th>\n",
       "      <td>1.38</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.15</td>\n",
       "      <td>146.74</td>\n",
       "      <td>825.67</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.15</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_2</th>\n",
       "      <td>1.45</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.16</td>\n",
       "      <td>145.13</td>\n",
       "      <td>1478.03</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.16</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_100</th>\n",
       "      <td>3.81</td>\n",
       "      <td>4.14</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.97</td>\n",
       "      <td>141.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_25_False</th>\n",
       "      <td>1.77</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.46</td>\n",
       "      <td>146.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_25_True</th>\n",
       "      <td>1.71</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.18</td>\n",
       "      <td>149.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_e2e</th>\n",
       "      <td>3.79</td>\n",
       "      <td>4.23</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.08</td>\n",
       "      <td>146.74</td>\n",
       "      <td>853.72</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.33</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>3.92</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.03</td>\n",
       "      <td>149.05</td>\n",
       "      <td>868.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.16</td>\n",
       "      <td>15.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>2.54</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.90</td>\n",
       "      <td>146.74</td>\n",
       "      <td>855.72</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.15</td>\n",
       "      <td>9.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coherence  consistency  fluency  relevance      id  \\\n",
       "model_id                                                               \n",
       "1                      1.58         1.61     1.61       1.39  140.17   \n",
       "10                     1.58         1.37     1.58       1.29  144.53   \n",
       "2                      1.56         1.46     1.69       1.23  146.74   \n",
       "3                      1.72         1.64     1.75       1.50  144.06   \n",
       "4                      1.53         1.39     1.58       1.32  149.05   \n",
       "9_1                    1.38         1.26     1.38       1.15  146.74   \n",
       "9_2                    1.45         1.32     1.42       1.16  145.13   \n",
       "German_100             3.81         4.14     3.84       3.97  141.08   \n",
       "German_25_False        1.77         1.74     1.62       1.46  146.74   \n",
       "German_25_True         1.71         1.39     1.63       1.18  149.00   \n",
       "chatGPT_e2e            3.79         4.23     3.87       4.08  146.74   \n",
       "chatGPT_pipeline       3.92         4.05     3.95       4.03  149.05   \n",
       "chatGPT_title          2.54         1.95     3.36       1.90  146.74   \n",
       "\n",
       "                  Unnamed: 0  rouge1  rougel  bertscore_P  bertscore_R  ...  \\\n",
       "model_id                                                                ...   \n",
       "1                    2116.69    0.39    0.20         0.53         0.56  ...   \n",
       "10                    167.26    0.39    0.20         0.53         0.55  ...   \n",
       "2                    2792.72    0.38    0.20         0.53         0.55  ...   \n",
       "3                    1814.72    0.40    0.20         0.54         0.57  ...   \n",
       "4                    1151.76    0.38    0.19         0.54         0.55  ...   \n",
       "9_1                   825.67    0.38    0.20         0.53         0.54  ...   \n",
       "9_2                  1478.03    0.38    0.20         0.53         0.54  ...   \n",
       "German_100               NaN    0.39    0.24         0.64         0.60  ...   \n",
       "German_25_False          NaN    0.34    0.18         0.53         0.58  ...   \n",
       "German_25_True           NaN    0.33    0.18         0.52         0.57  ...   \n",
       "chatGPT_e2e           853.72    0.40    0.25         0.65         0.61  ...   \n",
       "chatGPT_pipeline      868.34    0.38    0.23         0.64         0.60  ...   \n",
       "chatGPT_title         855.72    0.30    0.17         0.54         0.53  ...   \n",
       "\n",
       "                  bartscore  moverscore  menli  DiscoScore_F  DiscoScore_S  \\\n",
       "model_id                                                                     \n",
       "1                     -3.45        0.57  -0.22          1.78          0.94   \n",
       "10                    -3.54        0.57  -0.33          1.20          0.94   \n",
       "2                     -3.52        0.57  -0.21          1.02          0.94   \n",
       "3                     -3.42        0.57  -0.22          1.33          0.94   \n",
       "4                     -3.54        0.57  -0.33          1.38          0.94   \n",
       "9_1                   -3.56        0.57  -0.21          1.64          0.94   \n",
       "9_2                   -3.55        0.57  -0.28          1.44          0.94   \n",
       "German_100            -3.41        0.57  -0.24          1.15          0.92   \n",
       "German_25_False       -3.24        0.56  -0.23          0.64          0.93   \n",
       "German_25_True        -3.28        0.55  -0.21          0.61          0.92   \n",
       "chatGPT_e2e           -3.33        0.58  -0.16          0.99          0.95   \n",
       "chatGPT_pipeline      -3.41        0.57  -0.32          0.94          0.94   \n",
       "chatGPT_title         -3.77        0.54  -0.72          0.66          0.93   \n",
       "\n",
       "                  MENLI_W0.8  MENLI_W0.2  MENLI_W0.3  overlap_count    sum  \n",
       "model_id                                                                    \n",
       "1                       0.41        0.48        0.46           2.11   6.19  \n",
       "10                      0.36        0.45        0.44           1.76   5.82  \n",
       "2                       0.41        0.47        0.46           1.69   5.95  \n",
       "3                       0.42        0.49        0.48           1.69   6.61  \n",
       "4                       0.37        0.46        0.44           1.13   5.82  \n",
       "9_1                     0.41        0.46        0.45           1.15   5.18  \n",
       "9_2                     0.38        0.45        0.44           1.16   5.34  \n",
       "German_100              0.43        0.59        0.57           1.00  15.76  \n",
       "German_25_False         0.41        0.49        0.47           1.00   6.59  \n",
       "German_25_True          0.41        0.47        0.46           1.00   5.92  \n",
       "chatGPT_e2e             0.47        0.62        0.59           1.00  15.97  \n",
       "chatGPT_pipeline        0.40        0.58        0.55           1.16  15.95  \n",
       "chatGPT_title           0.21        0.40        0.37           1.15   9.74  \n",
       "\n",
       "[13 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatty.groupby(\"model_id\").mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d0b0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human chatty corr\n",
    "human_chatty = pd.merge(human[['model_id', 'id', 'coherence', 'consistency', 'fluency', 'relevance',]], chatty[['model_id', 'id', 'coherence', 'consistency', 'fluency', 'relevance',]], on = [\"id\", \"model_id\"], how = \"left\", suffixes = [\"_human\", \"_chatty\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52b8d978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence_chatty</th>\n",
       "      <th>consistency_chatty</th>\n",
       "      <th>fluency_chatty</th>\n",
       "      <th>relevance_chatty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence_human</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency_human</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluency_human</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance_human</th>\n",
       "      <td>0.564</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   coherence_chatty  consistency_chatty  fluency_chatty  \\\n",
       "coherence_human               0.490               0.410           0.455   \n",
       "consistency_human             0.655               0.569           0.665   \n",
       "fluency_human                 0.618               0.618           0.597   \n",
       "relevance_human               0.564               0.628           0.431   \n",
       "\n",
       "                   relevance_chatty  \n",
       "coherence_human               0.515  \n",
       "consistency_human             0.679  \n",
       "fluency_human                 0.591  \n",
       "relevance_human               0.577  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_chatty.corr(\"spearman\").loc[[\"coherence_human\", \"consistency_human\", \"fluency_human\", \"relevance_human\"], [\"coherence_chatty\", \"consistency_chatty\", \"fluency_chatty\", \"relevance_chatty\"]].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b21edac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ['coherence', 'consistency', 'fluency', 'relevance'] + order_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8272cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_level_coorr(df_):\n",
    "    df = df_.groupby([\"id\", \"model_id\"])[columns_list].mean() # summary level aggregation\n",
    "    dct = {}\n",
    "    for dim in ['coherence', 'consistency', 'fluency', 'relevance']:\n",
    "        lst_tau = []\n",
    "        lst_spearmanr = []\n",
    "        lst_pr = []\n",
    "        lst_ptau = []\n",
    "        for metric in order_metric:\n",
    "            #if dim == \"fluency\":\n",
    "             #   df = df_[df_.annotator != \"1\"].groupby([\"id\", \"model_id\"])[columns_list].mean()\n",
    "               # except:pass\n",
    "            #else: \n",
    "             #   tmp = df\n",
    "            lst_tau.append(kendalltau(y=df[dim], x=df[metric]).correlation) #scipy.stats.weightedtau \n",
    "            lst_ptau.append(kendalltau(y=df[dim], x=df[metric]).pvalue)\n",
    "            lst_spearmanr.append(spearmanr(df[dim], df[metric]).correlation)\n",
    "            #lst_pr.append(pearsonr(x=df[dim], y=df[metric])[1])\n",
    "        dct[dim] = lst_spearmanr\n",
    "        #dct[dim+\"_pvalue\"] = lst_pr\n",
    "        #dct[dim+\"_tau\"] = lst_tau\n",
    "        #dct[dim+\"_pvalue_tau\"] = lst_ptau\n",
    "\n",
    "    return pd.DataFrame(dct, index = order_metric)#.to_csv(\"tabular/hDe/corr_segment_HUMAN.csv\", index = True)\n",
    "    #.loc[['rouge1', 'rougel','bertscore', 'bartscore', 'moverscore',  'menli', 'supert']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dec8bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hDe = merged_hDe.rename(columns = {\"rouge1\": \"ROUGE-1\", \"rougel\":\"ROUGE-L\", 'bertscore_P': \"BERTScore-P\", 'bertscore_R':\"BERTScore-R\", \n",
    "                      'bertscore_F1': \"BERTScore-F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI-W1',\n",
    "                                    'MENLI_W0.8': 'MENLI-W.8', 'MENLI_W0.3':'MENLI-W.3', 'MENLI_W0.2':'MENLI-W.2', \"DiscoScore_F\":\"DiscoScore-F\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4528072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hDe[\"id_model\"] = merged_hDe.apply(lambda x: str(x[\"id\"]) + \"_\" + x[\"model_id\"], axis = 1)\n",
    "intersection_of_models = set(merged_hDe[(merged_hDe.annotator != \"8\" ) & (merged_hDe.annotator != \"7\" )].id_model.unique()).intersection(set(merged_hDe[(merged_hDe.annotator == \"8\" )].id_model.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c106246",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_diff = ['ROUGE-1', 'ROUGE-L', 'BERTScore-P', 'BERTScore-R', 'BERTScore-F1',\n",
    "       'BARTScore', 'MoverScore', 'MENLI-W1','MENLI-W.8',  'MENLI-W.3', 'MENLI-W.2', 'DiscoScore-F', \n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "217c7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "df_ = merged_hDe[(merged_hDe.annotator != \"8\" )].set_index(\"id_model\").loc[intersection_of_models]#.set_index(\"annotator\").loc[[\"1\",\"2\",\"3\"]].reset_index()#.loc[[\"4\",\"5\"]].reset_index()# \n",
    "inter1 = df_.groupby(\"id_model\").mean()\n",
    "#segment_human = segment_level_coorr(df_)\n",
    "#segment_human.round(3)\n",
    "caseALL = inter1.corr(\"spearman\").iloc[:4, 6:19]\n",
    "from scipy.stats import pearsonr\n",
    "pval = inter1.corr(method=lambda x, y: pearsonr(x, y)[1]).iloc[:4, 6:19] #- np.eye(*caseF.shape)\n",
    "p = pval.applymap(lambda x: \"\\n\\n\" + ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "label = caseALL.round(2).astype(str) + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d67f2d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.heatmap(caseALL.loc[:,metric_diff].round(2),\n",
    "            #mask= (p.loc[:,metric_diff] != \"*\"),\n",
    "            # Use annot key with np.array as value containing strings of data + latex \n",
    "            # prefixes/suffices making the bold/italic/underline formatting\n",
    "            #annot_kws={\"style\": \"italic\", \"weight\": \"bold\"},\n",
    "            annot=label.loc[:,metric_diff],\n",
    "            # fmt key must be empty, formatting error otherwise\n",
    "            fmt=\"\",#'0.2f',,\n",
    "            cbar=False,\n",
    "            linewidth=0.5,\n",
    "            cmap=\"coolwarm_r\")\n",
    "plt.savefig('hDe-en-segment_cor.pdf',bbox_inches='tight', pad_inches=0 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74c50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5cee188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = merged_hDe[(merged_hDe.annotator != \"8\" )].set_index(\"id_model\").loc[intersection_of_models]#.set_index(\"annotator\").loc[[\"1\",\"2\",\"3\"]].reset_index()#.loc[[\"4\",\"5\"]].reset_index()# \n",
    "inter2 = df_[(df_.model_id != 'chatGPT_title') & (df_.model_id != 'chatGPT_pipeline')].groupby(\"id_model\").mean()\n",
    "#segment_human = segment_level_coorr(df_)\n",
    "#segment_human.round(3)\n",
    "caseF = inter2.corr(\"spearman\").iloc[:4, 6:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d69b4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "boostrap = []\n",
    "for i in range(20000):\n",
    "    diff = inter2.sample(20).corr(\"spearman\").iloc[:4, 6:19] - inter1.sample(20).corr(\"spearman\").iloc[:4, 6:19] \n",
    "    boostrap.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6438c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import statsmodels.stats.api as sms\n",
    "diff = pd.DataFrame(columns = caseF.columns, index = caseF.index)\n",
    "for dim in caseF.index:\n",
    "    for metric in caseF.columns:\n",
    "        lst = []\n",
    "        for df in boostrap:\n",
    "            lst.append(df.loc[dim, metric])\n",
    "        conf = sms.DescrStatsW(lst).tconfint_mean()\n",
    "        diff.loc[dim, metric] = [round(con, 1) for con in conf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44fb5418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore-P</th>\n",
       "      <th>BERTScore-R</th>\n",
       "      <th>BERTScore-F1</th>\n",
       "      <th>BARTScore</th>\n",
       "      <th>MoverScore</th>\n",
       "      <th>MENLI-W1</th>\n",
       "      <th>DiscoScore-F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI-W.8</th>\n",
       "      <th>MENLI-W.2</th>\n",
       "      <th>MENLI-W.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluency</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ROUGE-1  ROUGE-L  BERTScore-P  BERTScore-R  BERTScore-F1  \\\n",
       "coherence       0.21     0.44         0.36         0.61          0.56   \n",
       "consistency     0.11     0.30         0.37         0.59          0.51   \n",
       "fluency        -0.15     0.00         0.13         0.46          0.25   \n",
       "relevance       0.07     0.37         0.24         0.65          0.45   \n",
       "\n",
       "             BARTScore  MoverScore  MENLI-W1  DiscoScore-F  DiscoScore_S  \\\n",
       "coherence         0.47        0.13     -0.14          0.09          0.07   \n",
       "consistency       0.49        0.06     -0.20         -0.07          0.03   \n",
       "fluency           0.23       -0.15     -0.01          0.09         -0.23   \n",
       "relevance         0.54        0.07     -0.16         -0.09         -0.12   \n",
       "\n",
       "             MENLI-W.8  MENLI-W.2  MENLI-W.3  \n",
       "coherence        -0.06       0.42       0.34  \n",
       "consistency      -0.12       0.37       0.28  \n",
       "fluency           0.06       0.20       0.17  \n",
       "relevance        -0.10       0.33       0.25  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caseF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba0e3c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore-P</th>\n",
       "      <th>BERTScore-R</th>\n",
       "      <th>BERTScore-F1</th>\n",
       "      <th>BARTScore</th>\n",
       "      <th>MoverScore</th>\n",
       "      <th>MENLI-W1</th>\n",
       "      <th>DiscoScore-F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI-W.8</th>\n",
       "      <th>MENLI-W.2</th>\n",
       "      <th>MENLI-W.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence</th>\n",
       "      <td>0.173*</td>\n",
       "      <td>0.296*</td>\n",
       "      <td>-0.112*</td>\n",
       "      <td>0.256*</td>\n",
       "      <td>0.072*</td>\n",
       "      <td>0.085*</td>\n",
       "      <td>0.144*</td>\n",
       "      <td>0.225*</td>\n",
       "      <td>0.209*</td>\n",
       "      <td>0.092*</td>\n",
       "      <td>0.234*</td>\n",
       "      <td>0.162*</td>\n",
       "      <td>0.202*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.175*</td>\n",
       "      <td>0.237*</td>\n",
       "      <td>-0.104*</td>\n",
       "      <td>0.187*</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.156*</td>\n",
       "      <td>0.156*</td>\n",
       "      <td>0.247*</td>\n",
       "      <td>0.164*</td>\n",
       "      <td>0.081*</td>\n",
       "      <td>0.255*</td>\n",
       "      <td>0.169*</td>\n",
       "      <td>0.205*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluency</th>\n",
       "      <td>0.126*</td>\n",
       "      <td>0.174*</td>\n",
       "      <td>-0.126*</td>\n",
       "      <td>0.235*</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.103*</td>\n",
       "      <td>0.144*</td>\n",
       "      <td>0.404*</td>\n",
       "      <td>0.321*</td>\n",
       "      <td>0.079*</td>\n",
       "      <td>0.404*</td>\n",
       "      <td>0.209*</td>\n",
       "      <td>0.257*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance</th>\n",
       "      <td>0.07*</td>\n",
       "      <td>0.191*</td>\n",
       "      <td>-0.194*</td>\n",
       "      <td>0.162*</td>\n",
       "      <td>-0.055*</td>\n",
       "      <td>0.084*</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.106*</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.107*</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ROUGE-1 ROUGE-L BERTScore-P BERTScore-R BERTScore-F1 BARTScore  \\\n",
       "coherence    0.173*  0.296*     -0.112*      0.256*       0.072*    0.085*   \n",
       "consistency  0.175*  0.237*     -0.104*      0.187*        0.006    0.156*   \n",
       "fluency      0.126*  0.174*     -0.126*      0.235*        0.015    0.103*   \n",
       "relevance     0.07*  0.191*     -0.194*      0.162*      -0.055*    0.084*   \n",
       "\n",
       "            MoverScore MENLI-W1 DiscoScore-F DiscoScore_S MENLI-W.8 MENLI-W.2  \\\n",
       "coherence       0.144*   0.225*       0.209*       0.092*    0.234*    0.162*   \n",
       "consistency     0.156*   0.247*       0.164*       0.081*    0.255*    0.169*   \n",
       "fluency         0.144*   0.404*       0.321*       0.079*    0.404*    0.209*   \n",
       "relevance        0.014   0.106*        0.017       -0.023    0.107*      0.01   \n",
       "\n",
       "            MENLI-W.3  \n",
       "coherence      0.202*  \n",
       "consistency    0.205*  \n",
       "fluency        0.257*  \n",
       "relevance       0.043  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = caseF-caseALL\n",
    "p = diff.applymap(lambda x: '' if 0 in x else \"*\")\n",
    "var.round(3).astype(str) + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dfa7edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.153865061503159"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.mean()[var.mean()>0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc3773a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = var.rename(columns = {\"rouge1\": \"ROUGE_1\", \"rougel\":\"ROUGE_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'}) \n",
    "p = p.rename(columns = {\"rouge1\": \"ROUGE_1\", \"rougel\":\"ROUGE_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7bc13d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore-P</th>\n",
       "      <th>BERTScore-R</th>\n",
       "      <th>BERTScore-F1</th>\n",
       "      <th>BARTScore</th>\n",
       "      <th>MoverScore</th>\n",
       "      <th>MENLI-W1</th>\n",
       "      <th>DiscoScore-F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "      <th>MENLI-W.8</th>\n",
       "      <th>MENLI-W.2</th>\n",
       "      <th>MENLI-W.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence</th>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluency</th>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ROUGE-1  ROUGE-L  BERTScore-P  BERTScore-R  BERTScore-F1  \\\n",
       "coherence       0.07    -0.01         0.80         0.17          0.67   \n",
       "consistency    -0.17    -0.24         0.59         0.01          0.42   \n",
       "fluency         0.08    -0.25         0.41        -0.25          0.25   \n",
       "relevance       0.00    -0.04         0.80         0.24          0.74   \n",
       "\n",
       "             BARTScore  MoverScore  MENLI-W1  DiscoScore-F  DiscoScore_S  \\\n",
       "coherence         0.42        0.49      0.52          0.27          0.33   \n",
       "consistency       0.25       -0.04      0.02          0.10          0.17   \n",
       "fluency           0.58        0.25      0.08         -0.08          0.08   \n",
       "relevance         0.37        0.47      0.37          0.27          0.38   \n",
       "\n",
       "             MENLI-W.8  MENLI-W.2  MENLI-W.3  \n",
       "coherence         0.52       0.80       0.80  \n",
       "consistency       0.02       0.45       0.45  \n",
       "fluency           0.08       0.25       0.25  \n",
       "relevance         0.40       0.80       0.80  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = merged_hDe[(merged_hDe.annotator != \"8\" )].set_index(\"id_model\").loc[intersection_of_models]#.set_index(\"annotator\").loc[[\"1\",\"2\",\"3\"]].reset_index()#.loc[[\"4\",\"5\"]].reset_index()# \n",
    "inter2 = df_[(df_.model_id == 'chatGPT_title') | (df_.model_id == 'chatGPT_pipeline')].groupby(\"id_model\").mean()\n",
    "#segment_human = segment_level_coorr(df_)\n",
    "#segment_human.round(3)\n",
    "inter2.corr(\"spearman\").iloc[:4, 6:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092da97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3ad1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_dem(df_):\n",
    "    df = pd.DataFrame()\n",
    "    case = df_[(df_.model_id != 'chatGPT_title') & (df_.model_id != 'chatGPT_pipeline')].groupby(\"id_model\").mean()\n",
    "    print(\"finetuned models: \",case.shape)\n",
    "    case = case.corr(\"spearman\").iloc[:4, 6:17]\n",
    "    dfm = case.reset_index().melt(id_vars=['index'])\n",
    "    dfm[\"model_group\"] = \"Finetuned\"\n",
    "    df = df.append(dfm)\n",
    "    \n",
    "    case = df_[(df_.model_id == 'chatGPT_title') | (df_.model_id == 'chatGPT_pipeline')].groupby(\"id_model\").mean()\n",
    "    print(\"GPT models: \", case.shape)\n",
    "    case = case.corr(\"spearman\").iloc[:4, 6:17]\n",
    "    dfm = case.reset_index().melt(id_vars=['index'])\n",
    "    dfm[\"model_group\"] = \"GPT\"\n",
    "    df = df.append(dfm)\n",
    "    \n",
    "    case = df_.groupby(\"id_model\").mean()\n",
    "    print(\"ALL models: \", case.shape)\n",
    "    case = case.corr(\"spearman\").iloc[:4, 6:17]\n",
    "    dfm = case.reset_index().melt(id_vars=['index'])\n",
    "    dfm[\"model_group\"] = \"Combined\"\n",
    "    df = df.append(dfm)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d396dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned models:  (37, 21)\n",
      "GPT models:  (8, 21)\n",
      "ALL models:  (45, 21)\n"
     ]
    }
   ],
   "source": [
    "sep_df = sep_dem(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f822e664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1386.1x324 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sep_df[\"variable\"] =sep_df[\"variable\"].replace({\"rouge1\": \"Rouge_1\", \"rougel\":\"Rouge_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'})\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(8, 3)})\n",
    "g = sns.catplot(kind='bar', data=sep_df, col='index', x='variable', y='value', order=[\"Rouge_1\", \"Rouge_L\", \"BERTScore_P\",\n",
    "                                                                             \"BERTScore_R\", \"BERTScore_F1\", \n",
    "                                                                              \"BARTScore\", \"MoverScore\",\"MENLI_W1\",\n",
    "                                                                             \"MENLI_W.8\", \"MENLI_W.3\", \"MENLI_W.2\"],\n",
    "                hue = \"model_group\", height = 4.5)\n",
    "g.set_titles(\"{col_name} \")\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set(ylabel=None, xlabel = None, ylim = (-0.5, 1))\n",
    "sns.set_style(\"dark\")\n",
    "g.tight_layout()\n",
    "plt.savefig('hDE-en-segment_cor_by_group.pdf',bbox_inches='tight', pad_inches=0 )  \n",
    "            #col_order=sorted(df.Code.unique()), estimator=sum, ci=None, height=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfb46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb277f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "076da028",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Columns not found: 'MENLI_W0.8', 'rouge1', 'MENLI_W0.3', 'menli', 'moverscore', 'bertscore_R', 'bertscore_P', 'bertscore_F1', 'bartscore', 'DiscoScore_F', 'MENLI_W0.2', 'rougel'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m df_ \u001b[38;5;241m=\u001b[39m merged_hDe[(merged_hDe\u001b[38;5;241m.\u001b[39mannotator \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8\u001b[39m\u001b[38;5;124m\"\u001b[39m ) ]\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mloc[intersection_of_models]\u001b[38;5;66;03m#.set_index(\"annotator\").loc[[\"1\",\"2\",\"3\", \"4\",\"5\",]].reset_index() \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m segment_GPT \u001b[38;5;241m=\u001b[39m \u001b[43msegment_level_coorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36msegment_level_coorr\u001b[0;34m(df_)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msegment_level_coorr\u001b[39m(df_):\n\u001b[0;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns_list\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;66;03m# summary level aggregation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     dct \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoherence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconsistency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfluency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelevance\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/pandas/core/groupby/generic.py:1538\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise warning\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing with multiple keys (implicitly converted to a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof keys) will be deprecated, use a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1536\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1537\u001b[0m     )\n\u001b[0;32m-> 1538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/pandas/core/base.py:222\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mintersection(key)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[1;32m    221\u001b[0m         bad_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(key)\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(bad_keys)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(\u001b[38;5;28mlist\u001b[39m(key), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Columns not found: 'MENLI_W0.8', 'rouge1', 'MENLI_W0.3', 'menli', 'moverscore', 'bertscore_R', 'bertscore_P', 'bertscore_F1', 'bartscore', 'DiscoScore_F', 'MENLI_W0.2', 'rougel'\""
     ]
    }
   ],
   "source": [
    "df_ = merged_hDe[(merged_hDe.annotator == \"8\" ) ].set_index(\"id_model\").loc[intersection_of_models]#.set_index(\"annotator\").loc[[\"1\",\"2\",\"3\", \"4\",\"5\",]].reset_index() \n",
    "segment_GPT = segment_level_coorr(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6166fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_seg =[\"coherence_human\",\"coherence_chatGPT\", \"consistency_human\", \"consistency_chatGPT\",\n",
    "             \"fluency_human\", \"fluency_chatGPT\", \"relevance_human\",   'relevance_chatGPT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65fc2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_cor = pd.merge(segment_human.reset_index(), segment_GPT.reset_index(), on = \"index\", \n",
    "         suffixes = [\"_human\", \"_chatGPT\"], how = \"outer\").set_index(\"index\").loc[order_metric, order_seg].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8eb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfm = seg_cor.reset_index().melt(id_vars=['index'])\n",
    "dfm[\"annotator\"] = [var.split(\"_\")[1] for var in dfm.variable]\n",
    "dfm[\"dimension\"] = [var.split(\"_\")[0] for var in dfm.variable]\n",
    "dfm[\"index\"] = dfm[\"index\"].replace({\"rouge1\": \"Rouge_1\", \"rougel\":\"Rouge_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'})\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(8, 3)})\n",
    "g = sns.catplot(kind='bar', data=dfm, col='dimension', x='index', y='value', order=[\"Rouge_1\", \"Rouge_L\", \"BERTScore_P\",\n",
    "                                                                             \"BERTScore_R\", \"BERTScore_F1\", \n",
    "                                                                              \"BARTScore\", \"MoverScore\",\"MENLI_W1\",\n",
    "                                                                             \"MENLI_W.8\", \"MENLI_W.3\", \"MENLI_W.2\"],\n",
    "                row='annotator', \n",
    "            margin_titles=True, height = 2.5)\n",
    "g.set_titles(\"{col_name} \")\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set(ylabel=None, xlabel = None, ylim = (-0.6, 0.6))\n",
    "sns.set_style(\"dark\")\n",
    "g.tight_layout()\n",
    "plt.savefig('hDE-en-segment_cor.pdf',bbox_inches='tight', pad_inches=0 )  \n",
    "            #col_order=sorted(df.Code.unique()), estimator=sum, ci=None, height=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe06e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b557a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_string(row):\n",
    "    lst = [\"{:.3f}\".format(i.round(3)) for i in row.values]\n",
    "    lst_ = [\"/\".join(lst[:2]), \"/\".join(lst[2:4]), \"/\".join(lst[4:6]), \"/\".join(lst[6:])]\n",
    "    print(lst_)\n",
    "    return \"&\".join(lst_)\n",
    "#generate latex\n",
    "pd.DataFrame(seg_cor.apply(lambda x: turn_string(x) + \"\\\\\" + \"\\\\\", axis = 1)).to_csv(\"experiments/latex/hDe_latex_seg_cor.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ae299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "def system_corr(df_):\n",
    "    seg = df_.groupby([\"id\", \"model_id\"])[columns_list].mean()\n",
    "    df = seg.reset_index().groupby(\"model_id\").mean()\n",
    "    dct = {}\n",
    "    for dim in ['coherence', 'consistency', 'fluency', 'relevance']:\n",
    "        lst_tau = []\n",
    "        lst_spearmanr = []\n",
    "        lst_pr = []\n",
    "        lst_ptau = []\n",
    "        for metric in order_metric:\n",
    "            #lst_tau.append(kendalltau(y=df[dim], x=df[metric]).correlation) #scipy.stats.weightedtau \n",
    "            #lst_ptau.append(kendalltau(y=df[dim], x=df[metric]).pvalue)\n",
    "            lst_spearmanr.append(spearmanr(df[dim], df[metric]).correlation)\n",
    "            if metric == \"bartscore\":\n",
    "                print(df[dim], df[metric], spearmanr(df[dim], df[metric]).correlation)\n",
    "            #lst_pr.append(pearsonr(x=df[dim], y=df[metric])[1])\n",
    "        dct[dim] = lst_spearmanr\n",
    "        #dct[dim+\"_pvalue\"] = lst_pr\n",
    "        #dct[dim+\"_tau\"] = lst_tau\n",
    "        #dct[dim+\"_pvalue_tau\"] = lst_ptau\n",
    "\n",
    "    return pd.DataFrame(dct, index = order_metric)#.to_csv(\"tabular/hEn/corr_system_GPT.csv\", index = True)\n",
    "    #.loc[['rouge1', 'rougel','bertscore', 'bartscore', 'moverscore',  'menli', 'supert']].to_csv(\"tabular/hEn/corr_system_jihed.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93555c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ = merged_hDe[(merged_hDe.annotator != \"8\" )].set_index(\"id_model\").loc[intersection_of_models]\n",
    "system_human = system_corr(df_)\n",
    "df_ = merged_hDe[(merged_hDe.annotator == \"8\" )].set_index(\"id_model\").loc[intersection_of_models]\n",
    "system_chatGPT = system_corr(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd38c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_cor = pd.merge(system_human.reset_index(), system_chatGPT.reset_index(), on = \"index\", \n",
    "         suffixes = [\"_human\", \"_chatGPT\"], how = \"outer\").set_index(\"index\").loc[order_metric, order_seg].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = sys_cor - seg_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = diff.reset_index().melt(id_vars=['index'])\n",
    "dfm[\"annotator\"] = [var.split(\"_\")[1] for var in dfm.variable]\n",
    "dfm[\"dimension\"] = [var.split(\"_\")[0] for var in dfm.variable]\n",
    "dfm[\"index\"] = dfm[\"index\"].replace({\"rouge1\": \"Rouge_1\", \"rougel\":\"Rouge_L\", 'bertscore_P': \"BERTScore_P\", 'bertscore_R':\"BERTScore_R\", \n",
    "                      'bertscore_F1': \"BERTScore_F1\", 'bartscore': \"BARTScore\", \"moverscore\":'MoverScore', \"menli\":'MENLI_W1',\n",
    "                                    'MENLI_W0.8': 'MENLI_W.8', 'MENLI_W0.3':'MENLI_W.3', 'MENLI_W0.2':'MENLI_W.2'})\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(8, 3)})\n",
    "g = sns.catplot(kind='bar', data=dfm, col='dimension', x='index', y='value', order=[\"Rouge_1\", \"Rouge_L\", \"BERTScore_P\",\n",
    "                                                                             \"BERTScore_R\", \"BERTScore_F1\", \n",
    "                                                                              \"BARTScore\", \"MoverScore\",\"MENLI_W1\",\n",
    "                                                                             \"MENLI_W.8\", \"MENLI_W.3\", \"MENLI_W.2\"],\n",
    "                row='annotator', \n",
    "            margin_titles=True, height = 2.5)\n",
    "g.set_titles(\"{col_name} \")\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set(ylabel=None, xlabel = None, ylim = (-0.6, 0.6))\n",
    "sns.set_style(\"dark\")\n",
    "g.tight_layout()\n",
    "\n",
    "            #col_order=sorted(df.Code.unique()), estimator=sum, ci=None, height=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7138d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc729a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ea11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = merged_hDe[(merged_hDe.annotator == \"8\" )].set_index(\"id_model\").loc[intersection_of_models]\n",
    "system_gpt = system_corr(df_)\n",
    "system_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac7c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(system_human.reset_index(), system_gpt.reset_index(), on = \"index\", \n",
    "         suffixes = [\"_human\", \"_chatGPT\"], how = \"outer\").set_index(\"index\").loc[order_metric, order_seg].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbac25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85fc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mul = pd.read_csv(\"./experiments/Metrics/052023/mul_en_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "combi = pd.merge(score_en, score_mul, on = \"idx\", suffixes =[\"_base_en\", \"_base_mul\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combi.corr(\"spearman\").iloc[2:8, 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd3942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e0579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f628af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "sns.set_style(\"dark\")\n",
    "pyplot.subplots(figsize=(8, 8))\n",
    "# calculate the correlation matrix\n",
    "corr = output_all_hDe.iloc[:,2:].corr().loc[order_metric, order_metric]\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(corr, cmap=\"Blues\", annot=True, \n",
    "        xticklabels=corr.index,\n",
    "        yticklabels=corr.columns)\n",
    "#pyplot.savefig('tabular/hDe/corr_plot.pdf',bbox_inches='tight', pad_inches=0 )  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
