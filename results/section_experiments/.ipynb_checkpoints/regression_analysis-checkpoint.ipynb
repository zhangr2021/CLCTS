{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72607ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regress against standardized \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fecba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hDe = pd.read_csv(\"./experiments/hDe-output_all_27052023.csv\")\n",
    "score_en = pd.read_csv(\"./experiments/Metrics/052023/en_en_output.csv\")\n",
    "discoscore_en = pd.read_csv(\"./experiments/discoplus_en_en_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2c9874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5519, 6) (5519, 9) (5519, 8)\n"
     ]
    }
   ],
   "source": [
    "print(output_all_hDe.shape,score_en.shape, discoscore_en.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cdb4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hDe.model_id = output_all_hDe.model_id.apply(lambda x: x.replace(\"-False-False-False\", \"_False\").replace(\"-True-True-True\", \"_True\"))\n",
    "score_en = pd.merge(score_en, discoscore_en[[\"idx\", \"rouge1\", \"DS_Focus_NN\",\"DS_SENT_NN\"]], on = [\"idx\", \"rouge1\"], how = \"inner\")\n",
    "score_en = score_en.rename(columns = {\"DS_Focus_NN\":\"DiscoScore_F\", \"DS_SENT_NN\":\"DiscoScore_S\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edec27ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Text   id_x    Phase             Model Model-Id  coherence  consistency  \\\n",
      "0  Text-1  199.0  Phase-1  mLED hDE-EN only        1        1.5          2.0   \n",
      "1  Text-1  199.0  Phase-1  mLED hDE-EN only        1        2.0          1.0   \n",
      "2  Text-1  199.0  Phase-1  mLED hDE-EN only        1        1.5          2.0   \n",
      "3  Text-1  199.0  Phase-1  mLED hDE-EN only        1        1.5          1.5   \n",
      "4  Text-1  199.0  Phase-1  mLED hDE-EN only        1        2.5          1.5   \n",
      "\n",
      "   fluency  relevance annotator  id_y     id model_id  \n",
      "0      3.0        2.5         2   NaN  199.0        1  \n",
      "1      3.0        1.5         3   NaN  199.0        1  \n",
      "2      3.0        2.0         1   NaN  199.0        1  \n",
      "3      2.5        1.5         4   NaN  199.0        1  \n",
      "4      3.0        1.5         5   NaN  199.0        1  \n",
      "chatGPT: (607, 15)\n"
     ]
    }
   ],
   "source": [
    "eval_ = pd.DataFrame()\n",
    "path = \"../dataset/Outputs/Human_Evaluation/hDE-EN\"\n",
    "for file in os.listdir(path):\n",
    "    if \"val\" in file:\n",
    "        try:\n",
    "            e = pd.read_csv(path + \"/\" + file, sep = \";\")\n",
    "        except:\n",
    "            e = pd.read_csv(path + \"/\" + file,) \n",
    "            e.columns = ['Unnamed: 0', 'Model-Id', 'generated_summary', 'id', 'direction',\n",
    "       'reference_summary', 'text', 'coherence', 'consistency', 'fluency',\n",
    "       'relevance']\n",
    "            e = e[['Model-Id', 'id', 'coherence', 'consistency', 'fluency',\n",
    "       'relevance']]\n",
    "        e[\"annotator\"] = file[-5:-4]\n",
    "       # if (file[-5:-4] != \"7\"): #& (file[-5:-4] != \"1\") :\n",
    "        eval_ = pd.concat([eval_, e])\n",
    "phase1_hDe=pd.read_csv(\"../dataset/Outputs/Human_Evaluation/hDE-EN-p1_id.csv\")[[\"Text\", \"id\"]]\n",
    "phase1_hDe[\"id\"] = [int(id_.split(\":\")[1].replace(\"\\r\", \"\")) for id_ in phase1_hDe.id]\n",
    "phase1_hDe[\"Phase\"] = \"Phase-1\"\n",
    "phase2_hDe=pd.read_csv(\"../dataset/Outputs/Human_Evaluation/hDE-EN-p2_id.csv\")[[\"Text\", \"id\"]]\n",
    "phase2_hDe[\"id\"] = [int(id_.split(\":\")[1].replace(\"\\r\", \"\")) for id_ in phase2_hDe.id]\n",
    "phase2_hDe[\"Phase\"] = \"Phase-2\"\n",
    "phase_id = phase1_hDe.append(phase2_hDe)\n",
    "\n",
    "# merge with id\n",
    "eval_ = pd.merge(phase_id, eval_, on = [\"Phase\", \"Text\"], how = 'outer')\n",
    "eval_[\"id\"] = [eval_.id_y.iloc[idx] if pd.isna(eval_.id_x.iloc[idx]) else eval_.id_x.iloc[idx] for idx in range(len(eval_))]\n",
    "for column in [\"coherence\", \"consistency\",  \"fluency\", \"relevance\"]:\n",
    "    eval_[column] = [float(str(eval_[column].iloc[idx]).replace(\",\", \".\")) for idx in range(len(eval_)) ]\n",
    "eval_[\"model_id\"] = eval_[\"Model-Id\"]\n",
    "eval_[\"model_id\"] = eval_[\"model_id\"].replace({\"101\":'10'})\n",
    "print(eval_.head())\n",
    "\n",
    "chat_anno = pd.read_csv(path + \"/\" + \"en_chat_8.csv\") \n",
    "chat_anno[\"annotator\"] = str(8)\n",
    "chat_anno = chat_anno.dropna()\n",
    "print(\"chatGPT:\", chat_anno.shape)\n",
    "\n",
    "eval_.model_id = eval_.model_id.replace({\"chatGPT_pp\": \"chatGPT_pipeline\", \"Memsum\":\"memsum_deepl\"})\n",
    "column = [\"id\", \"model_id\", \"coherence\", \"consistency\", \"fluency\", \"relevance\", \"annotator\"]\n",
    "eval_ = pd.concat([eval_[column], chat_anno[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e319a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_all_hDe_en = pd.concat([output_all_hDe, score_en], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b9570e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from menli normalization\n",
    "def min_max_normalize(scores):\n",
    "    if len(scores) > 1:\n",
    "        normalized_scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "    else:\n",
    "        normalized_scores = scores\n",
    "    return normalized_scores\n",
    "def compute_menli(df):\n",
    "    for nli_weight in [0.8, 0.2, 0.3]:   \n",
    "        norm_metric_scores = min_max_normalize(df.bertscore_F1)\n",
    "        norm_nli_scores = min_max_normalize(df.menli)\n",
    "        final_scores = [nli_weight*n + (1-nli_weight)*m for n, m in zip(norm_nli_scores, norm_metric_scores)]\n",
    "        df[\"MENLI_W\" + str(nli_weight)] = final_scores\n",
    "    return df\n",
    "output_all_hDe = compute_menli(output_all_hDe_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e5c90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_metric = ['rouge1', 'rougel', 'bertscore_P',\n",
    "       'bertscore_R', 'bertscore_F1',  'bartscore','moverscore','menli',  'MENLI_W0.8', 'MENLI_W0.3', 'MENLI_W0.2', \"DiscoScore_F\", \"DiscoScore_S\"]\n",
    "\n",
    "model_order = ['German_25_False', 'German_25_True',\n",
    "       'German_100',  \n",
    "                '1','3', '2', '4','9_2', '9_1',  '10',  'chatGPT_title',\n",
    "       'chatGPT_e2e', 'chatGPT_pipeline',\n",
    "       ]\n",
    "\n",
    "model_order_human = [\n",
    "                '1','3', '2', '4','9_2', '9_1',  '10',  'chatGPT_title', 'chatGPT_pipeline',\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58effbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id\n",
      "1                   324\n",
      "10                  324\n",
      "2                   324\n",
      "3                   324\n",
      "4                   324\n",
      "5                   324\n",
      "6                   324\n",
      "7                   324\n",
      "8                   324\n",
      "9_1                 324\n",
      "9_2                 324\n",
      "German_100          324\n",
      "German_25_False     324\n",
      "German_25_True      324\n",
      "chatGPT_e2e         323\n",
      "chatGPT_pipeline    324\n",
      "chatGPT_title       324\n",
      "Name: menli, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougel</th>\n",
       "      <th>bertscore_P</th>\n",
       "      <th>bertscore_R</th>\n",
       "      <th>bertscore_F1</th>\n",
       "      <th>bartscore</th>\n",
       "      <th>moverscore</th>\n",
       "      <th>menli</th>\n",
       "      <th>MENLI_W0.8</th>\n",
       "      <th>MENLI_W0.3</th>\n",
       "      <th>MENLI_W0.2</th>\n",
       "      <th>DiscoScore_F</th>\n",
       "      <th>DiscoScore_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>German_25_False</th>\n",
       "      <td>0.320</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.545</td>\n",
       "      <td>-3.311</td>\n",
       "      <td>0.552</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_25_True</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-3.360</td>\n",
       "      <td>0.551</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_100</th>\n",
       "      <td>0.382</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-3.421</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.391</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.547</td>\n",
       "      <td>-3.524</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.479</td>\n",
       "      <td>1.838</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.393</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.551</td>\n",
       "      <td>-3.492</td>\n",
       "      <td>0.569</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.485</td>\n",
       "      <td>1.725</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.547</td>\n",
       "      <td>-3.534</td>\n",
       "      <td>0.567</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.477</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.389</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.547</td>\n",
       "      <td>-3.567</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.426</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_2</th>\n",
       "      <td>0.386</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-3.593</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.464</td>\n",
       "      <td>1.595</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_1</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-3.615</td>\n",
       "      <td>0.567</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.458</td>\n",
       "      <td>1.685</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.386</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.539</td>\n",
       "      <td>-3.590</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.462</td>\n",
       "      <td>1.635</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_title</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.528</td>\n",
       "      <td>-3.857</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_e2e</th>\n",
       "      <td>0.399</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.624</td>\n",
       "      <td>-3.363</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatGPT_pipeline</th>\n",
       "      <td>0.382</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-3.422</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rouge1  rougel  bertscore_P  bertscore_R  bertscore_F1  \\\n",
       "model_id                                                                   \n",
       "German_25_False    0.320   0.175        0.521        0.574         0.545   \n",
       "German_25_True     0.315   0.171        0.514        0.567         0.538   \n",
       "German_100         0.382   0.234        0.639        0.597         0.615   \n",
       "1                  0.391   0.201        0.537        0.561         0.547   \n",
       "3                  0.393   0.200        0.539        0.566         0.551   \n",
       "2                  0.388   0.198        0.537        0.561         0.547   \n",
       "4                  0.389   0.198        0.540        0.556         0.547   \n",
       "9_2                0.386   0.201        0.536        0.547         0.540   \n",
       "9_1                0.380   0.198        0.530        0.544         0.536   \n",
       "10                 0.386   0.202        0.532        0.548         0.539   \n",
       "chatGPT_title      0.304   0.164        0.527        0.530         0.528   \n",
       "chatGPT_e2e        0.399   0.244        0.646        0.607         0.624   \n",
       "chatGPT_pipeline   0.382   0.232        0.637        0.597         0.615   \n",
       "\n",
       "                  bartscore  moverscore  menli  MENLI_W0.8  MENLI_W0.3  \\\n",
       "model_id                                                                 \n",
       "German_25_False      -3.311       0.552 -0.232       0.407       0.463   \n",
       "German_25_True       -3.360       0.551 -0.248       0.398       0.450   \n",
       "German_100           -3.421       0.571 -0.206       0.446       0.566   \n",
       "1                    -3.524       0.568 -0.206       0.418       0.469   \n",
       "3                    -3.492       0.569 -0.216       0.416       0.473   \n",
       "2                    -3.534       0.567 -0.231       0.408       0.465   \n",
       "4                    -3.567       0.568 -0.255       0.398       0.461   \n",
       "9_2                  -3.593       0.568 -0.252       0.397       0.453   \n",
       "9_1                  -3.615       0.567 -0.241       0.400       0.448   \n",
       "10                   -3.590       0.568 -0.246       0.399       0.451   \n",
       "chatGPT_title        -3.857       0.542 -0.700       0.211       0.367   \n",
       "chatGPT_e2e          -3.363       0.575 -0.194       0.455       0.580   \n",
       "chatGPT_pipeline     -3.422       0.571 -0.282       0.415       0.554   \n",
       "\n",
       "                  MENLI_W0.2  DiscoScore_F  DiscoScore_S  \n",
       "model_id                                                  \n",
       "German_25_False        0.474         0.551         0.928  \n",
       "German_25_True         0.461         0.536         0.926  \n",
       "German_100             0.589         0.883         0.925  \n",
       "1                      0.479         1.838         0.936  \n",
       "3                      0.485         1.725         0.935  \n",
       "2                      0.477         1.142         0.936  \n",
       "4                      0.473         1.426         0.936  \n",
       "9_2                    0.464         1.595         0.934  \n",
       "9_1                    0.458         1.685         0.934  \n",
       "10                     0.462         1.635         0.934  \n",
       "chatGPT_title          0.398         0.788         0.928  \n",
       "chatGPT_e2e            0.605         0.982         0.945  \n",
       "chatGPT_pipeline       0.581         0.907         0.937  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate table 1 eval_metrics\n",
    "filtered = output_all_hDe.set_index(\"id\").loc[output_all_hDe[output_all_hDe.model_id == \"1\"].id]\n",
    "latex = filtered.groupby(\"model_id\").mean().iloc[:, -14:].loc[model_order, order_metric]#.to_csv(\"tabular/hDe/metric_eval_mean.csv\", index = True)\n",
    "print(filtered.groupby(\"model_id\").menli.count())\n",
    "latex.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab417ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hDe_processed = pd.read_csv(\"../chatGPT/results_r1/de_processed_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "073b85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document features\n",
    "merged = pd.merge(hDe_processed[[\"id\", \"count_word\", \"Year\"]], output_all_hDe, on = \"id\", how = \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81151004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'count_word', 'Year', 'model_id', 'Unnamed: 0',\n",
       "       'reference_summary', 'generated_summary', 'direction', 'rouge1',\n",
       "       'rougel', 'bertscore_P', 'bertscore_R', 'bertscore_F1', 'bartscore',\n",
       "       'moverscore', 'menli', 'idx', 'DiscoScore_F', 'DiscoScore_S',\n",
       "       'MENLI_W0.8', 'MENLI_W0.2', 'MENLI_W0.3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "097df463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61b91173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95ae29db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     slope     intercept   r_value       p_value\n",
      "model_id                                                        \n",
      "1                -0.183251 -7.292378e-17 -0.183251  9.201335e-04\n",
      "10               -0.117292 -3.248418e-18 -0.117292  3.482537e-02\n",
      "2                -0.125818 -8.492620e-17 -0.125818  2.351366e-02\n",
      "3                -0.232923  3.999583e-17 -0.232923  2.287642e-05\n",
      "4                -0.136696  4.188886e-17 -0.136696  1.379379e-02\n",
      "5                -0.136096  1.405359e-16 -0.136096  1.421931e-02\n",
      "6                -0.196380 -1.076968e-16 -0.196380  3.767472e-04\n",
      "7                -0.180715  3.381976e-17 -0.180715  1.086015e-03\n",
      "8                -0.156928 -1.708845e-17 -0.156928  4.635159e-03\n",
      "9_1              -0.074518 -6.088838e-17 -0.074518  1.808961e-01\n",
      "9_2              -0.088540  1.209594e-16 -0.088540  1.116784e-01\n",
      "German_100       -0.273247  4.634733e-17 -0.273247  5.013864e-07\n",
      "German_25_False  -0.343121  2.973196e-17 -0.343121  1.710112e-10\n",
      "German_25_True   -0.347387  1.005060e-16 -0.347387  9.798574e-11\n",
      "chatGPT_e2e      -0.213162  3.137659e-17 -0.213162  1.131099e-04\n",
      "chatGPT_pipeline -0.209338 -8.157791e-18 -0.209338  1.472538e-04\n",
      "chatGPT_title     0.070932  6.660687e-17  0.070932  2.028584e-01\n"
     ]
    }
   ],
   "source": [
    "def linReg(x, y):\n",
    "    '''linear regression using numpy starting from two one dimensional numpy arrays'''\n",
    "    x = scaler.fit_transform(np.array(x).reshape(-1, 1))\n",
    "    y = scaler.fit_transform(np.array(y).reshape(-1, 1))\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x.reshape(-1),y.reshape(-1))\n",
    "    return pd.Series({'slope':slope, 'intercept': intercept, \"r_value\": r_value, \"p_value\":p_value })\n",
    "res = merged.groupby('model_id').apply(lambda x: linReg(x[\"count_word\"], x[\"menli\"]))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abac3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     slope     intercept   r_value   p_value\n",
      "model_id                                                    \n",
      "1                -0.076575 -9.099682e-16 -0.076575  0.169117\n",
      "10                0.003477 -3.114591e-15  0.003477  0.950288\n",
      "2                -0.038045 -1.614553e-15 -0.038045  0.494981\n",
      "3                -0.072516  2.570434e-15 -0.072516  0.192932\n",
      "4                 0.011195 -3.676233e-16  0.011195  0.840908\n",
      "5                 0.004163  1.226473e-15  0.004163  0.940493\n",
      "6                 0.017957 -1.288579e-15  0.017957  0.747454\n",
      "7                 0.058343  2.537872e-16  0.058343  0.295094\n",
      "8                -0.109123  3.457397e-15 -0.109123  0.049706\n",
      "9_1               0.035061  5.993388e-16  0.035061  0.529444\n",
      "9_2              -0.035657 -3.041199e-15 -0.035657  0.522465\n",
      "German_100       -0.103082  3.450851e-17 -0.103082  0.062218\n",
      "German_25_False  -0.128714 -7.273159e-16 -0.128714  0.019705\n",
      "German_25_True   -0.148729  6.829314e-16 -0.148729  0.006969\n",
      "chatGPT_e2e      -0.042220 -3.341664e-16 -0.042220  0.449544\n",
      "chatGPT_pipeline -0.091914 -4.777788e-16 -0.091914  0.098625\n",
      "chatGPT_title    -0.106130  3.122472e-15 -0.106130  0.056347\n"
     ]
    }
   ],
   "source": [
    "def linReg(x, y):\n",
    "    '''linear regression using numpy starting from two one dimensional numpy arrays'''\n",
    "    x = scaler.fit_transform(np.array(x).reshape(-1, 1))\n",
    "    y = scaler.fit_transform(np.array(y).reshape(-1, 1))\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x.reshape(-1),y.reshape(-1))\n",
    "    return pd.Series({'slope':slope, 'intercept': intercept, \"r_value\": r_value, \"p_value\":p_value })\n",
    "res = merged.groupby('model_id').apply(lambda x: linReg(x[\"Year\"], x[\"bertscore_F1\"]))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a71a3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
